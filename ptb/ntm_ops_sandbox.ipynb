{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focusing by content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys= Tensor(\"Const:0\", shape=(2, 3), dtype=float32)\n",
      "memory= Tensor(\"transpose:0\", shape=(3, 4), dtype=float32)\n",
      "keys =\n",
      " [array([[ 0.2       ,  0.30000001,  0.40000001],\n",
      "       [ 0.1       ,  0.2       ,  0.69999999]], dtype=float32)]\n",
      "memory =\n",
      " [array([[ 0.2       ,  0.2       ,  0.30000001,  0.1       ],\n",
      "       [ 0.30000001,  0.30000001,  0.30000001,  0.2       ],\n",
      "       [ 0.40000001,  0.40000001,  0.30000001,  0.69999999]], dtype=float32)]\n",
      "focus =\n",
      " [array([[  4.92605865e-01,   4.92605865e-01,   1.47291617e-02,\n",
      "          5.90993950e-05],\n",
      "       [  1.19946955e-04,   1.19946955e-04,   4.91867769e-10,\n",
      "          9.99760211e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Reset graph - just in case.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def focusing_by_location(keys, beta, memory):\n",
    "    \"\"\"Computes content addressing. Uses both address and content part for calculation of the similarity.\n",
    "    Args:\n",
    "        key: a 2-D Tensor [BATCH_SIZE x SLOT_SIZE] \n",
    "        beta: a 1-D Tensor - key strength [BATCH_SIZE x 1]\n",
    "        memory: a 2-D Tensor [SLOT_SIZE x NUMBER_OF_SLOTS]\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"focusing_by_location\"):\n",
    "    \n",
    "        # Normalize batch - along samples.\n",
    "        norm_keys = tf.nn.l2_normalize(keys,1, name=\"normalized_keys\")\n",
    "        # Normalize memory - along slots \n",
    "        norm_memory = tf.nn.l2_normalize(memory, 0)\n",
    "\n",
    "        # Calculate cosine similarity [BATCH_SIZE x NUMBER_OF_SLOTS].\n",
    "        similarity = tf.matmul(norm_keys, norm_memory, name=\"similarity\")\n",
    "\n",
    "        # Element-wise multiplication [BATCH_SIZE x NUMBER_OF_SLOTS]\n",
    "        strengthtened_similarity = beta * similarity\n",
    "\n",
    "        # Calculate weighting based on similarity along the \"slot dimension\" [BATCH_SIZE x NUMBER_OF_SLOTS].\n",
    "        result = tf.nn.softmax(strengthtened_similarity, dim=1)\n",
    "        return result\n",
    "\n",
    "\n",
    "# test focusing\n",
    "keys = tf.constant([[0.2, 0.3, 0.4],[0.1, 0.2, 0.7]], dtype=tf.float32)\n",
    "print(\"keys=\",keys)\n",
    "beta= tf.constant([[100.0],[100.0]], dtype=tf.float32)\n",
    "\n",
    "memory = tf.transpose(tf.constant([[0.2, 0.3, 0.4],[0.2, 0.3, 0.4],[0.3, 0.3, 0.3],[0.1, 0.2, 0.7]], dtype=tf.float32))\n",
    "print(\"memory=\",memory)\n",
    "\n",
    "focus = focusing_by_location(keys, beta, memory)\n",
    "\n",
    "# Finally - initialize all variables.\n",
    "initialize_model = tf.global_variables_initializer()    \n",
    "    \n",
    "# Execute graph.\n",
    "sess=tf.InteractiveSession()\n",
    "# Initialize.\n",
    "sess.run(initialize_model)\n",
    "print(\"keys =\\n\",sess.run([keys]))\n",
    "print(\"memory =\\n\",sess.run([memory]))\n",
    "print(\"focus =\\n\",sess.run([focus]))\n",
    "# [7,1,2,3,4,5,6]\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focusing by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v= Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n",
      "g= Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
      "gammas_stacked= Tensor(\"sharpening/transpose:0\", shape=(?, 3), dtype=float32)\n",
      "powed_batch= Tensor(\"sharpening/add:0\", shape=(?, 3), dtype=float32)\n",
      "sharpened_batch= Tensor(\"sharpening/truediv:0\", shape=(?, 3), dtype=float32)\n",
      "v =\n",
      " [array([[ 0.2       ,  0.30000001,  0.40000001],\n",
      "       [ 0.        ,  0.30000001,  0.89999998],\n",
      "       [ 0.30000001,  0.30000001,  0.30000001],\n",
      "       [ 0.1       ,  0.2       ,  0.69999999]], dtype=float32)]\n",
      "sharp_v =\n",
      " [array([[  7.88868831e-11,   5.66400843e-07,   9.99999404e-01],\n",
      "       [  8.33333336e-31,   2.50000000e-01,   7.49999940e-01],\n",
      "       [  3.33333313e-01,   3.33333313e-01,   3.33333313e-01],\n",
      "       [  5.56030187e-23,   5.56036435e-23,   1.00000000e+00]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Reset graph - just in case.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def sharpening(batch, gamma):\n",
    "    \"\"\"Computes sharpening.\n",
    "    Args:\n",
    "        batch: a 2-D Tensor [BATCH_SIZE x NUMBER_OF_SLOTS] \n",
    "        gamma: a 1-D Tensor [BATCH_SIZE x 1]\n",
    "    \"\"\"\n",
    "    EPS = 1e-30\n",
    "    with tf.name_scope(\"sharpening\"):    \n",
    "        number_of_slots = int(batch.get_shape()[1])\n",
    "\n",
    "        # Duplicate gammas - tf.tile is not working for partially unknown shape :] \n",
    "        gammas = []\n",
    "        for i in range(number_of_slots):\n",
    "            # Truncates gamma to 50!\n",
    "            gammas.append(tf.minimum(gamma[:,0], 50))\n",
    "        gammas_stacked = tf.transpose(tf.stack(gammas))\n",
    "        print(\"gammas_stacked=\", gammas_stacked)\n",
    "        # Calculate powered batch [BATCH_SIZE x NUMBER_OF_SLOTS].\n",
    "        powed_batch = tf.pow(batch, gammas_stacked)+EPS\n",
    "        print(\"powed_batch=\", powed_batch)\n",
    "\n",
    "        # \"Normalization\" [BATCH_SIZE x NUMBER_OF_SLOTS].\n",
    "        sharpened_batch = (powed_batch) / (tf.reduce_sum(powed_batch, axis=1, keep_dims=True))\n",
    "        print(\"sharpened_batch=\",sharpened_batch)\n",
    "\n",
    "        return sharpened_batch\n",
    "\n",
    "\n",
    "NUMBER_OF_SLOTS = 3\n",
    "# test sharpening\n",
    "v = tf.placeholder(tf.float32, shape=[None, NUMBER_OF_SLOTS])\n",
    "#v = tf.constant([[0.2, 0.3, 0.4]], dtype=tf.float32)\n",
    "print(\"v=\",v)\n",
    "g = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "#g = tf.constant([1.0], dtype=tf.float32)\n",
    "print(\"g=\",g)\n",
    "\n",
    "sharp_v = sharpening(v, g)\n",
    "\n",
    "# Finally - initialize all variables.\n",
    "initialize_model = tf.global_variables_initializer()    \n",
    "\n",
    "my_v = [[0.2, 0.3, 0.4],[0.0, 0.3, 0.9],[0.3, 0.3, 0.3],[0.1, 0.2, 0.7]]\n",
    "init_g = np.transpose([50.0, 1.0, 10.0, 50.0])\n",
    "my_g = np.reshape(init_g, [4,1])\n",
    "my_feed_dict={v: my_v, g: my_g}\n",
    "\n",
    "# Execute graph.\n",
    "sess=tf.InteractiveSession()\n",
    "# Initialize.\n",
    "sess.run(initialize_model)\n",
    "print(\"v =\\n\",sess.run([v], feed_dict=my_feed_dict))\n",
    "print(\"sharp_v =\\n\",sess.run([sharp_v], feed_dict=my_feed_dict))\n",
    "# [7,1,2,3,4,5,6]\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circular convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v= Tensor(\"Const:0\", shape=(3, 7), dtype=float32)\n",
      "k= Tensor(\"Const_1:0\", shape=(3, 3), dtype=float32)\n",
      "conv =\n",
      " [array([[ 7.        ,  1.        ,  2.        ,  3.        ,  4.        ,\n",
      "         5.        ,  6.        ],\n",
      "       [ 4.        ,  1.5       ,  2.5       ,  3.5       ,  4.5       ,\n",
      "         5.5       ,  6.5       ],\n",
      "       [ 0.2       ,  0.30000001,  0.40000001,  0.5       ,  0.60000002,\n",
      "         0.69999999,  0.1       ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Reset graph - just in case.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def circular_index(idx, size):\n",
    "    if idx < 0: return size + idx\n",
    "    if idx >= size : return idx - size\n",
    "    else: return idx\n",
    "\n",
    "def circular_convolution(batch, kernel):\n",
    "    \"\"\"Computes circular convolution.\n",
    "    Args:\n",
    "        batch: a 2-D Tensor [BATCH_SIZE x NUMBER_OF_SLOTS] \n",
    "        kernel: a 2-D Tensor [BATCH_SIZE x KERNEL_SIZE (e.g. 3)]\n",
    "    \"\"\"\n",
    "    size = int(batch.get_shape()[1])\n",
    "    kernel_size = int(k.get_shape()[1])\n",
    "    kernel_shift = int(math.floor(kernel_size/2.0))\n",
    "\n",
    "    kernels = []\n",
    "    for i in range(size):\n",
    "        # Create a list of index vectors.\n",
    "        indices = [circular_index(i+j, size) for j in range(kernel_shift, -kernel_shift-1, -1)]\n",
    "        # Reorganize batch according to indices. \n",
    "        reorganized_batch = tf.gather(batch, indices, axis=1)\n",
    "        # Perform convolution.\n",
    "        kernels.append(tf.reduce_sum(reorganized_batch * kernel, 1))\n",
    "    # Sum elements lying on the same positions.\n",
    "    result = tf.transpose(tf.dynamic_stitch([i for i in range(size)], kernels))\n",
    "    return result\n",
    "\n",
    "# test circular convolution\n",
    "v = tf.constant([[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[0.1,0.2,0.3,0.4,0.5,0.6,0.7]], dtype=tf.float32)\n",
    "print(\"v=\",v)\n",
    "k = tf.constant([[0,0,1],[0,0.5,0.5],[1,0,0]], dtype=tf.float32)\n",
    "print(\"k=\",k)\n",
    "\n",
    "conv = circular_convolution(v, k)\n",
    "\n",
    "# Finally - initialize all variables.\n",
    "initialize_model = tf.global_variables_initializer()    \n",
    "    \n",
    "# Execute graph.\n",
    "sess=tf.InteractiveSession()\n",
    "# Initialize.\n",
    "sess.run(initialize_model)\n",
    "print(\"conv =\\n\",sess.run([conv]))\n",
    "# [7,1,2,3,4,5,6]\n",
    "sess.close()batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sharpening\n",
    "## Requirements: EPS = 1e-40, gamma truncated to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v= Tensor(\"Const:0\", shape=(4, 3), dtype=float32)\n",
      "g= Tensor(\"Const_1:0\", shape=(4,), dtype=float32)\n",
      "pows= 3\n",
      "v =\n",
      " [array([[ 0.2       ,  0.30000001,  0.40000001],\n",
      "       [ 0.2       ,  0.30000001,  0.40000001],\n",
      "       [ 0.30000001,  0.30000001,  0.30000001],\n",
      "       [ 0.1       ,  0.2       ,  0.69999999]], dtype=float32)]\n",
      "sharp_v =\n",
      " [array([[  2.22222239e-01,   3.33333343e-01,   4.44444478e-01],\n",
      "       [  1.37931034e-01,   3.10344815e-01,   5.51724136e-01],\n",
      "       [  3.33333343e-01,   3.33333343e-01,   3.33333343e-01],\n",
      "       [  4.13564994e-04,   6.61703991e-03,   9.92969394e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Reset graph - just in case.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "def sharpening(batch, gamma):\n",
    "    \"\"\"Computes sharpening.\n",
    "    Args:\n",
    "        batch: a 2-D Tensor [BATCH_SIZE x NUMBER_OF_SLOTS] \n",
    "        gamma: a 2-D Tensor [BATCH_SIZE x 1]\n",
    "    \"\"\"\n",
    "    EPS = 1e-40\n",
    "    \n",
    "    slots = int(batch.get_shape()[1]) # NUMBER_OF_SLOTS\n",
    "    \n",
    "    # Calculate powered batch [BATCH_SIZE x NUMBER_OF_SLOTS].\n",
    "    pows = []\n",
    "    for i in range(slots):\n",
    "        pows.append(tf.pow(batch[:,i], gamma))\n",
    "    print(\"pows=\",len(pows))\n",
    "    powed_batch_stacked = tf.transpose(tf.stack(pows))\n",
    "    #print(\"powed_batch_stacked=\", powed_batch_stacked)\n",
    "    \n",
    "    # \"Normalization\" [BATCH_SIZE x NUMBER_OF_SLOTS].\n",
    "    sharpened_batch = (powed_batch_stacked+EPS) / (tf.reduce_sum(powed_batch_stacked, axis=1, keep_dims=True)+EPS)\n",
    "\n",
    "    return sharpened_batch\n",
    "\n",
    "\n",
    "# test sharpening\n",
    "v = tf.constant([[0.2, 0.3, 0.4],[0.2, 0.3, 0.4],[0.3, 0.3, 0.3],[0.1, 0.2, 0.7]], dtype=tf.float32)\n",
    "#v = tf.constant([[0.2, 0.3, 0.4]], dtype=tf.float32)\n",
    "print(\"v=\",v)\n",
    "g = tf.constant([1.0, 2.0, 3.0, 4.0], dtype=tf.float32)\n",
    "#g = tf.constant([1.0], dtype=tf.float32)\n",
    "print(\"g=\",g)\n",
    "\n",
    "sharp_v = sharpening(v, g)\n",
    "\n",
    "# Finally - initialize all variables.\n",
    "initialize_model = tf.global_variables_initializer()    \n",
    "    \n",
    "# Execute graph.\n",
    "sess=tf.InteractiveSession()\n",
    "# Initialize.\n",
    "sess.run(initialize_model)\n",
    "print(\"v =\\n\",sess.run([v]))\n",
    "print(\"sharp_v =\\n\",sess.run([sharp_v]))\n",
    "# [7,1,2,3,4,5,6]\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
