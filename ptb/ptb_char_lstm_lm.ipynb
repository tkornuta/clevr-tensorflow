{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import tarfile\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import shutil \n",
    "import random\n",
    "\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "# Local dir where PTB files will be stored.\n",
    "PTB_DIR = '/home/tkornuta/data/ptb/'\n",
    "\n",
    "# Filenames.\n",
    "TRAIN = \"ptb.train.txt\"\n",
    "VALID = \"ptb.valid.txt\"\n",
    "TEST = \"ptb.test.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check/maybe download PTB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified /home/tkornuta/data/ptb/simple-examples.tgz ( 34869662 )\n"
     ]
    }
   ],
   "source": [
    "def maybe_download_ptb(path, \n",
    "                       filename='simple-examples.tgz', \n",
    "                       url='http://www.fit.vutbr.cz/~imikolov/rnnlm/', \n",
    "                       expected_bytes =34869662):\n",
    "  # Eventually create the PTB dir.\n",
    "  if not tf.gfile.Exists(path):\n",
    "    tf.gfile.MakeDirs(path)\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  _filename = path+filename\n",
    "  if not os.path.exists(_filename):\n",
    "    print('Downloading %s...' % filename)\n",
    "    _filename, _ = urlretrieve(url+filename, _filename)\n",
    "  statinfo = os.stat(_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', (_filename), '(', statinfo.st_size, ')')\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + _filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download_ptb(PTB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract dataset-related files from the PTB archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_ptb(path, filename='simple-examples.tgz', files=[\"ptb.train.txt\", \"ptb.valid.txt\", \"ptb.test.txt\", \n",
    "                                       \"ptb.char.train.txt\", \"ptb.char.valid.txt\", \"ptb.char.test.txt\"]):\n",
    "    \"\"\"Extracts files from PTB archive.\"\"\"\n",
    "    # Extract\n",
    "    tar = tarfile.open(path+filename)\n",
    "    tar.extractall(path)\n",
    "    tar.close()\n",
    "    # Copy files\n",
    "    for file in files:\n",
    "        shutil.copyfile(PTB_DIR+\"simple-examples/data/\"+file, PTB_DIR+file)\n",
    "    # Delete directory\n",
    "    shutil.rmtree(PTB_DIR+\"simple-examples/\")        \n",
    "\n",
    "extract_ptb(PTB_DIR)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train, valid and test texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5101618  aer banknote berlitz calloway centrust cluett fromstein gitano \n",
      "399782  consumers may want to move their telephones a little closer to \n",
      "449945  no it was n't black monday \n",
      " but while the new york stock excha\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename, path):\n",
    "    with open(path+filename, 'r') as myfile:\n",
    "        data=myfile.read()# .replace('\\n', '')\n",
    "        return data\n",
    "\n",
    "train_text = read_data(TRAIN, PTB_DIR)\n",
    "train_size=len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "\n",
    "valid_text = read_data(VALID, PTB_DIR)\n",
    "valid_size=len(valid_text)\n",
    "print(valid_size, valid_text[:64])\n",
    "\n",
    "test_text = read_data(TEST, PTB_DIR)\n",
    "test_size=len(test_text)\n",
    "print(test_size, test_text[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to map characters to vocabulary IDs and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "65\n",
      "33 1 58 26 0 0\n",
      "a A\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 59 # [A-Z] + [a-z] + ' ' +few 'in between; + punctuation\n",
    "first_letter = ord(string.ascii_uppercase[0]) # ascii_uppercase before lowercase! \n",
    "print(vocabulary_size)\n",
    "print(first_letter)\n",
    "\n",
    "def char2id(char):\n",
    "  \"\"\" Converts char to id (int) with chandling of unexpected characters\"\"\"\n",
    "  if char in string.ascii_letters:# or char in string.punctuation or char in string.digits:\n",
    "    return ord(char) - first_letter + 1\n",
    "  elif char == ' ':\n",
    "    return 0\n",
    "  else:\n",
    "    # print('Unexpected character: %s' % char)\n",
    "    return 0\n",
    "  \n",
    "def id2char(dictid):\n",
    "  \"\"\" Converts single id (int) to character\"\"\"\n",
    "  if dictid > 0:\n",
    "    return chr(dictid + first_letter - 1)\n",
    "  else:\n",
    "    return ' '\n",
    "\n",
    "def characters(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  characters back into its (most likely) character representation.\"\"\"\n",
    "  return [id2char(c) for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "  \"\"\"Convert a sequence of batches back into their (most likely) string\n",
    "  representation.\"\"\"\n",
    "  s = [''] * batches[0].shape[0]\n",
    "  for b in batches:\n",
    "    s = [''.join(x) for x in zip(s, characters(b))]\n",
    "  return s\n",
    "\n",
    "#print(len(string.punctuation))\n",
    "#for i in string.ascii_letters:\n",
    "#    print (i, char2id(i))\n",
    "\n",
    "\n",
    "print(char2id('a'), char2id('A'), char2id('z'), char2id('Z'), char2id(' '), char2id('Ã¯'))\n",
    "print(id2char(char2id('a')), id2char(char2id('A')))\n",
    "#print(id2char(65), id2char(33), id2char(90), id2char(58), id2char(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper class for batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro quebec ipo kia memotec', 'as the six members of the association of southeast asian nations thailand malaysia singapore indonesi', 'ack said he is pleased with the economy  s recent performance and does n t see a lot of excesses out ', 'significant recent experience with a similar program in central america indicates that it could take ', 'age does n t cause volatility it  unk  to it   think about what causes the difference in prices betwe', 'rk stock exchange composite trading yesterday intelogic shares rose N cents to close at   N   mr  ede', 's goodman theatre  unk   unk  take the stage in  unk  city leisure   arts the role of  unk  played by', 'rs who are up to N years old and then for another N days if the company institutes a specific trainin', '  unk  taste  unk  says hispanics prefer the new brand has a  unk  content of N N   that compares wit', ' university of kentucky a team led by dean  unk  a physical therapy researcher is testing the stimula', 'ite house are squeezed too by steady increases   N million in veteran  s medical care   the result is', 'ole over  unk  and the results of  unk  and  unk  aircraft experiments conducted over the past severa', '  unk  election between the two biggest  unk  social democrat mario  unk  and two conservatives  unk ', 'omputers   toyota motor corp   s sales offices in japan have  unk  the computers per employee that it', ' north  unk  are pushing spot prices of potatoes beyond what michael contracted to pay last spring   ', ' unk  aircraft corp  a unit of  unk  co  received an   N million air force contract for  unk  aircraf', 'drug companies although he would n t elaborate   an indication of akzo  s success in  unk  itself wil', 'annual rate   in august personal income rose N N and spending grew N N   analysts have attributed muc', '  unk     unk  elliott   wives may not benefit when men do chores   when  unk  take on more  unk  the', 's although economists noted the rate probably will pick up in the months ahead in response to hurrica', 'cturing of its bank debt   the write off will be reported as an extraordinary item in the company  s ', 'tional council on the handicapped all appointed by president reagan   you  unk  the bill as something', ' t add to volatility he says   futures do n t need defending says andrew  unk  a spokesman for the ch', 'na which has nearly N adjusters had deployed about N of them in charlotte columbia and charleston   a', '  unk    his daughter turns to  unk  then to peddling herself for a few  unk    one son  unk  his own', 'on the amendment by threatening a  unk  or extended debate   for a  unk  vote to stop the  unk  repub', ' while many experts argue that  unk  nations would eventually become  unk  in a free market system th', 'happens the entire process of  unk  technology to the marketplace could be  unk  they say   the stake', ' teams and new restrictions on  unk    unconstitutional bills make good legal targets but the line it', ' board argues that its new product will help rather than hurt the situation by possibly drawing busin', 'ts a share   average daily trading volume N shares   common shares outstanding N million      include', 'r   N a share the year earlier   the latest nine months included charges of   N million related to th', '  unk  to a   N million loss disclosed in december that was suffered by west virginia  s consolidated', ' sang the dallas staging that introduced the  unk  idea   in an  unk  that drives  unk   unk   unk  v', 're from   N million or N cents a share in the year earlier period   the latest results include a gain', 'ackluster mid october sales   the treasury  s    year bond ended over N point higher   municipal mort', 'the least leveraged casino companies said daniel lee an analyst with drexel burnham lambert inc   mr ', 'luding profit from discontinued operations both years and in N an extraordinary charge of   N million', 'eral noriega in custody but was under attack by  unk  troops   mr  noriega did n t suffer from any  u', 'unk  acquisition have begun a cash tender offer for all of vermont  s common shares outstanding   the', 'ood as well as practical advice on how to  unk   unk   unk  meals became the basis for her  unk  and ', ' arrest the N decline when beijing  unk  the  unk  on foreign exchange spending and  unk  the currenc', 'gh court majority said it was up to the state courts for now to decide whether the definition has any', 'en a big loss   we  ve taken it on the  unk    but we  re out there and we  re going to stay in busin', 'liquid crystal displays   the new technologies are intended to retire the  unk  tube which accounts f', 'cle   during its centennial year the wall street journal will report events of the past century that ', 'rrowed indicating weaker demand for cash copper   long term support for the december contract was bel', 'police department  s  unk  division    unk   unk  are the most visible targets of unscrupulous  unk  ', ' tables show the big board and amex issues in which a short interest position of at least N shares ex', 'mr  baldwin likes the offering   but several mutual fund managers nervous about the deteriorating qua', 'r the year ending jan  N N are expected to be N to N cents a share compared with a previous estimate ', 'rease despite a N N rise in fuel costs and a N N drop in car  unk    most of the commodity traffic wa', ' speaker thomas foley d  wash after  unk  with california lawmakers   it  s impossible to put an exac', 'N N N days N N N days N N N days   negotiable bank backed business credit instruments typically finan', 'ers general accident rose N pence to   N   N a share guardian royal climbed N to N pence sun alliance', 'ig customers who already own both digital and ibm systems   one such company is bankers trust co   st', '  flight to safety   despite recent declines in interest rates money funds continue to offer better y', '  back in says richard ross a market research director for  unk     unk  in chicago   then there  ll ', ' should do well there   at the same time the market is smaller than the market for  unk  software   f', 'ill face an immediate threat to his nation  s very existence german reunification   mr  krenz age N i', 'by recent market volatility analysts and traders say there are still a few concerns on the horizon   ', ' tiger with combined  unk  gains of about   N million and ual gave him a   N million bonus when it hi', 'ho do n t quite share the enthusiasm   this summer speeding bikers were blamed for an accident in the', '   N million almost unchanged from   N million a year earlier   polaroid reported operating profit be']\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "num_unrollings=100\n",
    "\n",
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, num_unrollings):\n",
    "    self._text = text\n",
    "    self._text_size = len(text)\n",
    "    self._batch_size = batch_size\n",
    "    self._num_unrollings = num_unrollings\n",
    "    segment = self._text_size // batch_size\n",
    "    self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "    self._last_batch = self._next_batch()\n",
    "  \n",
    "  def _next_batch(self):\n",
    "    \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
    "    batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\n",
    "    for b in range(self._batch_size):\n",
    "      batch[b, char2id(self._text[self._cursor[b]])] = 1.0\n",
    "      self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "    return batch\n",
    "  \n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "    the last batch of the previous array, followed by num_unrollings new ones.\n",
    "    \"\"\"\n",
    "    batches = [self._last_batch]\n",
    "    for step in range(self._num_unrollings):\n",
    "      batches.append(self._next_batch())\n",
    "    self._last_batch = batches[-1]\n",
    "    return batches\n",
    "\n",
    "# Create two objects for training and validation batch generation.\n",
    "train_batches = BatchGenerator(train_text, batch_size, num_unrollings)\n",
    "valid_batches = BatchGenerator(valid_text, 1, 1)\n",
    "\n",
    "batch = train_batches.next()\n",
    "#print(batch)\n",
    "print(batches2string(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "  \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "  predictions[predictions < 1e-10] = 1e-10\n",
    "  return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "  \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "  probabilities.\n",
    "  \"\"\"\n",
    "  r = random.uniform(0, 1)\n",
    "  s = 0\n",
    "  for i in range(len(distribution)):\n",
    "    s += distribution[i]\n",
    "    if s >= r:\n",
    "      return i\n",
    "  return len(distribution) - 1\n",
    "\n",
    "def sample(prediction):\n",
    "  \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "  p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
    "  p[0, sample_distribution(prediction[0])] = 1.0\n",
    "  return p\n",
    "\n",
    "def random_distribution():\n",
    "  \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "  b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
    "  return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_nodes = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  # Parameters:\n",
    "  # Input gate: input, previous output, and bias.\n",
    "  ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ib = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Forget gate: input, previous output, and bias.\n",
    "  fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  fb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Memory cell: input, state and bias.                             \n",
    "  cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  cb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Output gate: input, previous output, and bias.\n",
    "  ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ob = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Variables saving state across unrollings.\n",
    "  saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  # Classifier weights and biases.\n",
    "  w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n",
    "  b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "  \n",
    "  # Definition of the cell computation.\n",
    "  def lstm_cell(i, o, state):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    return output_gate * tf.tanh(state), state\n",
    "\n",
    "  # Input data.\n",
    "  train_data = list()\n",
    "  for _ in range(num_unrollings + 1):\n",
    "    train_data.append(\n",
    "      tf.placeholder(tf.float32, shape=[batch_size,vocabulary_size]))\n",
    "  train_inputs = train_data[:num_unrollings]\n",
    "  train_labels = train_data[1:]  # labels are inputs shifted by one time step.\n",
    "\n",
    "  # Unrolled LSTM loop.\n",
    "  outputs = list()\n",
    "  output = saved_output\n",
    "  state = saved_state\n",
    "  for i in train_inputs:\n",
    "    output, state = lstm_cell(i, output, state)\n",
    "    outputs.append(output)\n",
    "\n",
    "  # State saving across unrollings.\n",
    "  with tf.control_dependencies([saved_output.assign(output),\n",
    "                                saved_state.assign(state)]):\n",
    "    # Classifier.\n",
    "    logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.concat(train_labels, 0), logits=logits))\n",
    "\n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "    10.0, global_step, 5000, 0.1, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "  gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "  optimizer = optimizer.apply_gradients(\n",
    "    zip(gradients, v), global_step=global_step)\n",
    "\n",
    "  # Predictions.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "  # Sampling and validation eval: batch 1, no unrolling.\n",
    "  sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n",
    "  saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  reset_sample_state = tf.group(\n",
    "    saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "    saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "  sample_output, sample_state = lstm_cell(\n",
    "    sample_input, saved_sample_output, saved_sample_state)\n",
    "  with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "                                saved_sample_state.assign(sample_state)]):\n",
    "    sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 4.079040 learning rate: 10.000000\n",
      "Minibatch BPC: 59.09\n",
      "================================================================================\n",
      "gZ[iiVWQJ lh`WAs J`] P B\\WzTsrG awuRcI Bn `QqfQvttyYqohL  u J U A yoVZ Ka TSqrk]\n",
      "_hcRo]`oao DJ nnI]dDQbIt cy Oa[sF yabyaRPcNonLK`   ny^lOepGgn]X eUWDveXryNtuPv E\n",
      "t_krO_ZExUVjj^b`vFDQ lafItXRMooXRrcoyRetnge aCc_Ja tuatfzordtSVYteoKOs  cL]mY HF\n",
      "Zl CpYxhJ^[VNiK S LotNMYbYnpP _ CQ  pV fFviA WnrwaqRu\\  ii`t TC t lIp` UzehMs[S\\\n",
      "Za   ss azufcbXMJDsF_ KA_ pj cmDElT[Rnehk]nYC_UPIi tNHiDjrC rEN Gh^ RrU_YUajI\\t \n",
      "================================================================================\n",
      "Validation set BPC: 31.28\n",
      "Average loss at step 100: 2.660756 learning rate: 10.000000\n",
      "Minibatch BPC: 10.37\n",
      "Validation set BPC: 10.56\n",
      "Average loss at step 200: 2.131332 learning rate: 10.000000\n",
      "Minibatch BPC: 7.85\n",
      "Validation set BPC: 7.42\n",
      "Average loss at step 300: 1.939570 learning rate: 10.000000\n",
      "Minibatch BPC: 6.74\n",
      "Validation set BPC: 6.93\n",
      "Average loss at step 400: 1.820804 learning rate: 10.000000\n",
      "Minibatch BPC: 6.18\n",
      "Validation set BPC: 6.52\n",
      "Average loss at step 500: 1.745067 learning rate: 10.000000\n",
      "Minibatch BPC: 5.61\n",
      "Validation set BPC: 6.07\n",
      "Average loss at step 600: 1.689336 learning rate: 10.000000\n",
      "Minibatch BPC: 5.09\n",
      "Validation set BPC: 6.63\n",
      "Average loss at step 700: 1.634293 learning rate: 10.000000\n",
      "Minibatch BPC: 4.87\n",
      "Validation set BPC: 4.47\n",
      "Average loss at step 800: 1.596749 learning rate: 10.000000\n",
      "Minibatch BPC: 4.65\n",
      "Validation set BPC: 4.61\n",
      "Average loss at step 900: 1.575593 learning rate: 10.000000\n",
      "Minibatch BPC: 4.93\n",
      "Validation set BPC: 5.82\n",
      "Average loss at step 1000: 1.551066 learning rate: 10.000000\n",
      "Minibatch BPC: 4.61\n",
      "================================================================================\n",
      "fority sale   indud   fut his the heip to net sietment moner other today man   t\n",
      "Fed in the smocks  millisa doup sRnesman sepracions had are was the sitelo expec\n",
      "Oed computer pences in manage ale n t yeen of toolargan buy near tomenn that tum\n",
      "Kent price antear lenorop worlustoce lometes aysuall operex fasurebering ram  un\n",
      "Eentwer  unk  busish ante  unk  to croge the andures inits   houra tow of beomis\n",
      "================================================================================\n",
      "Validation set BPC: 5.23\n",
      "Average loss at step 1100: 1.517415 learning rate: 10.000000\n",
      "Minibatch BPC: 4.60\n",
      "Validation set BPC: 5.05\n",
      "Average loss at step 1200: 1.499768 learning rate: 10.000000\n",
      "Minibatch BPC: 4.39\n",
      "Validation set BPC: 5.02\n",
      "Average loss at step 1300: 1.487109 learning rate: 10.000000\n",
      "Minibatch BPC: 4.54\n",
      "Validation set BPC: 4.66\n",
      "Average loss at step 1400: 1.477180 learning rate: 10.000000\n",
      "Minibatch BPC: 4.47\n",
      "Validation set BPC: 3.97\n",
      "Average loss at step 1500: 1.464184 learning rate: 10.000000\n",
      "Minibatch BPC: 4.43\n",
      "Validation set BPC: 3.89\n",
      "Average loss at step 1600: 1.448566 learning rate: 10.000000\n",
      "Minibatch BPC: 4.26\n",
      "Validation set BPC: 4.51\n",
      "Average loss at step 1700: 1.448500 learning rate: 10.000000\n",
      "Minibatch BPC: 4.17\n",
      "Validation set BPC: 3.87\n",
      "Average loss at step 1800: 1.438504 learning rate: 10.000000\n",
      "Minibatch BPC: 4.18\n",
      "Validation set BPC: 4.23\n",
      "Average loss at step 1900: 1.420095 learning rate: 10.000000\n",
      "Minibatch BPC: 4.13\n",
      "Validation set BPC: 3.80\n",
      "Average loss at step 2000: 1.413929 learning rate: 10.000000\n",
      "Minibatch BPC: 4.15\n",
      "================================================================================\n",
      "Yed to mr  added the  unk  now former says bank in stcknd spend to N will trade \n",
      "ublion  s investment was weel insurt for raped busy said  antistan short hadelov\n",
      "lawing or  unk    j ames flow any briect which official  lented co  n t up tax t\n",
      "^ed supphen taxn   pprand excections wo yound conturned announi relover and manu\n",
      "go revenue saffery funds unco thyuch huble time  unk   unk  mayson purceesinn a \n",
      "================================================================================\n",
      "Validation set BPC: 4.02\n",
      "Average loss at step 2100: 1.408680 learning rate: 10.000000\n",
      "Minibatch BPC: 4.10\n",
      "Validation set BPC: 3.89\n",
      "Average loss at step 2200: 1.406624 learning rate: 10.000000\n",
      "Minibatch BPC: 4.04\n",
      "Validation set BPC: 3.67\n",
      "Average loss at step 2300: 1.402485 learning rate: 10.000000\n",
      "Minibatch BPC: 4.13\n",
      "Validation set BPC: 4.42\n",
      "Average loss at step 2400: 1.391978 learning rate: 10.000000\n",
      "Minibatch BPC: 3.99\n",
      "Validation set BPC: 3.61\n",
      "Average loss at step 2500: 1.396430 learning rate: 10.000000\n",
      "Minibatch BPC: 4.19\n",
      "Validation set BPC: 4.37\n",
      "Average loss at step 2600: 1.390568 learning rate: 10.000000\n",
      "Minibatch BPC: 3.92\n",
      "Validation set BPC: 4.44\n",
      "Average loss at step 2700: 1.375615 learning rate: 10.000000\n",
      "Minibatch BPC: 3.88\n",
      "Validation set BPC: 4.21\n",
      "Average loss at step 2800: 1.373990 learning rate: 10.000000\n",
      "Minibatch BPC: 3.99\n",
      "Validation set BPC: 3.31\n",
      "Average loss at step 2900: 1.371795 learning rate: 10.000000\n",
      "Minibatch BPC: 3.85\n",
      "Validation set BPC: 3.22\n",
      "Average loss at step 3000: 1.371587 learning rate: 10.000000\n",
      "Minibatch BPC: 3.89\n",
      "================================================================================\n",
      "[osing   volunn time is common suming control says   intruced had beay line and \n",
      "Gusters rating will have brow N unoviev at accorded   the industry flowed N for \n",
      "Jest said the and will say to yean the built major N   the blade investment assi\n",
      "Keck to commits in the pehational and called to   who have lists that twles dowa\n",
      " off has can blawnhed too shilohell lost cities incceeler by to medicly displaye\n",
      "================================================================================\n",
      "Validation set BPC: 4.04\n",
      "Average loss at step 3100: 1.370599 learning rate: 10.000000\n",
      "Minibatch BPC: 3.81\n",
      "Validation set BPC: 4.37\n",
      "Average loss at step 3200: 1.361885 learning rate: 10.000000\n",
      "Minibatch BPC: 4.02\n",
      "Validation set BPC: 4.06\n",
      "Average loss at step 3300: 1.365605 learning rate: 10.000000\n",
      "Minibatch BPC: 3.91\n",
      "Validation set BPC: 4.38\n",
      "Average loss at step 3400: 1.362469 learning rate: 10.000000\n",
      "Minibatch BPC: 3.89\n",
      "Validation set BPC: 4.30\n",
      "Average loss at step 3500: 1.350181 learning rate: 10.000000\n",
      "Minibatch BPC: 3.83\n",
      "Validation set BPC: 4.70\n",
      "Average loss at step 3600: 1.350505 learning rate: 10.000000\n",
      "Minibatch BPC: 3.98\n",
      "Validation set BPC: 3.42\n",
      "Average loss at step 3700: 1.348201 learning rate: 10.000000\n",
      "Minibatch BPC: 3.95\n",
      "Validation set BPC: 3.75\n",
      "Average loss at step 3800: 1.346140 learning rate: 10.000000\n",
      "Minibatch BPC: 3.79\n",
      "Validation set BPC: 3.72\n",
      "Average loss at step 3900: 1.348191 learning rate: 10.000000\n",
      "Minibatch BPC: 3.87\n",
      "Validation set BPC: 3.90\n",
      "Average loss at step 4000: 1.342880 learning rate: 10.000000\n",
      "Minibatch BPC: 4.04\n",
      "================================================================================\n",
      "Ies  unk  for anative and pech or  s prediate was decline he say it it half   th\n",
      "\\e that having lawyer  s for the filed price recent  s N months scien  on use he\n",
      "]es would or  s  unk  as u s  would be was about   N by the far day   nor  unk  \n",
      "Y roistive to N manuaterselary  unk    N debated quested a perberm out   on a pr\n",
      "Qew car ban  unk  than resultmy watheld suggriton tests   securities   federal i\n",
      "================================================================================\n",
      "Validation set BPC: 3.93\n",
      "Average loss at step 4100: 1.344635 learning rate: 10.000000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 4.64\n",
      "Average loss at step 4200: 1.345223 learning rate: 10.000000\n",
      "Minibatch BPC: 3.77\n",
      "Validation set BPC: 4.19\n",
      "Average loss at step 4300: 1.330865 learning rate: 10.000000\n",
      "Minibatch BPC: 3.69\n",
      "Validation set BPC: 4.04\n",
      "Average loss at step 4400: 1.331997 learning rate: 10.000000\n",
      "Minibatch BPC: 3.78\n",
      "Validation set BPC: 4.45\n",
      "Average loss at step 4500: 1.331798 learning rate: 10.000000\n",
      "Minibatch BPC: 3.86\n",
      "Validation set BPC: 4.51\n",
      "Average loss at step 4600: 1.328396 learning rate: 10.000000\n",
      "Minibatch BPC: 3.83\n",
      "Validation set BPC: 4.74\n",
      "Average loss at step 4700: 1.332548 learning rate: 10.000000\n",
      "Minibatch BPC: 3.96\n",
      "Validation set BPC: 5.39\n",
      "Average loss at step 4800: 1.327244 learning rate: 10.000000\n",
      "Minibatch BPC: 3.75\n",
      "Validation set BPC: 4.50\n",
      "Average loss at step 4900: 1.332190 learning rate: 10.000000\n",
      "Minibatch BPC: 3.80\n",
      "Validation set BPC: 5.23\n",
      "Average loss at step 5000: 1.330822 learning rate: 1.000000\n",
      "Minibatch BPC: 3.77\n",
      "================================================================================\n",
      "mention forging to about legrlston  unk  of  unk  and the  unk  point phoriaks f\n",
      "Uess englong what p then and japan des under china and suctifien that the flect \n",
      "Ret was assimation in the u s when not are to linting and the new machine mornon\n",
      "jomment and cresisate secretacce in the  unk  fine that N tim brand in revinic a\n",
      "ray texas will in often it flinh in earlier closes   the could n t were to lates\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set BPC: 4.43\n",
      "Average loss at step 5100: 1.308180 learning rate: 1.000000\n",
      "Minibatch BPC: 3.70\n",
      "Validation set BPC: 4.65\n",
      "Average loss at step 5200: 1.307375 learning rate: 1.000000\n",
      "Minibatch BPC: 3.72\n",
      "Validation set BPC: 4.59\n",
      "Average loss at step 5300: 1.304303 learning rate: 1.000000\n",
      "Minibatch BPC: 3.72\n",
      "Validation set BPC: 3.89\n",
      "Average loss at step 5400: 1.301745 learning rate: 1.000000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 4.21\n",
      "Average loss at step 5500: 1.306507 learning rate: 1.000000\n",
      "Minibatch BPC: 3.71\n",
      "Validation set BPC: 3.69\n",
      "Average loss at step 5600: 1.301749 learning rate: 1.000000\n",
      "Minibatch BPC: 3.69\n",
      "Validation set BPC: 3.88\n",
      "Average loss at step 5700: 1.305911 learning rate: 1.000000\n",
      "Minibatch BPC: 3.71\n",
      "Validation set BPC: 4.66\n",
      "Average loss at step 5800: 1.300741 learning rate: 1.000000\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 4.65\n",
      "Average loss at step 5900: 1.297149 learning rate: 1.000000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 4.12\n",
      "Average loss at step 6000: 1.300710 learning rate: 1.000000\n",
      "Minibatch BPC: 3.58\n",
      "================================================================================\n",
      "Jen revenue six president digitore improve strvession for its and its investment\n",
      "Ked is the national prussects was before a capital  unk  company  s it managigut\n",
      "boeming   have the  unk  inc  its could nead last one   N big surcendent had nef\n",
      "uctimes in the presidentgow notevo likely who precbion  unk  development the hel\n",
      "ent securities been rats a boad to heads and bac to anson voloves claim  unk  ar\n",
      "================================================================================\n",
      "Validation set BPC: 3.69\n",
      "Average loss at step 6100: 1.299815 learning rate: 1.000000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 4.05\n",
      "Average loss at step 6200: 1.296845 learning rate: 1.000000\n",
      "Minibatch BPC: 3.69\n",
      "Validation set BPC: 4.14\n",
      "Average loss at step 6300: 1.303170 learning rate: 1.000000\n",
      "Minibatch BPC: 3.71\n",
      "Validation set BPC: 3.97\n",
      "Average loss at step 6400: 1.299338 learning rate: 1.000000\n",
      "Minibatch BPC: 3.81\n",
      "Validation set BPC: 4.14\n",
      "Average loss at step 6500: 1.303308 learning rate: 1.000000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.78\n",
      "Average loss at step 6600: 1.299926 learning rate: 1.000000\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 4.17\n",
      "Average loss at step 6700: 1.293287 learning rate: 1.000000\n",
      "Minibatch BPC: 3.55\n",
      "Validation set BPC: 3.81\n",
      "Average loss at step 6800: 1.299064 learning rate: 1.000000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.71\n",
      "Average loss at step 6900: 1.297087 learning rate: 1.000000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.31\n",
      "Average loss at step 7000: 1.294406 learning rate: 1.000000\n",
      "Minibatch BPC: 3.62\n",
      "================================================================================\n",
      "Vonch  unk   unk  and traditively officer caper has production the mpenged a com\n",
      "`ied co    its can any or determat and managed sold were buy ors was bue whether\n",
      "Pess in apparentlely stock soming costs of egoth  unk  surply company was  unk  \n",
      "Less in a late by a group of  unk  buted N to kudd of mortgaged handationine off\n",
      "men  s priced to public its  unk  corp  a for house julizen and procections well\n",
      "================================================================================\n",
      "Validation set BPC: 3.70\n",
      "Average loss at step 7100: 1.301128 learning rate: 1.000000\n",
      "Minibatch BPC: 3.72\n",
      "Validation set BPC: 3.47\n",
      "Average loss at step 7200: 1.297111 learning rate: 1.000000\n",
      "Minibatch BPC: 3.77\n",
      "Validation set BPC: 3.47\n",
      "Average loss at step 7300: 1.301863 learning rate: 1.000000\n",
      "Minibatch BPC: 3.73\n",
      "Validation set BPC: 3.20\n",
      "Average loss at step 7400: 1.298778 learning rate: 1.000000\n",
      "Minibatch BPC: 3.75\n",
      "Validation set BPC: 3.17\n",
      "Average loss at step 7500: 1.289307 learning rate: 1.000000\n",
      "Minibatch BPC: 3.44\n",
      "Validation set BPC: 3.31\n",
      "Average loss at step 7600: 1.298685 learning rate: 1.000000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.57\n",
      "Average loss at step 7700: 1.294703 learning rate: 1.000000\n",
      "Minibatch BPC: 3.54\n",
      "Validation set BPC: 3.98\n",
      "Average loss at step 7800: 1.292175 learning rate: 1.000000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 3.84\n",
      "Average loss at step 7900: 1.300304 learning rate: 1.000000\n",
      "Minibatch BPC: 3.80\n",
      "Validation set BPC: 3.68\n",
      "Average loss at step 8000: 1.294473 learning rate: 1.000000\n",
      "Minibatch BPC: 3.61\n",
      "================================================================================\n",
      "deers  unk  large    unk  that a yeersecorg of wisseding    s gran package in u \n",
      "`e ham fujurers program tues on much of  unk  includes and futial suber is the s\n",
      "zose his   N a some cargers wnt a researchersact just at union all the dellaads \n",
      "^es became both of the when the profit bank in the  unk  on the mercogioy demoks\n",
      "Pes to an all of  unk  attempters    unk  create intelbiel associated in convict\n",
      "================================================================================\n",
      "Validation set BPC: 3.67\n",
      "Average loss at step 8100: 1.300888 learning rate: 1.000000\n",
      "Minibatch BPC: 3.50\n",
      "Validation set BPC: 3.62\n",
      "Average loss at step 8200: 1.297578 learning rate: 1.000000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 4.29\n",
      "Average loss at step 8300: 1.286892 learning rate: 1.000000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 4.13\n",
      "Average loss at step 8400: 1.297587 learning rate: 1.000000\n",
      "Minibatch BPC: 3.75\n",
      "Validation set BPC: 3.33\n",
      "Average loss at step 8500: 1.293066 learning rate: 1.000000\n",
      "Minibatch BPC: 3.73\n",
      "Validation set BPC: 3.72\n",
      "Average loss at step 8600: 1.290839 learning rate: 1.000000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.91\n",
      "Average loss at step 8700: 1.297960 learning rate: 1.000000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.48\n",
      "Average loss at step 8800: 1.292938 learning rate: 1.000000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.65\n",
      "Average loss at step 8900: 1.299970 learning rate: 1.000000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.40\n",
      "Average loss at step 9000: 1.295732 learning rate: 1.000000\n",
      "Minibatch BPC: 3.74\n",
      "================================================================================\n",
      "Ge reported with like the red  unk    furk as  unk  se triet other find the old \n",
      "Gine wiclieas institute freaturine common  s intentom in financial  unk  and   l\n",
      "Eetal and change for the would steers of the n t she declinery who and composite\n",
      "ents a fance in lows   the state modermake   in a ret belief annual  unk  ceothe\n",
      "ket to mr   unk  lasty measures in corpsficial procesdo young a sales were sais \n",
      "================================================================================\n",
      "Validation set BPC: 3.33\n",
      "Average loss at step 9100: 1.285747 learning rate: 1.000000\n",
      "Minibatch BPC: 3.76\n",
      "Validation set BPC: 3.05\n",
      "Average loss at step 9200: 1.295341 learning rate: 1.000000\n",
      "Minibatch BPC: 3.63\n",
      "Validation set BPC: 3.22\n",
      "Average loss at step 9300: 1.291789 learning rate: 1.000000\n",
      "Minibatch BPC: 3.56\n",
      "Validation set BPC: 4.01\n",
      "Average loss at step 9400: 1.288649 learning rate: 1.000000\n",
      "Minibatch BPC: 3.57\n",
      "Validation set BPC: 3.77\n",
      "Average loss at step 9500: 1.296300 learning rate: 1.000000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 3.65\n",
      "Average loss at step 9600: 1.292335 learning rate: 1.000000\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 3.29\n",
      "Average loss at step 9700: 1.298874 learning rate: 1.000000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.63\n",
      "Average loss at step 9800: 1.294023 learning rate: 1.000000\n",
      "Minibatch BPC: 3.51\n",
      "Validation set BPC: 3.35\n",
      "Average loss at step 9900: 1.284226 learning rate: 1.000000\n",
      "Minibatch BPC: 3.54\n",
      "Validation set BPC: 4.17\n",
      "Average loss at step 10000: 1.293649 learning rate: 0.100000\n",
      "Minibatch BPC: 3.50\n",
      "================================================================================\n",
      "mend tvoduiting ohios  unk   unk  unis aid also capaction offal to deplays cost \n",
      "Iedare salis   it said fatis concerns agree spection corporations of an investme\n",
      "ch tix is a but the  unk  quarter is rable rather when a services inc  vice bank\n",
      "Wed scriving closed the call  s issues of a  unk  the gure the u s  profitabilti\n",
      "Bed  unk  of hempost in the pale to   N million after they  unk  tot its special\n",
      "================================================================================\n",
      "Validation set BPC: 4.29\n",
      "Average loss at step 10100: 1.292639 learning rate: 0.100000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 10200: 1.288764 learning rate: 0.100000\n",
      "Minibatch BPC: 3.71\n",
      "Validation set BPC: 4.34\n",
      "Average loss at step 10300: 1.296630 learning rate: 0.100000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.50\n",
      "Average loss at step 10400: 1.291366 learning rate: 0.100000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.61\n",
      "Average loss at step 10500: 1.297846 learning rate: 0.100000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.95\n",
      "Average loss at step 10600: 1.292706 learning rate: 0.100000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 3.88\n",
      "Average loss at step 10700: 1.280646 learning rate: 0.100000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.57\n",
      "Average loss at step 10800: 1.291205 learning rate: 0.100000\n",
      "Minibatch BPC: 3.72\n",
      "Validation set BPC: 3.96\n",
      "Average loss at step 10900: 1.290743 learning rate: 0.100000\n",
      "Minibatch BPC: 3.70\n",
      "Validation set BPC: 3.90\n",
      "Average loss at step 11000: 1.287167 learning rate: 0.100000\n",
      "Minibatch BPC: 3.67\n",
      "================================================================================\n",
      "outher this year peace the use  unk  c a as year   homo inclistanwes or texes it\n",
      "Uet will the two seeingy offergold include when the demand in the  unk   unk  of\n",
      "weekers in N cancert the carry to blued ration sont office   seen  wroter the it\n",
      "quise of their summercely co    N million borroc  unk  hinsole  unk  the ume  s \n",
      "fucr a land  unk  political some proving manager   market ippontment your p  rem\n",
      "================================================================================\n",
      "Validation set BPC: 3.28\n",
      "Average loss at step 11100: 1.296052 learning rate: 0.100000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 3.54\n",
      "Average loss at step 11200: 1.289774 learning rate: 0.100000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.53\n",
      "Average loss at step 11300: 1.297798 learning rate: 0.100000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.93\n",
      "Average loss at step 11400: 1.292528 learning rate: 0.100000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.44\n",
      "Average loss at step 11500: 1.280368 learning rate: 0.100000\n",
      "Minibatch BPC: 3.87\n",
      "Validation set BPC: 3.38\n",
      "Average loss at step 11600: 1.291124 learning rate: 0.100000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 2.75\n",
      "Average loss at step 11700: 1.290355 learning rate: 0.100000\n",
      "Minibatch BPC: 3.52\n",
      "Validation set BPC: 2.90\n",
      "Average loss at step 11800: 1.287426 learning rate: 0.100000\n",
      "Minibatch BPC: 3.73\n",
      "Validation set BPC: 2.92\n",
      "Average loss at step 11900: 1.295240 learning rate: 0.100000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 3.64\n",
      "Average loss at step 12000: 1.289100 learning rate: 0.100000\n",
      "Minibatch BPC: 3.62\n",
      "================================================================================\n",
      "_ed dof the  unk  state menutimes of the year  unk  proferses to the pacations i\n",
      "Ze eroper are  s N N unificaty the companies wegrale local failive to commercial\n",
      "nat also his bank in upline publist access under is economic to think wenk by th\n",
      "Jens  unk  encome interest resine i   N pensions corp  had dirays aid   N billio\n",
      "Men corp   wedl to by settlement of sistamels airline of heaved in a consultmal \n",
      "================================================================================\n",
      "Validation set BPC: 4.13\n",
      "Average loss at step 12100: 1.298038 learning rate: 0.100000\n",
      "Minibatch BPC: 3.71\n",
      "Validation set BPC: 4.35\n",
      "Average loss at step 12200: 1.291558 learning rate: 0.100000\n",
      "Minibatch BPC: 3.32\n",
      "Validation set BPC: 4.20\n",
      "Average loss at step 12300: 1.280431 learning rate: 0.100000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 4.08\n",
      "Average loss at step 12400: 1.291677 learning rate: 0.100000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.99\n",
      "Average loss at step 12500: 1.290436 learning rate: 0.100000\n",
      "Minibatch BPC: 3.77\n",
      "Validation set BPC: 5.00\n",
      "Average loss at step 12600: 1.286151 learning rate: 0.100000\n",
      "Minibatch BPC: 3.55\n",
      "Validation set BPC: 4.52\n",
      "Average loss at step 12700: 1.295699 learning rate: 0.100000\n",
      "Minibatch BPC: 3.70\n",
      "Validation set BPC: 4.84\n",
      "Average loss at step 12800: 1.289222 learning rate: 0.100000\n",
      "Minibatch BPC: 3.63\n",
      "Validation set BPC: 5.06\n",
      "Average loss at step 12900: 1.297018 learning rate: 0.100000\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 3.48\n",
      "Average loss at step 13000: 1.291757 learning rate: 0.100000\n",
      "Minibatch BPC: 3.68\n",
      "================================================================================\n",
      "Best post is drugs rates last few wriff help   musich he ford   solaries tomants\n",
      "x many expressial aids associates has been   N to N reasantly is a month the  un\n",
      "quN phind imprustry of that airs arguine revied to offer that on yeargo accounts\n",
      "Xed  unk  forming by  unk  when not   but gengate  unk  standard sont you  unk  \n",
      "Eet trust dacketimo were  s bloke  unk  perseal policies seving growth  unk  in \n",
      "================================================================================\n",
      "Validation set BPC: 4.05\n",
      "Average loss at step 13100: 1.280403 learning rate: 0.100000\n",
      "Minibatch BPC: 3.68\n",
      "Validation set BPC: 3.55\n",
      "Average loss at step 13200: 1.291790 learning rate: 0.100000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.73\n",
      "Average loss at step 13300: 1.289509 learning rate: 0.100000\n",
      "Minibatch BPC: 3.53\n",
      "Validation set BPC: 3.98\n",
      "Average loss at step 13400: 1.286111 learning rate: 0.100000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 4.32\n",
      "Average loss at step 13500: 1.295644 learning rate: 0.100000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.78\n",
      "Average loss at step 13600: 1.289416 learning rate: 0.100000\n",
      "Minibatch BPC: 3.71\n",
      "Validation set BPC: 4.14\n",
      "Average loss at step 13700: 1.296791 learning rate: 0.100000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 4.34\n",
      "Average loss at step 13800: 1.290594 learning rate: 0.100000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 4.56\n",
      "Average loss at step 13900: 1.281381 learning rate: 0.100000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.95\n",
      "Average loss at step 14000: 1.291202 learning rate: 0.100000\n",
      "Minibatch BPC: 3.55\n",
      "================================================================================\n",
      "ing N mrea west withwemens and exampigations and the roces wiald  s a feelday re\n",
      "Yes and lists are cana ruch to left   the morgan be n proposed its meant the deh\n",
      "Cined jaguan mr  gasheld to   its  unk  auto is prenail every operating france N\n",
      "Aed regulators from pay el which  unk  its inini sales   N billion from   N with\n",
      "ze for ford of the investment playted was of the consultally  s a peralicial dru\n",
      "================================================================================\n",
      "Validation set BPC: 3.38\n",
      "Average loss at step 14100: 1.289271 learning rate: 0.100000\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 3.28\n",
      "Average loss at step 14200: 1.285747 learning rate: 0.100000\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 3.54\n",
      "Average loss at step 14300: 1.296203 learning rate: 0.100000\n",
      "Minibatch BPC: 3.66\n",
      "Validation set BPC: 3.57\n",
      "Average loss at step 14400: 1.288303 learning rate: 0.100000\n",
      "Minibatch BPC: 3.51\n",
      "Validation set BPC: 3.04\n",
      "Average loss at step 14500: 1.297465 learning rate: 0.100000\n",
      "Minibatch BPC: 3.52\n",
      "Validation set BPC: 3.36\n",
      "Average loss at step 14600: 1.289806 learning rate: 0.100000\n",
      "Minibatch BPC: 3.66\n",
      "Validation set BPC: 3.87\n",
      "Average loss at step 14700: 1.282001 learning rate: 0.100000\n",
      "Minibatch BPC: 3.66\n",
      "Validation set BPC: 3.87\n",
      "Average loss at step 14800: 1.290307 learning rate: 0.100000\n",
      "Minibatch BPC: 3.70\n",
      "Validation set BPC: 3.60\n",
      "Average loss at step 14900: 1.289474 learning rate: 0.100000\n",
      "Minibatch BPC: 3.78\n",
      "Validation set BPC: 4.31\n",
      "Average loss at step 15000: 1.285821 learning rate: 0.010000\n",
      "Minibatch BPC: 3.68\n",
      "================================================================================\n",
      "Led down attorneys wall and yesterday purchases in pahed   they soints campubsta\n",
      "y gevench a research who common it inflations  s arking house   acquisities inve\n",
      "Ciner and securities of N the move share of sales    s managements fleking agree\n",
      "Ye special of its economy says net losects in become for ribolited N N its finas\n",
      "Cemations of the year issuinnip sussess of  unk  cham op twicus is that  unk  ol\n",
      "================================================================================\n",
      "Validation set BPC: 3.38\n",
      "Average loss at step 15100: 1.296483 learning rate: 0.010000\n",
      "Minibatch BPC: 3.63\n",
      "Validation set BPC: 3.62\n",
      "Average loss at step 15200: 1.288090 learning rate: 0.010000\n",
      "Minibatch BPC: 3.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set BPC: 3.70\n",
      "Average loss at step 15300: 1.297086 learning rate: 0.010000\n",
      "Minibatch BPC: 3.53\n",
      "Validation set BPC: 3.58\n",
      "Average loss at step 15400: 1.289887 learning rate: 0.010000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.29\n",
      "Average loss at step 15500: 1.281800 learning rate: 0.010000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.70\n",
      "Average loss at step 15600: 1.290611 learning rate: 0.010000\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 3.95\n",
      "Average loss at step 15700: 1.289164 learning rate: 0.010000\n",
      "Minibatch BPC: 3.66\n",
      "Validation set BPC: 4.03\n",
      "Average loss at step 15800: 1.285005 learning rate: 0.010000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.65\n",
      "Average loss at step 15900: 1.295645 learning rate: 0.010000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.64\n",
      "Average loss at step 16000: 1.288239 learning rate: 0.010000\n",
      "Minibatch BPC: 3.55\n",
      "================================================================================\n",
      "Oed consider up to say index british and  unk  telef  measurming the the bortoon\n",
      "ing tomest a news share off N said the c   unk  though worrse jubith and year en\n",
      "^ess has been the new modeman commote for a warrial the waicings mr   unk  syste\n",
      "Xess that union company and treat eventers was wide express samplousp no wax cou\n",
      "Fiturery slowery for unitemed said administratiqulignts and however lawrecaled a\n",
      "================================================================================\n",
      "Validation set BPC: 4.03\n",
      "Average loss at step 16100: 1.297312 learning rate: 0.010000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 4.17\n",
      "Average loss at step 16200: 1.288857 learning rate: 0.010000\n",
      "Minibatch BPC: 3.53\n",
      "Validation set BPC: 3.93\n",
      "Average loss at step 16300: 1.282442 learning rate: 0.010000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.92\n",
      "Average loss at step 16400: 1.290054 learning rate: 0.010000\n",
      "Minibatch BPC: 3.53\n",
      "Validation set BPC: 3.81\n",
      "Average loss at step 16500: 1.290110 learning rate: 0.010000\n",
      "Minibatch BPC: 3.75\n",
      "Validation set BPC: 3.46\n",
      "Average loss at step 16600: 1.284932 learning rate: 0.010000\n",
      "Minibatch BPC: 3.75\n",
      "Validation set BPC: 3.49\n",
      "Average loss at step 16700: 1.295060 learning rate: 0.010000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.63\n",
      "Average loss at step 16800: 1.288229 learning rate: 0.010000\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 3.60\n",
      "Average loss at step 16900: 1.297570 learning rate: 0.010000\n",
      "Minibatch BPC: 3.68\n",
      "Validation set BPC: 3.33\n",
      "Average loss at step 17000: 1.287986 learning rate: 0.010000\n",
      "Minibatch BPC: 3.65\n",
      "================================================================================\n",
      "lewed   while details   nortalin   they  unk  s c   unk   unk  prices   on press\n",
      "ly uso latel   another is which time each quarter reports to kinway turnets   to\n",
      "Jestes the banks to also lawreet wage peters thing on  s totes or world  s presi\n",
      "Kether  s many and i well air them market more than the former as west genere  u\n",
      "Ze that mr  while to be us an inflation of the u s  still booston at head  unk  \n",
      "================================================================================\n",
      "Validation set BPC: 3.58\n",
      "Average loss at step 17100: 1.282900 learning rate: 0.010000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 3.57\n",
      "Average loss at step 17200: 1.289831 learning rate: 0.010000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.52\n",
      "Average loss at step 17300: 1.290218 learning rate: 0.010000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 4.17\n",
      "Average loss at step 17400: 1.285332 learning rate: 0.010000\n",
      "Minibatch BPC: 3.66\n",
      "Validation set BPC: 4.01\n",
      "Average loss at step 17500: 1.294531 learning rate: 0.010000\n",
      "Minibatch BPC: 3.56\n",
      "Validation set BPC: 3.60\n",
      "Average loss at step 17600: 1.288903 learning rate: 0.010000\n",
      "Minibatch BPC: 3.68\n",
      "Validation set BPC: 3.80\n",
      "Average loss at step 17700: 1.296580 learning rate: 0.010000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.55\n",
      "Average loss at step 17800: 1.287999 learning rate: 0.010000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.67\n",
      "Average loss at step 17900: 1.283305 learning rate: 0.010000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.33\n",
      "Average loss at step 18000: 1.288968 learning rate: 0.010000\n",
      "Minibatch BPC: 3.44\n",
      "================================================================================\n",
      "jokey could gemeips has n yure   appoint to but diffortent has many beini specif\n",
      "n thoustile that rate to N N to c    at school officer   since of they british i\n",
      "eme yirt unte dominsf  s to   s  unk  an as jos one day of close the case consin\n",
      "cimully  unk  a mangateried the macharly of N times that buying blow  unk  japan\n",
      "jetines company  unk  its plant of to at bank charges   n t was  unk  least issu\n",
      "================================================================================\n",
      "Validation set BPC: 3.83\n",
      "Average loss at step 18100: 1.290488 learning rate: 0.010000\n",
      "Minibatch BPC: 3.54\n",
      "Validation set BPC: 3.58\n",
      "Average loss at step 18200: 1.285819 learning rate: 0.010000\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 3.50\n",
      "Average loss at step 18300: 1.295195 learning rate: 0.010000\n",
      "Minibatch BPC: 3.73\n",
      "Validation set BPC: 3.67\n",
      "Average loss at step 18400: 1.288302 learning rate: 0.010000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 3.32\n",
      "Average loss at step 18500: 1.296884 learning rate: 0.010000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.54\n",
      "Average loss at step 18600: 1.286760 learning rate: 0.010000\n",
      "Minibatch BPC: 3.48\n",
      "Validation set BPC: 3.66\n",
      "Average loss at step 18700: 1.284119 learning rate: 0.010000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.70\n",
      "Average loss at step 18800: 1.288222 learning rate: 0.010000\n",
      "Minibatch BPC: 3.54\n",
      "Validation set BPC: 3.98\n",
      "Average loss at step 18900: 1.290896 learning rate: 0.010000\n",
      "Minibatch BPC: 3.55\n",
      "Validation set BPC: 3.18\n",
      "Average loss at step 19000: 1.286549 learning rate: 0.010000\n",
      "Minibatch BPC: 3.70\n",
      "================================================================================\n",
      "`ed airlines nfrative   thould guodson of epuirath in avouges being  unk  delear\n",
      "Le according to at a personal whitely courding must increased co    fine the ren\n",
      "vert of the showry vieting of communy appeal currency  s convictors men economy \n",
      "`e against approved at the company sales used at union prision presines of puste\n",
      "Jes barger and eustryoukedians   finings chaerg  unk  black   minison in even wi\n",
      "================================================================================\n",
      "Validation set BPC: 4.02\n",
      "Average loss at step 19100: 1.295239 learning rate: 0.010000\n",
      "Minibatch BPC: 3.66\n",
      "Validation set BPC: 3.69\n",
      "Average loss at step 19200: 1.287764 learning rate: 0.010000\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 4.51\n",
      "Average loss at step 19300: 1.295936 learning rate: 0.010000\n",
      "Minibatch BPC: 3.46\n",
      "Validation set BPC: 3.58\n",
      "Average loss at step 19400: 1.287210 learning rate: 0.010000\n",
      "Minibatch BPC: 3.45\n",
      "Validation set BPC: 4.09\n",
      "Average loss at step 19500: 1.283873 learning rate: 0.010000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.67\n",
      "Average loss at step 19600: 1.288994 learning rate: 0.010000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.93\n",
      "Average loss at step 19700: 1.289579 learning rate: 0.010000\n",
      "Minibatch BPC: 3.50\n",
      "Validation set BPC: 3.78\n",
      "Average loss at step 19800: 1.287950 learning rate: 0.010000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.72\n",
      "Average loss at step 19900: 1.295067 learning rate: 0.010000\n",
      "Minibatch BPC: 3.76\n",
      "Validation set BPC: 3.53\n",
      "Average loss at step 20000: 1.288589 learning rate: 0.001000\n",
      "Minibatch BPC: 3.73\n",
      "================================================================================\n",
      "Qet for a whitwest profit bepinacy wrantir mass any  unk  contribution group    \n",
      "N officient new kuare to iff a news to plano inc  enoive to   N million to which\n",
      "tel   left canigigumed put for its now as at   N billion says of  unk   unk  exp\n",
      "\\ed changed wither peops   the operations clayms   are cents  f  areas of famili\n",
      "Dets heaw light say a plan   of replaching voise and caused  s national far of t\n",
      "================================================================================\n",
      "Validation set BPC: 3.86\n",
      "Average loss at step 20100: 1.294766 learning rate: 0.001000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 3.96\n",
      "Average loss at step 20200: 1.287730 learning rate: 0.001000\n",
      "Minibatch BPC: 3.54\n",
      "Validation set BPC: 3.97\n",
      "Average loss at step 20300: 1.282862 learning rate: 0.001000\n",
      "Minibatch BPC: 3.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set BPC: 4.11\n",
      "Average loss at step 20400: 1.288763 learning rate: 0.001000\n",
      "Minibatch BPC: 3.49\n",
      "Validation set BPC: 3.54\n",
      "Average loss at step 20500: 1.290526 learning rate: 0.001000\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 3.75\n",
      "Average loss at step 20600: 1.288587 learning rate: 0.001000\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 4.05\n",
      "Average loss at step 20700: 1.294140 learning rate: 0.001000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 4.12\n",
      "Average loss at step 20800: 1.288938 learning rate: 0.001000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 4.09\n",
      "Average loss at step 20900: 1.294107 learning rate: 0.001000\n",
      "Minibatch BPC: 3.50\n",
      "Validation set BPC: 3.88\n",
      "Average loss at step 21000: 1.287678 learning rate: 0.001000\n",
      "Minibatch BPC: 3.51\n",
      "================================================================================\n",
      "S ralists of high president you woulderry supported around small night have  unk\n",
      "rowendenf may negony and mr   unk  some weekly at might actimuling awnord outsid\n",
      "N  unk  the suptement their by third company day we  n intenting this moven the \n",
      "Vels crest in mining from its  unk  is auburaled of wasluses from unfer the data\n",
      "Se firm   and entition tax aways  unk  use publiny is scame of several two court\n",
      "================================================================================\n",
      "Validation set BPC: 3.94\n",
      "Average loss at step 21100: 1.282644 learning rate: 0.001000\n",
      "Minibatch BPC: 3.57\n",
      "Validation set BPC: 4.27\n",
      "Average loss at step 21200: 1.288784 learning rate: 0.001000\n",
      "Minibatch BPC: 3.57\n",
      "Validation set BPC: 3.50\n",
      "Average loss at step 21300: 1.290791 learning rate: 0.001000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.27\n",
      "Average loss at step 21400: 1.289035 learning rate: 0.001000\n",
      "Minibatch BPC: 3.63\n",
      "Validation set BPC: 2.93\n",
      "Average loss at step 21500: 1.293392 learning rate: 0.001000\n",
      "Minibatch BPC: 3.49\n",
      "Validation set BPC: 3.82\n",
      "Average loss at step 21600: 1.289740 learning rate: 0.001000\n",
      "Minibatch BPC: 3.75\n",
      "Validation set BPC: 4.18\n",
      "Average loss at step 21700: 1.294134 learning rate: 0.001000\n",
      "Minibatch BPC: 3.51\n",
      "Validation set BPC: 4.02\n",
      "Average loss at step 21800: 1.287384 learning rate: 0.001000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 4.09\n",
      "Average loss at step 21900: 1.282066 learning rate: 0.001000\n",
      "Minibatch BPC: 3.52\n",
      "Validation set BPC: 4.03\n",
      "Average loss at step 22000: 1.289098 learning rate: 0.001000\n",
      "Minibatch BPC: 3.48\n",
      "================================================================================\n",
      "fellear  unk  added N million plants is new york on viewed seven a ship mr  big \n",
      "andinators more studement of  unk  intenned financing operations wherbill  unk  \n",
      "jupth  and burger david onned a phrent has dathill as publovery to two north at \n",
      "   for has loausive case   to were you co  analysts and poblic   government to  \n",
      "zeet problemence can share cifred it would relations of white are in the stoanes\n",
      "================================================================================\n",
      "Validation set BPC: 4.19\n",
      "Average loss at step 22100: 1.290450 learning rate: 0.001000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 3.72\n",
      "Average loss at step 22200: 1.289210 learning rate: 0.001000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 3.90\n",
      "Average loss at step 22300: 1.293626 learning rate: 0.001000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 3.45\n",
      "Average loss at step 22400: 1.289673 learning rate: 0.001000\n",
      "Minibatch BPC: 3.43\n",
      "Validation set BPC: 3.37\n",
      "Average loss at step 22500: 1.294498 learning rate: 0.001000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 3.75\n",
      "Average loss at step 22600: 1.286500 learning rate: 0.001000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.79\n",
      "Average loss at step 22700: 1.282515 learning rate: 0.001000\n",
      "Minibatch BPC: 3.73\n",
      "Validation set BPC: 3.35\n",
      "Average loss at step 22800: 1.289581 learning rate: 0.001000\n",
      "Minibatch BPC: 3.50\n",
      "Validation set BPC: 4.07\n",
      "Average loss at step 22900: 1.291025 learning rate: 0.001000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.76\n",
      "Average loss at step 23000: 1.288621 learning rate: 0.001000\n",
      "Minibatch BPC: 3.66\n",
      "================================================================================\n",
      "vert awaidate if there of shapp court is now years intex s good he marketsork hi\n",
      "_ed stocks were he estems   N maybens to an todastirist  s startbeer ed  N   the\n",
      "Bed to eask declans a year be nortal enx geres    unk  application to last daien\n",
      "d   we porttolly traden there defensive two  unk  says closifies are rate of the\n",
      "n ascomp  s N yen to rid after mr  contract quarter the new second also said ref\n",
      "================================================================================\n",
      "Validation set BPC: 3.58\n",
      "Average loss at step 23100: 1.293177 learning rate: 0.001000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.61\n",
      "Average loss at step 23200: 1.291031 learning rate: 0.001000\n",
      "Minibatch BPC: 3.70\n",
      "Validation set BPC: 3.66\n",
      "Average loss at step 23300: 1.293953 learning rate: 0.001000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 2.99\n",
      "Average loss at step 23400: 1.285424 learning rate: 0.001000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 2.99\n",
      "Average loss at step 23500: 1.283496 learning rate: 0.001000\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.81\n",
      "Average loss at step 23600: 1.288374 learning rate: 0.001000\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 3.72\n",
      "Average loss at step 23700: 1.291776 learning rate: 0.001000\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 2.97\n",
      "Average loss at step 23800: 1.288823 learning rate: 0.001000\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.18\n",
      "Average loss at step 23900: 1.292949 learning rate: 0.001000\n",
      "Minibatch BPC: 3.83\n",
      "Validation set BPC: 3.43\n",
      "Average loss at step 24000: 1.291870 learning rate: 0.001000\n",
      "Minibatch BPC: 3.66\n",
      "================================================================================\n",
      "que high suled said assets over the this   madies but dealed  unk  chairman   sh\n",
      "Fess sthing  unk  and the  unk  to   N   mr  one as obligs at N  unk  manufactur\n",
      "Ke operatize their were har they toarver of markets otherces on have city has ra\n",
      "Aes next remorf  unk  drexed when the above carcor    unk  share were paten wrot\n",
      "Le is support stryt rarging that  unk   s branding   investment a fire give ligi\n",
      "================================================================================\n",
      "Validation set BPC: 3.41\n",
      "Average loss at step 24100: 1.293569 learning rate: 0.001000\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 3.52\n",
      "Average loss at step 24200: 1.285187 learning rate: 0.001000\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.45\n",
      "Average loss at step 24300: 1.283136 learning rate: 0.001000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.50\n",
      "Average loss at step 24400: 1.288647 learning rate: 0.001000\n",
      "Minibatch BPC: 3.53\n",
      "Validation set BPC: 3.27\n",
      "Average loss at step 24500: 1.292022 learning rate: 0.001000\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 3.72\n",
      "Average loss at step 24600: 1.288369 learning rate: 0.001000\n",
      "Minibatch BPC: 3.54\n",
      "Validation set BPC: 3.23\n",
      "Average loss at step 24700: 1.293121 learning rate: 0.001000\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 2.78\n",
      "Average loss at step 24800: 1.291926 learning rate: 0.001000\n",
      "Minibatch BPC: 3.72\n",
      "Validation set BPC: 2.88\n",
      "Average loss at step 24900: 1.293410 learning rate: 0.001000\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.77\n",
      "Average loss at step 25000: 1.285107 learning rate: 0.000100\n",
      "Minibatch BPC: 3.61\n",
      "================================================================================\n",
      "He securities fambere an early  unk    the stocks of feet is price have  unk  no\n",
      "Becat gain who increase create the moregumibative said bid secores   the advakin\n",
      "^ess francher koline modicals are producted francs and the started harriship com\n",
      "Dea production   the  unk  antion mr   unk  acken from prot been the spokesman s\n",
      "beel expects such as the contracts whosols that from these industrials have of t\n",
      "================================================================================\n",
      "Validation set BPC: 3.74\n",
      "Average loss at step 25100: 1.284372 learning rate: 0.000100\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.21\n",
      "Average loss at step 25200: 1.287647 learning rate: 0.000100\n",
      "Minibatch BPC: 3.56\n",
      "Validation set BPC: 3.66\n",
      "Average loss at step 25300: 1.291984 learning rate: 0.000100\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 3.22\n",
      "Average loss at step 25400: 1.288613 learning rate: 0.000100\n",
      "Minibatch BPC: 3.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set BPC: 3.34\n",
      "Average loss at step 25500: 1.292020 learning rate: 0.000100\n",
      "Minibatch BPC: 3.43\n",
      "Validation set BPC: 4.02\n",
      "Average loss at step 25600: 1.292535 learning rate: 0.000100\n",
      "Minibatch BPC: 3.60\n",
      "Validation set BPC: 4.00\n",
      "Average loss at step 25700: 1.294377 learning rate: 0.000100\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.85\n",
      "Average loss at step 25800: 1.284781 learning rate: 0.000100\n",
      "Minibatch BPC: 3.58\n",
      "Validation set BPC: 3.87\n",
      "Average loss at step 25900: 1.284301 learning rate: 0.000100\n",
      "Minibatch BPC: 3.57\n",
      "Validation set BPC: 3.42\n",
      "Average loss at step 26000: 1.287398 learning rate: 0.000100\n",
      "Minibatch BPC: 3.57\n",
      "================================================================================\n",
      "Yene   it  s  smeed tolesting of shoping demands care sales at all a said   the \n",
      "ent a first does to anyts to a pothel is poltuct in differentialds and closed  s\n",
      "N office at transhime the said at operate for being   it wirm boasdong and servi\n",
      "N   a lond chail will accunacis stock maved burn to gorbachue buy wempave as N N\n",
      "de at unturs of many  unk  to power but the twos as small export the firms at fi\n",
      "================================================================================\n",
      "Validation set BPC: 3.58\n",
      "Average loss at step 26100: 1.291748 learning rate: 0.000100\n",
      "Minibatch BPC: 3.61\n",
      "Validation set BPC: 4.27\n",
      "Average loss at step 26200: 1.288722 learning rate: 0.000100\n",
      "Minibatch BPC: 3.66\n",
      "Validation set BPC: 4.45\n",
      "Average loss at step 26300: 1.291401 learning rate: 0.000100\n",
      "Minibatch BPC: 3.68\n",
      "Validation set BPC: 4.42\n",
      "Average loss at step 26400: 1.293592 learning rate: 0.000100\n",
      "Minibatch BPC: 3.75\n",
      "Validation set BPC: 3.62\n",
      "Average loss at step 26500: 1.293569 learning rate: 0.000100\n",
      "Minibatch BPC: 3.52\n",
      "Validation set BPC: 4.07\n",
      "Average loss at step 26600: 1.285351 learning rate: 0.000100\n",
      "Minibatch BPC: 3.72\n",
      "Validation set BPC: 4.40\n",
      "Average loss at step 26700: 1.284424 learning rate: 0.000100\n",
      "Minibatch BPC: 3.73\n",
      "Validation set BPC: 3.64\n",
      "Average loss at step 26800: 1.286639 learning rate: 0.000100\n",
      "Minibatch BPC: 3.56\n",
      "Validation set BPC: 3.61\n",
      "Average loss at step 26900: 1.292141 learning rate: 0.000100\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 3.31\n",
      "Average loss at step 27000: 1.289029 learning rate: 0.000100\n",
      "Minibatch BPC: 3.59\n",
      "================================================================================\n",
      "`es big weakne to contion   the and   from chairman agree need to officials sase\n",
      "bile arm like that the by year a joint leading of francisco into the contract wa\n",
      "Ied said   report services the tever  unk  industrias jaga destillion   and not \n",
      "Ded injuniansia  s off their   three for the parences in i abletice hugo the abo\n",
      "y lenking it we N are stellenty as the slow  unk  a the payment since bond on to\n",
      "================================================================================\n",
      "Validation set BPC: 3.71\n",
      "Average loss at step 27100: 1.290299 learning rate: 0.000100\n",
      "Minibatch BPC: 3.46\n",
      "Validation set BPC: 4.42\n",
      "Average loss at step 27200: 1.294246 learning rate: 0.000100\n",
      "Minibatch BPC: 3.55\n",
      "Validation set BPC: 4.14\n",
      "Average loss at step 27300: 1.293963 learning rate: 0.000100\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 3.75\n",
      "Average loss at step 27400: 1.285452 learning rate: 0.000100\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.82\n",
      "Average loss at step 27500: 1.283965 learning rate: 0.000100\n",
      "Minibatch BPC: 3.52\n",
      "Validation set BPC: 3.73\n",
      "Average loss at step 27600: 1.287050 learning rate: 0.000100\n",
      "Minibatch BPC: 3.66\n",
      "Validation set BPC: 3.71\n",
      "Average loss at step 27700: 1.291713 learning rate: 0.000100\n",
      "Minibatch BPC: 3.62\n",
      "Validation set BPC: 3.63\n",
      "Average loss at step 27800: 1.289489 learning rate: 0.000100\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.81\n",
      "Average loss at step 27900: 1.290031 learning rate: 0.000100\n",
      "Minibatch BPC: 3.56\n",
      "Validation set BPC: 3.60\n",
      "Average loss at step 28000: 1.294444 learning rate: 0.000100\n",
      "Minibatch BPC: 3.79\n",
      "================================================================================\n",
      "Cer relie earlier   N billion with an  s clus by a periegam for us numbeged a re\n",
      "Lecay it loan   underwaibly according the offices unil effecting onlydord reques\n",
      "Led  unk  have maheful resen buy unis  s not is sell on the farm and the   N bil\n",
      "or other they long term  unk  rose N N by seet markets trade opten even during w\n",
      "Pet mr   s the with  unk  the rayore we quicklong tool  s tribleror he   but for\n",
      "================================================================================\n",
      "Validation set BPC: 3.42\n",
      "Average loss at step 28100: 1.294147 learning rate: 0.000100\n",
      "Minibatch BPC: 3.71\n",
      "Validation set BPC: 3.49\n",
      "Average loss at step 28200: 1.285558 learning rate: 0.000100\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 3.70\n",
      "Average loss at step 28300: 1.283774 learning rate: 0.000100\n",
      "Minibatch BPC: 3.67\n",
      "Validation set BPC: 4.08\n",
      "Average loss at step 28400: 1.287781 learning rate: 0.000100\n",
      "Minibatch BPC: 3.81\n",
      "Validation set BPC: 3.91\n",
      "Average loss at step 28500: 1.289822 learning rate: 0.000100\n",
      "Minibatch BPC: 3.54\n",
      "Validation set BPC: 3.51\n",
      "Average loss at step 28600: 1.290078 learning rate: 0.000100\n",
      "Minibatch BPC: 3.51\n",
      "Validation set BPC: 3.72\n",
      "Average loss at step 28700: 1.289064 learning rate: 0.000100\n",
      "Minibatch BPC: 3.43\n",
      "Validation set BPC: 3.79\n",
      "Average loss at step 28800: 1.296093 learning rate: 0.000100\n",
      "Minibatch BPC: 3.74\n",
      "Validation set BPC: 3.80\n",
      "Average loss at step 28900: 1.294295 learning rate: 0.000100\n",
      "Minibatch BPC: 3.59\n",
      "Validation set BPC: 3.62\n",
      "Average loss at step 29000: 1.284947 learning rate: 0.000100\n",
      "Minibatch BPC: 3.61\n",
      "================================================================================\n",
      "Pe netherd one trial care on penchant   N denaid street vay the sifferrations  u\n",
      "Oed stoangert to according to encusier specuring high histay legper  s three wer\n",
      "ng management hamperions a peaked that in contrasst to be investorly  unk  for a\n",
      "Ked N alvan   has small futurized group and the ucal gial bikely in any when the\n",
      "Qens that amediquits tonck of a savings     costs workers inside and aljeme as a\n",
      "================================================================================\n",
      "Validation set BPC: 3.83\n",
      "Average loss at step 29100: 1.284046 learning rate: 0.000100\n",
      "Minibatch BPC: 3.65\n",
      "Validation set BPC: 3.53\n",
      "Average loss at step 29200: 1.288114 learning rate: 0.000100\n",
      "Minibatch BPC: 3.70\n",
      "Validation set BPC: 3.84\n",
      "Average loss at step 29300: 1.289048 learning rate: 0.000100\n",
      "Minibatch BPC: 3.75\n",
      "Validation set BPC: 3.59\n",
      "Average loss at step 29400: 1.290592 learning rate: 0.000100\n",
      "Minibatch BPC: 3.64\n",
      "Validation set BPC: 3.60\n",
      "Average loss at step 29500: 1.288714 learning rate: 0.000100\n",
      "Minibatch BPC: 3.64\n"
     ]
    }
   ],
   "source": [
    "num_steps = 70001\n",
    "summary_frequency = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  mean_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batches = train_batches.next()\n",
    "    feed_dict = dict()\n",
    "    for i in range(num_unrollings + 1):\n",
    "      feed_dict[train_data[i]] = batches[i]\n",
    "    _, l, predictions, lr = session.run(\n",
    "      [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "    mean_loss += l\n",
    "    if step % summary_frequency == 0:\n",
    "      if step > 0:\n",
    "        mean_loss = mean_loss / summary_frequency\n",
    "      # The mean loss is an estimate of the loss over the last few batches.\n",
    "      print(\n",
    "        'Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
    "      mean_loss = 0\n",
    "      labels = np.concatenate(list(batches)[1:])\n",
    "      print('Minibatch BPC: %.2f' % float(\n",
    "        np.exp(logprob(predictions, labels))))\n",
    "      if step % (summary_frequency * 10) == 0:\n",
    "        # Generate some samples.\n",
    "        print('=' * 80)\n",
    "        for _ in range(5):\n",
    "          feed = sample(random_distribution())\n",
    "          sentence = characters(feed)[0]\n",
    "          reset_sample_state.run()\n",
    "          for _ in range(79):\n",
    "            prediction = sample_prediction.eval({sample_input: feed})\n",
    "            feed = sample(prediction)\n",
    "            sentence += characters(feed)[0]\n",
    "          print(sentence)\n",
    "        print('=' * 80)\n",
    "      # Measure validation set perplexity.\n",
    "      reset_sample_state.run()\n",
    "      valid_logprob = 0\n",
    "      for _ in range(1000): #valid_size):\n",
    "        b = valid_batches.next()\n",
    "        predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "        valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
    "      print('Validation set BPC: %.2f' % float(np.exp(\n",
    "        valid_logprob / 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
