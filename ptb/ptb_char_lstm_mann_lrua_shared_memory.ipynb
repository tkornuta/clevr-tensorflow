{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import tarfile\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import shutil \n",
    "import random\n",
    "\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "# Dirs - must be absolute paths!\n",
    "LOG_DIR = '/tmp/tf/ptb_char_lstm_mann_lrua_shared_memory/h16b1s1lru3_no_trunk/'\n",
    "# Local dir where PTB files will be stored.\n",
    "PTB_DIR = '/home/tkornuta/data/ptb/'\n",
    "\n",
    "# Filenames.\n",
    "TRAIN = \"ptb.train.txt\"\n",
    "VALID = \"ptb.valid.txt\"\n",
    "TEST = \"ptb.test.txt\"\n",
    "\n",
    "# Size of the hidden state\n",
    "HIDDEN_SIZE = 4\n",
    "\n",
    "# Size of batch\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Length of sequence (=  number of units of controller (recurrent layer))\n",
    "SEQ_LENGTH = 1\n",
    "\n",
    "#### MANN-related parameters.\n",
    "# Size of the local memory of each cell.\n",
    "MEMORY_SLOTS = 10\n",
    "\n",
    "# Number of smallest elements - used in LRUA scheme.\n",
    "N_SMALLEST = 1\n",
    "\n",
    "# \"Update weight decay\".\n",
    "GAMMA = 0.95\n",
    "\n",
    "# Eps for normalization in visualization\n",
    "EPS = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified /home/tkornuta/data/ptb/simple-examples.tgz ( 34869662 )\n"
     ]
    }
   ],
   "source": [
    "def maybe_download_ptb(path, \n",
    "                       filename='simple-examples.tgz', \n",
    "                       url='http://www.fit.vutbr.cz/~imikolov/rnnlm/', \n",
    "                       expected_bytes =34869662):\n",
    "  # Eventually create the PTB dir.\n",
    "  if not tf.gfile.Exists(path):\n",
    "    tf.gfile.MakeDirs(path)\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  _filename = path+filename\n",
    "  if not os.path.exists(_filename):\n",
    "    print('Downloading %s...' % filename)\n",
    "    _filename, _ = urlretrieve(url+filename, _filename)\n",
    "  statinfo = os.stat(_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', (_filename), '(', statinfo.st_size, ')')\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + _filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download_ptb(PTB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check/maybe download PTB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract dataset-related files from the PTB archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_ptb(path, filename='simple-examples.tgz', files=[\"ptb.train.txt\", \"ptb.valid.txt\", \"ptb.test.txt\", \n",
    "                                       \"ptb.char.train.txt\", \"ptb.char.valid.txt\", \"ptb.char.test.txt\"]):\n",
    "    \"\"\"Extracts files from PTB archive.\"\"\"\n",
    "    # Extract\n",
    "    tar = tarfile.open(path+filename)\n",
    "    tar.extractall(path)\n",
    "    tar.close()\n",
    "    # Copy files\n",
    "    for file in files:\n",
    "        shutil.copyfile(PTB_DIR+\"simple-examples/data/\"+file, PTB_DIR+file)\n",
    "    # Delete directory\n",
    "    shutil.rmtree(PTB_DIR+\"simple-examples/\")        \n",
    "\n",
    "extract_ptb(PTB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train, valid and test texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5101618  aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memote\n",
      "399782  consumers may want to move their telephones a little closer to \n",
      "449945  no it was n't black monday \n",
      " but while the new york stock excha\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename, path):\n",
    "    with open(path+filename, 'r') as myfile:\n",
    "        data=myfile.read()# .replace('\\n', '')\n",
    "        return data\n",
    "\n",
    "train_text = read_data(TRAIN, PTB_DIR)\n",
    "train_size=len(train_text)\n",
    "print(train_size, train_text[:100])\n",
    "\n",
    "valid_text = read_data(VALID, PTB_DIR)\n",
    "valid_size=len(valid_text)\n",
    "print(valid_size, valid_text[:64])\n",
    "\n",
    "test_text = read_data(TEST, PTB_DIR)\n",
    "test_size=len(test_text)\n",
    "print(test_size, test_text[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to map characters to vocabulary IDs and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size =  59\n",
      "65\n",
      "33 1 58 26 0 0\n",
      "a A\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 59 # [A-Z] + [a-z] + ' ' +few 'in between; + punctuation\n",
    "first_letter = ord(string.ascii_uppercase[0]) # ascii_uppercase before lowercase! \n",
    "print(\"vocabulary size = \", vocabulary_size)\n",
    "print(first_letter)\n",
    "\n",
    "def char2id(char):\n",
    "  \"\"\" Converts char to id (int) with one-hot encoding handling of unexpected characters\"\"\"\n",
    "  if char in string.ascii_letters:# or char in string.punctuation or char in string.digits:\n",
    "    return ord(char) - first_letter + 1\n",
    "  elif char == ' ':\n",
    "    return 0\n",
    "  else:\n",
    "    # print('Unexpected character: %s' % char)\n",
    "    return 0\n",
    "  \n",
    "def id2char(dictid):\n",
    "  \"\"\" Converts single id (int) to character\"\"\"\n",
    "  if dictid > 0:\n",
    "    return chr(dictid + first_letter - 1)\n",
    "  else:\n",
    "    return ' '\n",
    "\n",
    "def characters(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  characters back into its (most likely) character representation.\"\"\"\n",
    "  return [id2char(c) for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "  \"\"\"Convert a sequence of batches back into their (most likely) string\n",
    "  representation.\"\"\"\n",
    "  s = [''] * batches[0].shape[0]\n",
    "  for b in batches:\n",
    "    s = [''.join(x) for x in zip(s, characters(b))]\n",
    "  return s\n",
    "\n",
    "#print(len(string.punctuation))\n",
    "#for i in string.ascii_letters:\n",
    "#    print (i, char2id(i))\n",
    "\n",
    "\n",
    "print(char2id('a'), char2id('A'), char2id('z'), char2id('Z'), char2id(' '), char2id('Ã¯'))\n",
    "print(id2char(char2id('a')), id2char(char2id('A')))\n",
    "#print(id2char(65), id2char(33), id2char(90), id2char(58), id2char(0))\n",
    "#bankno\n",
    "sample = np.zeros(shape=(1, vocabulary_size), dtype=np.float)\n",
    "sample[0, char2id(' ')] = 1.0\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper class for batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, seq_length, vocab_size):\n",
    "    \"\"\"\n",
    "    Initializes the batch generator object. Stores the variables and first \"letter batch\".\n",
    "    text is text to be processed\n",
    "    batch_size is size of batch (number of samples)\n",
    "    seq_length represents the length of sequence\n",
    "    vocab_size is number of words in vocabulary (assumes one-hot encoding)\n",
    "    \"\"\"\n",
    "    # Store input parameters.\n",
    "    self._text = text\n",
    "    self._text_size = len(text)\n",
    "    self._batch_size = batch_size\n",
    "    self._seq_length = seq_length\n",
    "    self._vocab_size = vocab_size\n",
    "    # Divide text into segments depending on number of batches, each segment determines a cursor position for a batch.\n",
    "    segment = self._text_size // batch_size\n",
    "    # Set initial cursor position.\n",
    "    self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "    # Store first \"letter batch\".\n",
    "    self._last_letter_batch = self._next_letter_batch()\n",
    "  \n",
    "  def _next_letter_batch(self):\n",
    "    \"\"\"\n",
    "    Returns a batch containing of encoded single letters depending on the current batch \n",
    "    cursor positions in the data.\n",
    "    Returned \"letter batch\" is of size batch_size x vocab_size\n",
    "    \"\"\"\n",
    "    letter_batch = np.zeros(shape=(self._batch_size, self._vocab_size), dtype=np.float)\n",
    "    # Iterate through \"samples\"\n",
    "    for b in range(self._batch_size):\n",
    "      # Set 1 in position pointed out by one-hot char encoding.\n",
    "      letter_batch[b, char2id(self._text[self._cursor[b]])] = 1.0\n",
    "      self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "    return letter_batch\n",
    "  \n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "    the last batch of the previous array, followed by num_unrollings new ones.\n",
    "    \"\"\"\n",
    "    # First add last letter from previous batch (the \"additional one\").\n",
    "    batches = [self._last_letter_batch]\n",
    "    for step in range(self._seq_length):\n",
    "      batches.append(self._next_letter_batch())\n",
    "    # Store last \"letter batch\" for next batch.\n",
    "    self._last_letter_batch = batches[-1]\n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(1, 59)\n"
     ]
    }
   ],
   "source": [
    "# Trick - override first 10 chars\n",
    "#list1 = list(train_text)\n",
    "#for i in range(2):\n",
    "#    list1[i] = 'z'\n",
    "#train_text = ''.join(list1)\n",
    "#print(\"Train set =\", train_text[0:100])\n",
    "\n",
    "# Create objects for training, validation and testing batch generation.\n",
    "train_batches = BatchGenerator(train_text, BATCH_SIZE, SEQ_LENGTH, vocabulary_size)\n",
    "\n",
    "# Get first training batch.\n",
    "batch = train_batches.next()\n",
    "print(len(batch))\n",
    "print(batch[0].shape)\n",
    "#print(\"Batch = \", batch)\n",
    "#print(batches2string(batch))\n",
    "#print(\"batch len = num of enrollings\",len(batch))\n",
    "#for i in range(num_unrollings):\n",
    "#    print(\"i = \", i, \"letter=\", batches2string(batch)[0][i][0], \"bits = \", batch[i][0])\n",
    "\n",
    "\n",
    "# For validation  - process the whole text as one big batch.\n",
    "VALID_BATCH_SIZE = int(np.floor(valid_size/SEQ_LENGTH))\n",
    "valid_batches = BatchGenerator(valid_text, VALID_BATCH_SIZE, SEQ_LENGTH, vocabulary_size)\n",
    "valid_batch = valid_batches.next()\n",
    "#print (VALID_BATCH_SIZE)\n",
    "#print(len(valid_batch))\n",
    "#print(valid_batch[0].shape)\n",
    "\n",
    "# For texting  - process the whole text as one big batch.\n",
    "TEST_BATCH_SIZE = int(np.floor(test_size/SEQ_LENGTH))\n",
    "test_batches = BatchGenerator(test_text, TEST_BATCH_SIZE, SEQ_LENGTH, vocabulary_size)\n",
    "# Get single batch! \n",
    "#test_batch = test_batches.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell definition OK\n"
     ]
    }
   ],
   "source": [
    "# Definition of the cell computation.\n",
    "def controller_cell(input_, # input x\n",
    "                    memory_input_, # read vector from the memory returned by previous cell\n",
    "                    prev_output_, # output of the previous cell\n",
    "                    prev_cell_state_, # previous cell state\n",
    "                    prev_read_weights_batch_, # read weights from previous time state (t-1) \n",
    "                    prev_update_weights_batch_, # update weights from previous time state (t-1)\n",
    "                    name_):\n",
    "    \"\"\"Create a controller with local memory cell\"\"\"\n",
    "    \"\"\"First dimensions of each of the computational nodes below is \"derrived\" from BATCH_SIZE\"\"\"\n",
    "    with tf.name_scope(name_):\n",
    "\n",
    "        with tf.name_scope(\"LSTM\"):\n",
    "            # LSTM cell equations according to Christopher Olah blog.\n",
    "            # colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "            # Concatenate intyp x with h_prev (\"prev output\") TODO: and memory.\n",
    "            i_h_m = tf.concat([input_, prev_output_, memory_input_], 1)\n",
    "\n",
    "            # Calculate forget, input and output gate activations.\n",
    "            forget_gate = tf.sigmoid(tf.matmul(i_h_m, Wf) + bf, name=\"Forget_gate\")\n",
    "            input_gate = tf.sigmoid(tf.matmul(i_h_m, Wi) + bi, name=\"Input_gate\")\n",
    "            output_gate = tf.sigmoid(tf.matmul(i_h_m, Wo) + bo, name=\"Output_gate\")\n",
    "\n",
    "            # Update of the cell state C~.\n",
    "            cell_update = tf.tanh(tf.matmul(i_h_m, Wc) + bc, name=\"Cell_update\")\n",
    "            # New cell state C.\n",
    "            cell_state = tf.add(forget_gate * prev_cell_state_, input_gate * cell_update, name = \"Cell_state\")\n",
    "            # Calculate h - \"output\".\n",
    "            cell_output = output_gate * tf.tanh(cell_state)\n",
    "            \n",
    "        with tf.name_scope(\"Keys\"):\n",
    "            # Calculate keys - read and add.\n",
    "            k_t = tf.tanh(tf.matmul(cell_output, W_key) + b_key) # (batch_size, nb_reads, memory_size[1])\n",
    "            #a_t = tf.tanh(tf.matmul(cell_output, W_add) + b_add) # (batch_size, nb_reads, memory_size[1])\n",
    "            alpha = tf.sigmoid(tf.matmul(cell_output, W_alpha) + b_alpha) # (batch_size, nb_reads, 1)\n",
    "\n",
    "            # Add histograms to TensorBoard.\n",
    "            k_t_hist = tf.summary.histogram(\"k_t\", k_t)\n",
    "            #a_t_hist = tf.summary.histogram(\"a_t\", a_t)\n",
    "            \n",
    "        # Read from the memory.\n",
    "        with tf.name_scope(\"Read_head\"):\n",
    "            \n",
    "            # Normalize batch.\n",
    "            norm_batch = tf.nn.l2_normalize(k_t,1)\n",
    "            # Normalize memory.\n",
    "            norm_memory = tf.nn.l2_normalize(memory,0)\n",
    "            # Calculate cosine similarity.\n",
    "            similarity_batch = tf.matmul(norm_batch, norm_memory)\n",
    "            # Calculate read weights based on similarity.\n",
    "            read_weights_batch = tf.nn.softmax(similarity_batch)\n",
    "\n",
    "            # Add to list returned as \"previous read weights\".\n",
    "            read_weights_seq_batch.append(read_weights_batch)\n",
    "            \n",
    "            # Add histograms to TensorBoard.\n",
    "            norm_batch_hist = tf.summary.histogram(\"norm_batch\", norm_batch)\n",
    "            norm_batch_hist = tf.summary.histogram(\"norm_batch\", norm_batch)\n",
    "            norm_memory_hist = tf.summary.histogram(\"norm_memory\", norm_memory)\n",
    "            similarity_batch_hist = tf.summary.histogram(\"cosine_similarity_batch\", similarity_batch)\n",
    "            read_weights_batch_hist = tf.summary.histogram(\"read_weights_batch\", read_weights_batch)\n",
    "\n",
    "            # Create hot-cold visualization of read head (red=positive/blue=negative)\n",
    "            zeros = tf.zeros_like(read_weights_batch) # batch_size (VARYING) x MEMORY_SLOTS\n",
    "            # Get negative values only.\n",
    "            neg = tf.less(read_weights_batch, zeros)\n",
    "            blue = tf.multiply(tf.cast(neg, tf.float32), read_weights_batch)\n",
    "            min_blue = tf.reduce_min(read_weights_batch, axis=1) + EPS\n",
    "            norm_blue = 255.0 * blue/min_blue\n",
    "            # Get positive values only.\n",
    "            pos = tf.greater(read_weights_batch, zeros)\n",
    "            red = tf.multiply(tf.cast(pos, tf.float32), read_weights_batch)\n",
    "            max_red = tf.reduce_max(read_weights_batch, axis=1) + EPS\n",
    "            norm_red = 255.0 * red/max_red\n",
    "            # Stack them into three channel image with hot-cold values.\n",
    "            rgb_read_weights_batch = tf.stack([norm_red, zeros, norm_blue], axis=2)\n",
    "            rgb_read_weights_batch_reshaped = tf.reshape(rgb_read_weights_batch, [1, -1, MEMORY_SLOTS, 3])\n",
    "\n",
    "            # Visualize read weights as image.\n",
    "            rgb_read_weights_batch_img = tf.summary.image(\"read_weights_batch_reshaped\", rgb_read_weights_batch_reshaped)\n",
    "            \n",
    "        \n",
    "        with tf.name_scope(\"Memory_output\"):\n",
    "            # Calcualte read vector.\n",
    "            memory_output_batch = tf.tensordot(read_weights_batch, tf.transpose(memory), axes=1, name=\"Memory_output_batch_r\")   \n",
    "            # Add histograms to TensorBoard.\n",
    "            memory_output_batch_hist = tf.summary.histogram(\"memory_output_batch\", memory_output_batch)\n",
    "\n",
    "        with tf.name_scope(\"Write_head\"):\n",
    "            # \"Truncation scheme to update the least-used positions\".\n",
    "            # First, find (size-n) top elements (in each \"batch sample\"/head separatelly).\n",
    "            top = tf.nn.top_k(-prev_update_weights_batch_, N_SMALLEST)\n",
    "            # To get boolean True/False values, you can first get the k-th value and then use tf.greater_equal:\n",
    "            kth = tf.reduce_min(top.values, axis=1, keep_dims=True)\n",
    "            top2 = tf.greater_equal(-prev_update_weights_batch_, kth)\n",
    "            # And finally - cast it to n smallest elements.\n",
    "            prev_smallest_lru_weights = tf.cast(top2, tf.float32)\n",
    "\n",
    "            #write_weights_seq_batch.append(prev_smallest_lru_weights)\n",
    "            write_weights_batch = tf.add(tf.sigmoid(alpha) * prev_read_weights_batch_,\n",
    "                                   (1.0 - tf.sigmoid(alpha)) * prev_smallest_lru_weights,\n",
    "                                   name=\"Write_weights_ww\")\n",
    "\n",
    "            # Add histograms to TensorBoard.\n",
    "            smallest_lru_weight_batch_hist = tf.summary.histogram(\"smallest_lru_weight_batch\", prev_smallest_lru_weights)\n",
    "            write_weights_batch_hist = tf.summary.histogram(\"write_weights_batch\", write_weights_batch)\n",
    "\n",
    "        with tf.name_scope(\"Update_head\"):\n",
    "            # This relies on prev. weights and will be used in fact in the NEXT step.\n",
    "            update_weights_batch = tf.add(GAMMA * prev_update_weights_batch_,\n",
    "                                            read_weights_batch + write_weights_batch,\n",
    "                                            name=\"Update_weights_uw\")\n",
    "            \n",
    "            # Add to list returned as \"previous update weights\".\n",
    "            update_weights_seq_batch.append(update_weights_batch)\n",
    "            # Add histograms to TensorBoard.\n",
    "            update_weights_batch_hist = tf.summary.histogram(\"update_weights_batch\", update_weights_batch)\n",
    "\n",
    "            \n",
    "    with tf.name_scope(\"Memory_update\"):\n",
    "        # Perform single update for each sequence/batch.\n",
    "        memory_update_batch = tf.tensordot(tf.transpose(k_t), write_weights_batch, axes=1)\n",
    "        # Add dependendency control - first prediction?\n",
    "        #with tf.control_dependencies([prediction_batch]):\n",
    "        # Update the memory\n",
    "        memory_update_op = memory.assign(memory + memory_update_batch)\n",
    "        \n",
    "        # Create hot-cold visualization of memory (red=positive/blue=negative)\n",
    "        zeros = tf.zeros([HIDDEN_SIZE, MEMORY_SLOTS])\n",
    "        # Get negative values only.\n",
    "        neg = tf.less(memory, zeros)\n",
    "        blue = tf.multiply(tf.cast(neg, tf.float32), memory)\n",
    "        min_blue = tf.reduce_min(memory, axis=0) + EPS\n",
    "        norm_blue = 255.0 * blue/min_blue\n",
    "        # Get positive values only.\n",
    "        pos = tf.greater(memory, zeros)\n",
    "        red = tf.multiply(tf.cast(pos, tf.float32), memory)\n",
    "        max_red = tf.reduce_max(memory, axis=0) + EPS\n",
    "        norm_red = 255.0 * red/max_red\n",
    "        # Stack them into three channel image with hot-cold values.\n",
    "        rgb_memory = tf.stack([norm_red, zeros, norm_blue], axis=2)\n",
    "        rgb_memory_reshaped = tf.reshape(rgb_memory, [1, HIDDEN_SIZE, MEMORY_SLOTS, 3])\n",
    "        \n",
    "        # Memory \"truncation\".\n",
    "        #memory_trunk_op = memory.assign(tf.tanh(memory))\n",
    "        #memory_trunk_vis = tf.reshape(memory, [1,HIDDEN_SIZE, MEMORY_SLOTS,1])\n",
    "\n",
    "        # Add histograms to TensorBoard.\n",
    "        memory_update_batch_hist = tf.summary.histogram(\"memory_update_batch\", memory_update_batch)\n",
    "        memory_hist = tf.summary.histogram(\"memory_before_truncation\", memory_update_op)\n",
    "        #memory_trunk_hist = tf.summary.histogram(\"memory_after_truncation\", memory_trunk_op)\n",
    "        # Visualize memory as image.\n",
    "        memory_updated_img = tf.summary.image(\"memory_before_truncation\", rgb_memory_reshaped)\n",
    "        #memory_trunk_img = tf.summary.image(\"memory_after_truncation\", memory_trunk_vis)\n",
    "\n",
    "        \n",
    "    return memory_output_batch, cell_output, cell_state\n",
    "\n",
    "print(\"Cell definition OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Definition of tensor graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_buffers shape = (?, 59)\n",
      "Seq length  = 1\n",
      "Batch shape = (?, 59)\n",
      "Graph definition OK\n"
     ]
    }
   ],
   "source": [
    "# Reset graph - just in case.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Memory.\n",
    "memory = tf.Variable(tf.truncated_normal(shape=[HIDDEN_SIZE, MEMORY_SLOTS]), trainable=False, name=\"Memory_M\")\n",
    "# Latest vs LRU ratio.\n",
    "#alpha = tf.Variable(tf.truncated_normal(shape=[1]), name=\"Alpha\")\n",
    "\n",
    "# 0. Previous variables.\n",
    "with tf.name_scope(\"Previous_variables\"):\n",
    "    # Create \"read vectors\" (in fact batch).\n",
    "    read_vectors_seq_batch = list()    \n",
    "    for i_seq in range(SEQ_LENGTH):\n",
    "        read_vectors_seq_batch.append(tf.placeholder(tf.float32, shape=[None, HIDDEN_SIZE], name=\"Read_vector_r\"))    \n",
    "\n",
    "    # Placeholders for previous weights.\n",
    "    prev_read_weights_seq_batch = list()    \n",
    "    prev_update_weights_seq_batch = list()    \n",
    "    for i_seq in range(SEQ_LENGTH):\n",
    "        prev_read_weights_seq_batch.append(tf.placeholder(tf.float32, shape=[None, MEMORY_SLOTS], name=\"Prev_rw\"))\n",
    "        prev_update_weights_seq_batch.append(tf.placeholder(tf.float32, shape=[None, MEMORY_SLOTS], name=\"Prev_uw\"))\n",
    "\n",
    "# 1. Placeholders for inputs.\n",
    "with tf.name_scope(\"Input_data\"):\n",
    "    # Define input data buffers.\n",
    "    data_buffers = list()\n",
    "    for _ in range(SEQ_LENGTH + 1):\n",
    "        # Collect placeholders for inputs/labels: Batch x Vocab size.\n",
    "        data_buffers.append(tf.placeholder(tf.float32, shape=[None, vocabulary_size], name=\"data_buffers\"))\n",
    "    print (\"data_buffers shape =\", data_buffers[0].shape)\n",
    "\n",
    "    # Sequence of batches.\n",
    "    input_seq_batch = data_buffers[:SEQ_LENGTH]\n",
    "    print (\"Seq length  =\", len(input_seq_batch))\n",
    "    print (\"Batch shape =\", input_seq_batch[0].shape)\n",
    "\n",
    "    # Labels are pointing to the same placeholders!\n",
    "    # Labels are inputs shifted by one time step.\n",
    "    labels_seq_batch = data_buffers[1:]  \n",
    "    # Concatenate targets into 2D tensor.\n",
    "    target_batch = tf.concat(labels_seq_batch, 0)\n",
    "\n",
    "    # Add histograms to TensorBoard.\n",
    "    input_seq_batch_hist = tf.summary.histogram(\"input_seq_batch\", input_seq_batch)\n",
    "\n",
    "# 2. Unrolled controller ops.\n",
    "with tf.name_scope(\"Controller\"):\n",
    "    # Define parameters:\n",
    "    # Input gate: input, previous output, and bias.\n",
    "    Wf = tf.Variable(tf.truncated_normal([vocabulary_size+2*HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"Wf\")\n",
    "    bf = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"bf\")\n",
    "\n",
    "    # Forget gate: input, previous output, and bias.\n",
    "    Wi = tf.Variable(tf.truncated_normal([vocabulary_size+2*HIDDEN_SIZE,HIDDEN_SIZE], -0.1, 0.1), name=\"Wi\")\n",
    "    bi = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"bi\")\n",
    "\n",
    "    # Memory cell: input, state and bias.                             \n",
    "    Wc = tf.Variable(tf.truncated_normal([vocabulary_size+2*HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"Wc\")\n",
    "    bc = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"bc\")\n",
    "\n",
    "    # Output gate: input, previous output, and bias.\n",
    "    Wo = tf.Variable(tf.truncated_normal([vocabulary_size+2*HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"Wo\")\n",
    "    bo = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"bo\")\n",
    "\n",
    "    # Read key.\n",
    "    W_key = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"W_key\")\n",
    "    b_key = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"b_key\")\n",
    "    \n",
    "    # Add key.\n",
    "    #W_add = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"W_add\")\n",
    "    #b_add = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"b_add\")\n",
    "    \n",
    "    # Alpha - used in Latest vs LRU ratio.\n",
    "    W_alpha = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, 1], -0.1, 0.1), name=\"W_alpha\")\n",
    "    b_alpha = tf.Variable(tf.zeros([1, 1]), name=\"b_alpha\")\n",
    "    \n",
    "    # Placeholders for \"zero\" (the oldest) state and output: Batch x Hidden size.\n",
    "    init_controller_output = tf.placeholder(tf.float32, shape=[None, HIDDEN_SIZE], name=\"init_controller_output\")\n",
    "    init_controller_state = tf.placeholder(tf.float32, shape=[None, HIDDEN_SIZE], name=\"init_controller_state\")\n",
    "    # Placeholder for \"zero\" memory read: Batch X Hidden (TODO: memory?) size.\n",
    "    init_memory_output = tf.placeholder(tf.float32, shape=[None, HIDDEN_SIZE], name=\"init_memory_read\")\n",
    "\n",
    "    # Unrolled LSTM.\n",
    "    # Build outpus of size SEQ_LENGTH.\n",
    "    controller_outputs_batch_seq = list()\n",
    "    memory_outputs_batch_seq = list()\n",
    "    # Two lists that will be \"returned\" and later passed as previous states. \n",
    "    read_weights_seq_batch = list()  \n",
    "    update_weights_seq_batch = list()  \n",
    "    \n",
    "    # \"Link\" oldest statte and output to placeholders.\n",
    "    controller_output = init_controller_output\n",
    "    controller_state = init_controller_state\n",
    "    memory_output = init_memory_output\n",
    "    # For every buffer in input sequence batch buffers...\n",
    "    for i in range(SEQ_LENGTH):\n",
    "        # ... add cell...     \n",
    "        memory_output, controller_output, controller_state = controller_cell(\n",
    "            input_seq_batch[i], \n",
    "            memory_output, \n",
    "            controller_output, \n",
    "            controller_state, \n",
    "            prev_read_weights_seq_batch[i],\n",
    "            prev_update_weights_seq_batch[i],\n",
    "            \"cell_\"+str(i))\n",
    "        # .. add controller buffer to outputs...\n",
    "        controller_outputs_batch_seq.append(controller_output)\n",
    "        memory_outputs_batch_seq.append(memory_output)\n",
    "        # .. and set memory input of (i+1) cell to i-th read vector buffer.\n",
    "        #memory_input = read_vectors_seq_batch[i]\n",
    "        \n",
    "    # Add histograms to TensorBoard.\n",
    "    controller_outputs_batch_seq_hist = tf.summary.histogram(\"controller_outputs_batch_seq\", controller_outputs_batch_seq)\n",
    "    memory_outputs_batch_seq_hist = tf.summary.histogram(\"memory_outputs_batch_seq\", memory_outputs_batch_seq)\n",
    "    memory_hist = tf.summary.histogram(\"memory\", memory)\n",
    "    read_weights_seq_batch_hist = tf.summary.histogram(\"read_weights_seq_batch\", read_weights_seq_batch)\n",
    "    update_weights_seq_batch_hist = tf.summary.histogram(\"update_weights_seq_batch\", update_weights_seq_batch)\n",
    "\n",
    "# 3. Output ops.\n",
    "with tf.name_scope(\"Output\"):\n",
    "    # Concatenate controller hidden state with the read vector.\n",
    "    coutput_rvector_seq_batch = list()    \n",
    "    for i_seq in range(SEQ_LENGTH):\n",
    "        coutput_rvector_seq_batch.append(tf.concat([controller_outputs_batch_seq[i_seq], \n",
    "                                                 memory_outputs_batch_seq[i_seq]], 1, name=\"Concat_coutput_rvector\"))    \n",
    "    # Add histograms to TensorBoard.\n",
    "    coutput_rvector_seq_batch_hist = tf.summary.histogram(\"coutput_rvector_seq_batch\", coutput_rvector_seq_batch)\n",
    "\n",
    "    output_batch = tf.concat(controller_outputs_batch_seq, 0) \n",
    "    #output_batch = tf.concat(controller_outputs_batch_seq, 0)\n",
    " \n",
    "    # Output layer weights and biases.\n",
    "    w = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, vocabulary_size], -0.1, 0.1), name=\"w\")\n",
    "    b = tf.Variable(tf.zeros([vocabulary_size]), name=\"b\")\n",
    "\n",
    "    # Logits.\n",
    "    logits_batch = tf.nn.xw_plus_b(output_batch, w, b, name = \"Final_FC\")\n",
    "    # Add fully connected softmax layer on top - predictions.\n",
    "    prediction_batch = tf.nn.softmax(logits_batch)\n",
    "    \n",
    "# 4. Loss ops.\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    # Loss function(s) - one for every output generated by every LSTM cell.\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=target_batch, logits=logits_batch))\n",
    "    # Add loss summary.\n",
    "    loss_summary = tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "# 5. Training ops.  \n",
    "with tf.name_scope(\"Optimization\"):\n",
    "    # Learning rate decay.\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, 5000, 0.9, staircase=True)\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "    # Gradient clipping.\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n",
    "\n",
    "# Merge all summaries.\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "\n",
    "print(\"Graph definition OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed_dict definition OK\n"
     ]
    }
   ],
   "source": [
    "def create_feed_dict(set_type_):\n",
    "    \"\"\"Creates a dictionaries for different sets: maps data onto Tensor placeholders.\"\"\"\n",
    "    feed_dict = dict()\n",
    "    \n",
    "    #if set_type_==\"train\":\n",
    "    # Get next batch and create a feed dict.\n",
    "    next_batch = train_batches.next()\n",
    "    # Feed batch to input buffers.\n",
    "    for i in range(SEQ_LENGTH + 1):\n",
    "        feed_dict[data_buffers[i]] = next_batch[i]\n",
    "\n",
    "    # Set previous weights of read and write heades.\n",
    "    for i in range(SEQ_LENGTH):\n",
    "        feed_dict[prev_read_weights_seq_batch[i]] = prev_rw_seq_batch[i]\n",
    "        feed_dict[prev_update_weights_seq_batch[i]] = prev_uw_seq_batch[i]\n",
    "\n",
    "    # Reset \"init\" state and output of controller.\n",
    "    feed_dict[init_controller_output] = np.zeros([BATCH_SIZE, HIDDEN_SIZE])\n",
    "    feed_dict[init_controller_state] = np.zeros([BATCH_SIZE, HIDDEN_SIZE])\n",
    "    feed_dict[init_memory_output] = np.zeros([BATCH_SIZE, HIDDEN_SIZE])\n",
    "            \n",
    "    #elif set_type_==\"valid\":\n",
    "    #    for i in range(SEQ_LENGTH + 1):\n",
    "    #        feed_dict[data_buffers[i]] = valid_batch[i]\n",
    "\n",
    "    # TODO: HOW TO VALIDATE !! when update/write depends on the previous batch??\n",
    "    \n",
    "    #else: # test\n",
    "    #    for i in range(SEQ_LENGTH + 1):\n",
    "    #        feed_dict[data_buffers[i]] = test_batch[i]\n",
    "        \n",
    "       \n",
    "    return feed_dict\n",
    "\n",
    "print(\"Feed_dict definition OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log dir CLEARED\n"
     ]
    }
   ],
   "source": [
    "# Eventually clear the log dir.\n",
    "if tf.gfile.Exists(LOG_DIR):\n",
    "  tf.gfile.DeleteRecursively(LOG_DIR)\n",
    "# Create (new) log dir.\n",
    "tf.gfile.MakeDirs(LOG_DIR)\n",
    "\n",
    "print(\"Log dir CLEARED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables initialized\n",
      "Number of iterations per epoch = 10000\n",
      "memory=\n",
      " [[ 0.75184965  0.30351904  1.44875455  0.83386803  1.2392602  -0.10503245\n",
      "  -0.15712482  0.19002728 -1.05824733  0.54126722]\n",
      " [ 1.16734219 -0.77776682 -1.74520576  0.72832596 -0.7012766  -1.19848382\n",
      "   0.89097685  0.42031693 -0.91780639  0.1528822 ]\n",
      " [ 1.77687776  0.94992328  1.81453133  1.87101102 -0.65485996 -0.18847853\n",
      "   0.38106561  1.18798268 -0.29824588  0.42026457]\n",
      " [ 0.10946539 -0.65063179  0.31195322 -0.87512648  1.65326619 -0.06295472\n",
      "   1.21986663  0.93531328 -1.49960518  0.94153011]]\n",
      "Training set BPC at step 0: 4.06645 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 0.63037449  0.17439751  1.40519369  0.71968079  0.98911417 -0.19926478\n",
      "  -0.25553876 -0.05703909 -1.23643577  0.44028074]\n",
      " [ 1.24350083 -0.73337311 -1.54600823  0.80307835 -0.65089172 -1.07376468\n",
      "   1.01595426  0.38472387 -0.85216331  0.28832588]\n",
      " [ 1.94348824  1.06258857  2.08798575  2.0263617  -0.48268571  0.03486843\n",
      "   0.59045255  1.27941573 -0.14952029  0.62903404]\n",
      " [-0.06349808 -0.80588239  0.23496187 -1.02974987  1.36302221 -0.21895912\n",
      "   1.08015311  0.61771816 -1.69649327  0.81861049]]\n",
      "Training set BPC at step 100: 3.31425 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 0.24211931 -0.77336127  0.21600491 -0.11226831 -0.20066804 -0.98789722\n",
      "  -0.93198657 -1.07844543 -2.15503287 -0.10897527]\n",
      " [ 1.33982432 -1.31641078 -2.48552871  0.46343198 -1.45527613 -1.48251641\n",
      "   0.94489527 -0.32482764 -1.32289279  0.46198547]\n",
      " [ 2.15553379  0.7747128   1.79247499  1.98165274 -0.82582891 -0.17353351\n",
      "   0.67415786  1.01624668 -0.39901724  0.76093107]\n",
      " [-0.39564279 -1.85121071 -1.51407254 -1.95318937 -0.0956433  -1.00519776\n",
      "   0.50267226 -0.70848322 -2.59393835  0.64101768]]\n",
      "Training set BPC at step 200: 0.58496 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 0.17074256 -0.94539982  0.13580221 -0.18696372 -0.38751885 -1.16725552\n",
      "  -1.07757294 -1.12714553 -2.21538448 -0.17738262]\n",
      " [ 1.16693246 -1.52352822 -2.4902494   0.31042895 -1.63410056 -1.68365407\n",
      "   0.89653033 -0.40934509 -1.41360974  0.39779547]\n",
      " [ 2.17345953  0.72052377  1.93083858  2.06301212 -0.83146828 -0.23030362\n",
      "   0.67476094  1.05792511 -0.37794709  0.87408131]\n",
      " [-0.72461927 -2.19531655 -1.74459374 -2.3334918  -0.45825434 -1.33996117\n",
      "   0.3565034  -0.9093107  -2.78727436  0.3640005 ]]\n",
      "Training set BPC at step 300: 1.07300 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.18179169 -1.16743279  0.09538248 -0.49037603 -0.57456696 -1.34097946\n",
      "  -1.22488141 -1.35875845 -2.43159533 -0.56771421]\n",
      " [ 0.8289144  -1.84277642 -2.56774139 -0.03714176 -1.90088868 -1.90011871\n",
      "   0.61528003 -0.69205743 -1.5779773   0.12879305]\n",
      " [ 1.99000621  0.57086903  2.03925753  1.85413396 -0.94510651 -0.32748497\n",
      "   0.65681654  0.93413967 -0.49215433  0.69148403]\n",
      " [-1.1969322  -2.61779237 -2.02547956 -2.77963376 -0.82337141 -1.63876379\n",
      "  -0.12046503 -1.32433474 -2.99340343 -0.01057593]]\n",
      "Training set BPC at step 400: 0.20879 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.37004635 -1.35435426  0.0929371  -0.67064393 -0.68956679 -1.45771122\n",
      "  -1.43608069 -1.54552317 -2.4928925  -0.74973422]\n",
      " [ 0.70130855 -1.94064116 -2.50166869 -0.12314381 -1.96488738 -1.98066449\n",
      "   0.48981822 -0.80672127 -1.61600792  0.04859309]\n",
      " [ 1.92177355  0.55436814  2.15706444  1.84790075 -0.92962778 -0.34237453\n",
      "   0.63525778  0.90355754 -0.47694981  0.60596889]\n",
      " [-1.38676596 -2.85041404 -2.06285906 -2.99701881 -0.99919802 -1.79977322\n",
      "  -0.37887186 -1.55428815 -3.09436679 -0.11020346]]\n",
      "Training set BPC at step 500: 6.26182 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.52391803 -1.47379851  0.0829283  -0.77942449 -0.77338231 -1.57184243\n",
      "  -1.47596538 -1.56535053 -2.56021023 -0.84532911]\n",
      " [ 0.75237417 -1.93043637 -2.40945554 -0.10013883 -1.92721403 -1.99117553\n",
      "   0.54363537 -0.77260715 -1.56349957  0.05803432]\n",
      " [ 1.89757371  0.54694384  2.20432591  1.84720576 -0.96863645 -0.39268059\n",
      "   0.64853758  0.90982598 -0.49987328  0.55931699]\n",
      " [-1.34739268 -2.87978077 -1.97494042 -3.01068044 -0.93157214 -1.80926013\n",
      "  -0.33194265 -1.51062953 -3.01395464 -0.07651146]]\n",
      "Training set BPC at step 600: 1.37541 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.4498243  -1.43415022  0.12656498 -0.71860373 -0.68185538 -1.56107783\n",
      "  -1.43424964 -1.46014631 -2.51313305 -0.72273749]\n",
      " [ 0.90046763 -1.84865284 -2.29455376 -0.01203884 -1.70544994 -1.92638695\n",
      "   0.66204208 -0.61110419 -1.43900526  0.26931715]\n",
      " [ 2.04348159  0.63309586  2.30568337  1.95717871 -0.83001381 -0.29348427\n",
      "   0.79888779  1.08065689 -0.34553984  0.86196357]\n",
      " [-1.26069868 -2.83355021 -1.89626229 -2.96961427 -0.70361131 -1.80530071\n",
      "  -0.32878807 -1.4027915  -2.99833322 -0.058636  ]]\n",
      "Training set BPC at step 700: 4.31582 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.5090633  -1.50839186  0.02949139 -0.94965076 -0.73878002 -1.70724893\n",
      "  -1.32100773 -1.42108202 -2.62109876 -0.96125859]\n",
      " [ 0.89749473 -1.81008017 -2.29532242 -0.12627931 -1.6527437  -1.97268641\n",
      "   0.88695121 -0.48899761 -1.44821489  0.16811301]\n",
      " [ 2.05601335  0.6777451   2.2730608   1.83627868 -0.75591344 -0.34282881\n",
      "   1.0056448   1.16033244 -0.37845936  0.72473669]\n",
      " [-1.31097639 -2.86678529 -1.9009124  -3.11046839 -0.7491737  -1.88041091\n",
      "  -0.19988929 -1.28417611 -3.02900505 -0.17766041]]\n",
      "Training set BPC at step 800: 0.07639 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.54880738 -1.50848043 -0.04282923 -0.93957192 -0.73699331 -1.71679413\n",
      "  -1.30663025 -1.38246572 -2.59980059 -0.93224972]\n",
      " [ 0.92328465 -1.78584456 -2.32125545 -0.06492665 -1.61805272 -1.94385064\n",
      "   0.98712391 -0.40822053 -1.40413594  0.19455661]\n",
      " [ 2.07433629  0.69940764  2.23489285  1.88582528 -0.70687437 -0.29966766\n",
      "   1.15061355  1.24783325 -0.31969601  0.79817212]\n",
      " [-1.30578125 -2.8537066  -1.9335742  -3.06374788 -0.74922591 -1.88785756\n",
      "  -0.20914043 -1.23649895 -3.01442504 -0.20320047]]\n",
      "Training set BPC at step 900: 1.90118 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.57455218 -1.65740693 -0.03651068 -0.91617006 -0.75523669 -1.70937669\n",
      "  -1.22539473 -1.29113185 -2.55412388 -0.99981546]\n",
      " [ 0.87655199 -1.91668546 -2.36732507 -0.10147507 -1.62256896 -1.93326235\n",
      "   0.99980325 -0.35662889 -1.34991038  0.15294145]\n",
      " [ 2.04707098  0.61116624  2.24234104  1.87439251 -0.71760166 -0.2869806\n",
      "   1.19845867  1.33904719 -0.27324632  0.77711034]\n",
      " [-1.35333347 -2.99734449 -2.00676107 -3.09232998 -0.74746865 -1.87655973\n",
      "  -0.19707805 -1.21548498 -2.95358133 -0.27850765]]\n",
      "Training set BPC at step 1000: 1.62466 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.54825079 -1.72165    -0.07898971 -0.89606363 -0.79157621 -1.69881201\n",
      "  -1.27124751 -1.21873891 -2.55547857 -1.07239413]\n",
      " [ 1.02664256 -1.88741052 -2.32909703 -0.00819014 -1.58981943 -1.84680688\n",
      "   1.01086056 -0.25122082 -1.26782596  0.13208948]\n",
      " [ 2.14176965  0.62764263  2.22086358  1.98146427 -0.69829482 -0.23782215\n",
      "   1.18504071  1.41518712 -0.21867971  0.73246515]\n",
      " [-1.22352767 -2.99276042 -1.94278097 -3.06414938 -0.73101795 -1.79500973\n",
      "  -0.18222155 -1.10042882 -2.88849115 -0.28953978]]\n",
      "Training set BPC at step 1100: 2.92550 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.40157047 -1.66316307 -0.13765879 -0.81639355 -0.78185534 -1.69423342\n",
      "  -1.24079561 -1.25620425 -2.5632844  -1.10335934]\n",
      " [ 1.18564808 -1.80708122 -2.34435034  0.05969091 -1.56477416 -1.7986989\n",
      "   1.08306825 -0.26096365 -1.22746348  0.18733941]\n",
      " [ 2.31473756  0.6981703   2.18898177  2.05753016 -0.683281   -0.21783385\n",
      "   1.26027775  1.41201949 -0.21752732  0.71386635]\n",
      " [-1.11072516 -2.91675019 -1.94855011 -2.99896765 -0.69466555 -1.73771882\n",
      "  -0.1403244  -1.11842859 -2.81950212 -0.19378518]]\n",
      "Training set BPC at step 1200: 3.37648 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.24812827 -1.51446211 -0.14750253 -0.9060989  -0.74879867 -1.73254383\n",
      "  -1.3435744  -1.21859169 -2.49838734 -1.10295415]\n",
      " [ 1.32259011 -1.67318988 -2.33152843  0.04254667 -1.52251172 -1.79672348\n",
      "   1.06040478 -0.20375738 -1.16240013  0.18963836]\n",
      " [ 2.46741843  0.86822838  2.19559979  1.99636102 -0.6355406  -0.24382341\n",
      "   1.20505738  1.4471755  -0.14238602  0.72177112]\n",
      " [-0.98953861 -2.83628178 -1.93767774 -3.00808406 -0.65589088 -1.72002459\n",
      "  -0.16607401 -1.03273439 -2.76739955 -0.18493576]]\n",
      "Training set BPC at step 1300: 3.20826 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.25642422 -1.49373734 -0.027289   -0.98306388 -0.68190986 -1.70165277\n",
      "  -1.2843889  -1.14864707 -2.37300944 -0.99747503]\n",
      " [ 1.34440637 -1.62369633 -2.20858026  0.02947647 -1.44160199 -1.73480868\n",
      "   1.12242222 -0.07223405 -0.99192423  0.29308152]\n",
      " [ 2.47961664  0.92522323  2.35277867  1.96631253 -0.53423005 -0.17604721\n",
      "   1.29013479  1.60002637  0.08787999  0.8436169 ]\n",
      " [-0.9762817  -2.81923938 -1.88254082 -3.03498244 -0.62089169 -1.69509673\n",
      "  -0.13441198 -0.98801893 -2.73717904 -0.11269592]]\n",
      "Training set BPC at step 1400: 2.55390 learning rate: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[-0.32641214 -1.53912425 -0.06424771 -1.06877422 -0.6979928  -1.70987117\n",
      "  -1.26720262 -1.18366063 -2.38479614 -0.85958385]\n",
      " [ 1.37348831 -1.61320722 -2.20604587 -0.00836594 -1.40623546 -1.69240248\n",
      "   1.23175824 -0.03237147 -0.95428675  0.48707476]\n",
      " [ 2.53240705  0.96131837  2.35976887  1.94325387 -0.473488   -0.10904928\n",
      "   1.4309727   1.68454134  0.14838496  1.10309446]\n",
      " [-1.0280751  -2.86793375 -1.89602578 -3.10135317 -0.64733613 -1.71546495\n",
      "  -0.13460508 -1.05817842 -2.75957751 -0.07892621]]\n",
      "Training set BPC at step 1500: 2.07581 learning rate: 0.100000\n",
      "memory=\n",
      " [[ -5.02233684e-01  -1.63196588e+00  -5.24018444e-02  -1.22612119e+00\n",
      "   -7.70031393e-01  -1.80708146e+00  -1.26461470e+00  -1.14242208e+00\n",
      "   -2.53924012e+00  -9.10175800e-01]\n",
      " [  1.29848754e+00  -1.57505250e+00  -2.13258076e+00   2.15823613e-02\n",
      "   -1.37503564e+00  -1.67405784e+00   1.38242054e+00   7.44318441e-02\n",
      "   -9.33728218e-01   5.29690206e-01]\n",
      " [  2.47906041e+00   1.00910854e+00   2.46193790e+00   2.00884652e+00\n",
      "   -4.24920946e-01  -8.35847929e-02   1.52298844e+00   1.80983865e+00\n",
      "    1.59435853e-01   1.16976786e+00]\n",
      " [ -1.15725863e+00  -2.90355086e+00  -1.88626015e+00  -3.21685863e+00\n",
      "   -6.86790049e-01  -1.76176000e+00   2.10843259e-03  -1.01073480e+00\n",
      "   -2.81362820e+00  -1.09223373e-01]]\n",
      "Training set BPC at step 1600: 1.97460 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.58861548 -1.66931665  0.01209847 -1.29427898 -0.76030791 -1.89200521\n",
      "  -1.30001402 -1.21315694 -2.60436153 -0.89769936]\n",
      " [ 1.35147536 -1.53412867 -2.01088142  0.07158009 -1.2636193  -1.64597476\n",
      "   1.39463902  0.07114284 -0.88477862  0.64486206]\n",
      " [ 2.52083325  1.02885342  2.55654955  2.02113581 -0.35578036 -0.0671256\n",
      "   1.54981649  1.81105185  0.19198437  1.26894832]\n",
      " [-1.16062665 -2.87814236 -1.770136   -3.18390203 -0.58374065 -1.77541184\n",
      "  -0.02302956 -1.0466975  -2.80534577 -0.03233917]]\n",
      "Training set BPC at step 1700: 4.34050 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.43526238 -1.6643827   0.06903204 -1.25199473 -0.82733214 -1.96057951\n",
      "  -1.21027708 -0.83608216 -2.72975063 -0.57641858]\n",
      " [ 1.50513923 -1.43704855 -1.82147014  0.24675101 -1.22554588 -1.56277633\n",
      "   1.57894886  0.35288373 -0.8749193   0.93854052]\n",
      " [ 2.66323924  1.11818588  2.69104004  2.12883902 -0.31017056 -0.00466683\n",
      "   1.67709184  2.110425    0.22720264  1.54066837]\n",
      " [-0.98874784 -2.82056189 -1.59939349 -3.01873207 -0.59771484 -1.74074399\n",
      "   0.16422457 -0.75818467 -2.88024402  0.27109581]]\n",
      "Training set BPC at step 1800: 3.02554 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.55506963 -1.67544568  0.14921083 -1.23031116 -0.80382282 -1.95662224\n",
      "  -1.10894632 -0.87670469 -2.84274697 -0.61117876]\n",
      " [ 1.586869   -1.24660015 -1.54735482  0.54078335 -0.95097733 -1.34750915\n",
      "   1.82374609  0.5322783  -0.77058685  1.13811672]\n",
      " [ 2.70343018  1.22322392  2.88928914  2.27741051 -0.17758745  0.14073388\n",
      "   1.8845309   2.19094944  0.28247133  1.63515019]\n",
      " [-0.97389627 -2.6682806  -1.38037252 -2.73479152 -0.31511769 -1.58276725\n",
      "   0.33309942 -0.59614545 -2.83944035  0.44422856]]\n",
      "Training set BPC at step 1900: 2.54635 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.61842197 -1.7234627  -0.05304569 -1.27025223 -0.98331255 -2.0601089\n",
      "  -1.12053883 -0.78332216 -2.95695257 -0.76318073]\n",
      " [ 1.7019881  -1.16927648 -1.4798131   0.66975319 -0.95048094 -1.30257106\n",
      "   1.99460018  0.70899165 -0.72496867  1.12324417]\n",
      " [ 2.75705481  1.26155591  2.90862274  2.3283937  -0.19845439  0.15251596\n",
      "   1.9377408   2.38411856  0.30613378  1.62937105]\n",
      " [-0.8902263  -2.61204338 -1.41204405 -2.61117625 -0.37479162 -1.57047474\n",
      "   0.52703393 -0.49571422 -2.84717703  0.34928018]]\n",
      "Training set BPC at step 2000: 1.14049 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.62536669 -1.87153399 -0.0526186  -1.39442623 -0.90734744 -2.08378386\n",
      "  -1.14105248 -0.75198066 -2.98274469 -0.94383699]\n",
      " [ 1.81690705 -1.13775229 -1.3919276   0.67122996 -0.7189427  -1.20235074\n",
      "   2.07660723  0.8581633  -0.65369141  1.08802354]\n",
      " [ 2.79556489  1.2575804   3.01716042  2.34900403 -0.01780688  0.19768859\n",
      "   1.9910928   2.4492507   0.34787023  1.64997303]\n",
      " [-0.76023954 -2.63252258 -1.40326416 -2.69950271 -0.21086991 -1.47617114\n",
      "   0.57367784 -0.32238016 -2.79595327  0.161053  ]]\n",
      "Training set BPC at step 2100: 3.10811 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.79041588 -1.9624697  -0.16336925 -1.50549066 -1.0295558  -2.229491\n",
      "  -1.21371651 -1.16645002 -3.17365098 -1.1125567 ]\n",
      " [ 1.78033793 -1.10906231 -1.36881196  0.62378037 -0.72581679 -1.23580265\n",
      "   2.00989532  0.63818288 -0.74222541  1.09591985]\n",
      " [ 2.78993058  1.28739381  3.10378075  2.36001611  0.01358983  0.19401039\n",
      "   2.02799487  2.2782619   0.31666741  1.70702398]\n",
      " [-0.87457943 -2.66498637 -1.53980958 -2.8591311  -0.32864353 -1.59109759\n",
      "   0.39780158 -0.66294295 -2.9875474   0.01424372]]\n",
      "Training set BPC at step 2200: 3.62185 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.12469566 -2.168396   -0.28428555 -1.53724563 -1.22530293 -2.35129547\n",
      "  -1.42772949 -1.38705659 -3.34418941 -1.26443481]\n",
      " [ 1.65423453 -1.16481912 -1.37899458  0.65474266 -0.78715259 -1.2165668\n",
      "   1.90698576  0.59481621 -0.74894047  1.01861382]\n",
      " [ 2.74082875  1.31536138  3.1582911   2.42807221  0.01218049  0.32663599\n",
      "   1.96807969  2.27321196  0.33736369  1.71179926]\n",
      " [-1.17543626 -2.88018203 -1.67093647 -2.89281511 -0.5147019  -1.78250539\n",
      "   0.2024812  -0.82338381 -3.09987235 -0.17414996]]\n",
      "Training set BPC at step 2300: 3.22535 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.37959957 -2.29338074 -0.22091018 -1.50030518 -1.3229003  -2.3314023\n",
      "  -1.60386288 -1.3425442  -3.37721181 -1.43819296]\n",
      " [ 1.44317305 -1.28465331 -1.39867735  0.66151977 -0.86721253 -1.29283667\n",
      "   1.78761065  0.57005715 -0.77057439  0.89342231]\n",
      " [ 2.65566063  1.29989743  3.23174977  2.54401159  0.0618944   0.36306491\n",
      "   1.9541086   2.36537838  0.40197101  1.69578445]\n",
      " [-1.51411486 -3.09435177 -1.7388413  -2.99542713 -0.74526751 -1.92218781\n",
      "  -0.04330584 -0.93933684 -3.22195435 -0.42551053]]\n",
      "Training set BPC at step 2400: 3.77624 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.45185316 -2.43773603 -0.53189367 -1.56830406 -1.40440071 -2.53510189\n",
      "  -1.82942164 -1.51189923 -3.46617317 -1.49542236]\n",
      " [ 1.41824055 -1.33986807 -1.6050117   0.6607644  -0.87572175 -1.31927311\n",
      "   1.71431327  0.48578957 -0.77640665  0.90732199]\n",
      " [ 2.65974808  1.30524075  3.11390543  2.6635046   0.10313123  0.41015863\n",
      "   1.87262404  2.36226511  0.48206702  1.76629078]\n",
      " [-1.59815025 -3.2658155  -2.07178473 -3.19918275 -0.8548435  -2.1458869\n",
      "  -0.17364749 -1.16063666 -3.38925529 -0.52559483]]\n",
      "Training set BPC at step 2500: 2.37633 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.6313839  -2.44455624 -0.50060403 -1.59434664 -1.44959903 -2.70982885\n",
      "  -2.05012059 -1.3105979  -3.60708356 -1.54189503]\n",
      " [ 1.40423965 -1.27374375 -1.51166105  0.71648759 -0.85989285 -1.3736037\n",
      "   1.64744341  0.71811867 -0.79893804  0.94393009]\n",
      " [ 2.66425943  1.39236605  3.20633936  2.75434065  0.13689592  0.39621517\n",
      "   1.85924685  2.55411339  0.47999436  1.82506621]\n",
      " [-1.7159636  -3.2631526  -2.01659489 -3.24252987 -0.89105201 -2.29411244\n",
      "  -0.3734009  -0.91618282 -3.48882437 -0.55656278]]\n",
      "Training set BPC at step 2600: 1.96696 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.66485345 -2.51992083 -0.45113593 -1.36051524 -1.41978943 -2.75242901\n",
      "  -2.02701378 -1.39876246 -3.63505125 -1.53641522]\n",
      " [ 1.45797515 -1.27501953 -1.33826971  0.94601643 -0.74437112 -1.30836916\n",
      "   1.71458542  0.70059556 -0.74915373  0.98377812]\n",
      " [ 2.71658301  1.44070256  3.37211013  2.93444228  0.24922702  0.46324578\n",
      "   1.99043453  2.57492042  0.55791819  1.88906431]\n",
      " [-1.70413268 -3.36367512 -1.93054247 -2.97342491 -0.82956678 -2.294101\n",
      "  -0.41141996 -1.01195335 -3.51899719 -0.56840992]]\n",
      "Training set BPC at step 2700: 1.46134 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.62436402 -2.42627096 -0.55177057 -1.18048453 -1.20916057 -2.72727799\n",
      "  -1.96899056 -1.2018007  -3.50787497 -1.33360255]\n",
      " [ 1.63227963 -1.13663495 -1.32509887  1.14837766 -0.55070108 -1.20244074\n",
      "   1.86048663  0.98905575 -0.5791055   1.21218586]\n",
      " [ 2.87595534  1.59883726  3.4511466   3.14187813  0.46612123  0.60480303\n",
      "   2.1729939   2.81324029  0.74874812  2.07772732]\n",
      " [-1.61910272 -3.30198526 -2.07489681 -2.8327632  -0.69159704 -2.29863429\n",
      "  -0.40000719 -0.7622816  -3.43279457 -0.3362267 ]]\n",
      "Training set BPC at step 2800: 2.49946 learning rate: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[-1.61808634 -2.34740973 -0.49198005 -1.10105383 -1.18109179 -2.66911173\n",
      "  -1.82457483 -1.02998507 -3.42801237 -1.33085358]\n",
      " [ 1.69674468 -0.94783944 -1.2388804   1.27499735 -0.42994294 -1.05751216\n",
      "   2.07619977  1.15531957 -0.43675056  1.28689373]\n",
      " [ 3.01775861  1.83890474  3.56521368  3.33117247  0.60573059  0.75599176\n",
      "   2.35611534  3.04326439  0.89750564  2.17274785]\n",
      " [-1.68639672 -3.27416825 -2.05363202 -2.83483982 -0.67951643 -2.23144007\n",
      "  -0.22559361 -0.70210582 -3.35644484 -0.33528578]]\n",
      "Training set BPC at step 2900: 2.38987 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.58877206 -2.34852552 -0.47741148 -1.30139196 -1.22787762 -2.74542999\n",
      "  -1.88965178 -1.11652303 -3.49094772 -1.21097994]\n",
      " [ 1.78012836 -0.84788191 -1.18452394  1.22386169 -0.41445637 -1.0493654\n",
      "   2.07603884  1.17871654 -0.42470837  1.42695451]\n",
      " [ 3.12387848  1.91631913  3.68268728  3.34021688  0.65900528  0.78810978\n",
      "   2.40421247  3.07690668  0.93537897  2.34055424]\n",
      " [-1.66001463 -3.21207285 -2.09816599 -3.03148293 -0.73993063 -2.29634452\n",
      "  -0.31299111 -0.75216419 -3.41262507 -0.246309  ]]\n",
      "Training set BPC at step 3000: 3.27159 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.51068473 -2.34682441 -0.34300196 -1.18958986 -1.35638094 -2.81187129\n",
      "  -1.83200359 -1.05273283 -3.53629065 -1.0571748 ]\n",
      " [ 1.82410467 -0.76267862 -0.95226288  1.38255954 -0.41434884 -0.98236907\n",
      "   2.1318357   1.2941488  -0.37645099  1.66458464]\n",
      " [ 3.22186184  2.0337131   3.9177289   3.51186848  0.6826182   0.85035104\n",
      "   2.49241805  3.21891403  1.00987136  2.52907825]\n",
      " [-1.66276073 -3.23069096 -1.96421206 -2.93845391 -0.83197623 -2.30062199\n",
      "  -0.30112955 -0.70867813 -3.44664001 -0.0225373 ]]\n",
      "Training set BPC at step 3100: 0.84009 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.36538029 -2.20910788 -0.27472475 -1.37199223 -1.04048479 -2.68191743\n",
      "  -1.66060221 -1.02358723 -3.42393327 -1.0487268 ]\n",
      " [ 2.01634979 -0.55458617 -0.76512933  1.34100485 -0.10749999 -0.77902234\n",
      "   2.36111403  1.38834751 -0.16692933  1.7655853 ]\n",
      " [ 3.37025428  2.21968007  4.09758568  3.48094249  0.96108353  0.97507882\n",
      "   2.64460278  3.31266379  1.17968929  2.59773088]\n",
      " [-1.46484923 -3.05392647 -1.87240398 -3.05134368 -0.52005118 -2.06615615\n",
      "  -0.04369843 -0.66979927 -3.26560044  0.05592361]]\n",
      "Training set BPC at step 3200: 2.77869 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.4362663  -2.26272225 -0.1292607  -1.41539478 -0.91084105 -2.61801696\n",
      "  -1.64602959 -0.98481476 -3.32727265 -0.89903033]\n",
      " [ 2.06308746 -0.5322727  -0.5825398   1.38369882  0.04872913 -0.63380963\n",
      "   2.42205596  1.52291214 -0.04724567  1.92553341]\n",
      " [ 3.47149086  2.24684453  4.27283287  3.50076675  1.12834859  1.10243523\n",
      "   2.74756765  3.43827558  1.32452023  2.79766917]\n",
      " [-1.56291401 -3.07803679 -1.71249676 -3.02566338 -0.40808138 -1.96650743\n",
      "  -0.06621649 -0.59267497 -3.19878292  0.1284489 ]]\n",
      "Training set BPC at step 3300: 0.10099 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.29716194 -2.35784388 -0.13363501 -1.38234544 -0.86557388 -2.56271005\n",
      "  -1.73672295 -1.0237987  -3.26701164 -0.8778559 ]\n",
      " [ 2.22853708 -0.53505951 -0.52649117  1.47431183  0.16133069 -0.55215162\n",
      "   2.46743441  1.53145444  0.03775563  2.02665305]\n",
      " [ 3.68849254  2.27330446  4.35643482  3.62056923  1.26265836  1.19058657\n",
      "   2.80310059  3.48865032  1.42342651  2.9003005 ]\n",
      " [-1.48905206 -3.15481448 -1.73507023 -3.00269771 -0.36098495 -1.90687156\n",
      "  -0.09707458 -0.65335679 -3.14504147  0.17074995]]\n",
      "Training set BPC at step 3400: 3.52973 learning rate: 0.100000\n",
      "memory=\n",
      " [[ -1.36397660e+00  -2.32431865e+00   2.34876230e-01  -1.46020448e+00\n",
      "   -7.26989567e-01  -2.45013428e+00  -1.67704988e+00  -9.25613225e-01\n",
      "   -3.01778531e+00  -9.03413236e-01]\n",
      " [  2.21265364e+00  -5.10863483e-01  -2.63795882e-01   1.44160450e+00\n",
      "    3.24525207e-01  -4.38429743e-01   2.53942680e+00   1.60437477e+00\n",
      "    2.61274129e-01   2.06365395e+00]\n",
      " [  3.66136146e+00   2.28358316e+00   4.66089153e+00   3.61523724e+00\n",
      "    1.45730031e+00   1.29241824e+00   2.83473349e+00   3.59203982e+00\n",
      "    1.68333685e+00   2.94239235e+00]\n",
      " [ -1.53662026e+00  -3.11691141e+00  -1.52246654e+00  -3.09780073e+00\n",
      "   -2.85810530e-01  -1.81055260e+00   3.39179212e-04  -6.17012143e-01\n",
      "   -3.01961637e+00   1.60860464e-01]]\n",
      "Training set BPC at step 3500: 3.08243 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.19397378 -2.30734444  0.26720098 -1.54477084 -0.58678949 -2.40075612\n",
      "  -1.63686872 -0.8439284  -2.91139483 -0.73141026]\n",
      " [ 2.33900666 -0.43293932 -0.21692756  1.41153288  0.45955557 -0.34192571\n",
      "   2.6240046   1.75286162  0.40965205  2.25017715]\n",
      " [ 3.80655313  2.32995582  4.71218824  3.58922696  1.628636    1.41103816\n",
      "   2.92359304  3.69137478  1.81725252  3.06385517]\n",
      " [-1.42393339 -3.02952003 -1.4901402  -3.14224744 -0.21649729 -1.77353227\n",
      "   0.05362046 -0.45753694 -2.89028478  0.40113887]]\n",
      "Training set BPC at step 3600: 2.40061 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.09067285 -2.29709172  0.33238143 -1.46667743 -0.4782131  -2.38331699\n",
      "  -1.67030907 -0.95321226 -2.92424679 -0.70970017]\n",
      " [ 2.43347287 -0.40155253 -0.11677366  1.47464776  0.6028713  -0.30582461\n",
      "   2.66885352  1.70567596  0.41586855  2.28900814]\n",
      " [ 3.95772958  2.36864972  4.8102808   3.67313743  1.73719656  1.45559084\n",
      "   2.96197557  3.64537811  1.8351897   3.16523767]\n",
      " [-1.40976501 -3.0175786  -1.41307867 -3.09986544 -0.05367736 -1.75748348\n",
      "   0.06213817 -0.5341962  -2.90581751  0.35612243]]\n",
      "Training set BPC at step 3700: 1.40083 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.036937   -2.19343781  0.30747581 -1.31662726 -0.41945899 -2.29607534\n",
      "  -1.51459801 -0.74583578 -2.73203969 -0.67592406]\n",
      " [ 2.53588057 -0.29602489 -0.10234396  1.61872375  0.75342602 -0.2089698\n",
      "   2.81009197  1.83868086  0.61552709  2.37567878]\n",
      " [ 4.07757092  2.45747566  4.85068798  3.7960186   1.86123943  1.54024899\n",
      "   3.10628748  3.82122183  1.99087799  3.26083755]\n",
      " [-1.35679722 -2.90241814 -1.44799554 -2.94126821  0.06977645 -1.6592499\n",
      "   0.19580415 -0.42328766 -2.67677093  0.40009943]]\n",
      "Training set BPC at step 3800: 1.28577 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.11055875 -2.24498367  0.17977208 -1.38965309 -0.57653415 -2.33436513\n",
      "  -1.47240782 -0.82806414 -2.72761011 -0.63203919]\n",
      " [ 2.52887893 -0.24071863 -0.1101656   1.70265937  0.78633684 -0.16026269\n",
      "   2.85655618  1.86867309  0.67265397  2.44431996]\n",
      " [ 4.09099483  2.54824519  4.85776854  3.86179852  1.88101482  1.57913613\n",
      "   3.1774745   3.86232805  2.06284809  3.32911372]\n",
      " [-1.4185636  -2.94304252 -1.53011119 -2.91975307  0.02241813 -1.6455605\n",
      "   0.20903319 -0.46256769 -2.66636443  0.45192388]]\n",
      "Training set BPC at step 3900: 3.30043 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.1349299  -2.25927329  0.22759087 -1.56935811 -0.61938149 -2.46383286\n",
      "  -1.59194088 -0.95943666 -2.79538107 -0.79234892]\n",
      " [ 2.55218172 -0.2109555  -0.15257952  1.68047738  0.80374902 -0.09139272\n",
      "   2.83830595  1.76154959  0.71354914  2.42516303]\n",
      " [ 4.1393013   2.61408424  4.95135736  3.85205626  1.91292977  1.60004389\n",
      "   3.18546367  3.84846592  2.15427089  3.32523823]\n",
      " [-1.44988346 -2.98098874 -1.68014562 -3.0334661  -0.00890318 -1.62825572\n",
      "   0.1119597  -0.67947757 -2.75481153  0.34696588]]\n",
      "Training set BPC at step 4000: 3.49801 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.29745889 -2.4667635   0.11737069 -1.67667198 -0.64753449 -2.38018227\n",
      "  -1.5561384  -0.90136564 -2.87329268 -0.77279836]\n",
      " [ 2.60268784 -0.21274248 -0.07716473  1.63041782  0.81707132  0.05219153\n",
      "   2.99027872  1.90787375  0.74541551  2.54567218]\n",
      " [ 4.17645454  2.6147542   5.00694942  3.84639406  1.97533393  1.75353551\n",
      "   3.30745959  3.96816349  2.18233752  3.40403771]\n",
      " [-1.49195707 -3.08559608 -1.67869842 -3.15634274 -0.07189502 -1.5360111\n",
      "   0.22823592 -0.55762947 -2.7741394   0.45561454]]\n",
      "Training set BPC at step 4100: 5.30657 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.42449486 -2.43131089 -0.07940087 -1.63785005 -0.69511086 -2.35265732\n",
      "  -1.58751917 -0.95876628 -2.86706924 -0.91411936]\n",
      " [ 2.57094598 -0.13298295 -0.1549027   1.73257995  0.83581364  0.14526594\n",
      "   3.01144767  1.97714031  0.80684429  2.48635364]\n",
      " [ 4.14819622  2.69611025  4.96221685  3.93964458  2.01388431  1.8177458\n",
      "   3.3268342   3.99261928  2.2460556   3.3561945 ]\n",
      " [-1.55276096 -3.03320265 -1.83858311 -3.08099294 -0.11882411 -1.43898344\n",
      "   0.23241931 -0.50137359 -2.74401546  0.35688254]]\n",
      "Training set BPC at step 4200: 1.58595 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.55246806 -2.58795571 -0.21890302 -1.94646215 -0.74739391 -2.43684244\n",
      "  -1.62220263 -1.03697002 -3.01201272 -1.16873085]\n",
      " [ 2.58672881 -0.12067137 -0.16653779  1.66513264  0.9674015   0.18702346\n",
      "   3.14569759  1.98920393  0.79947686  2.43623662]\n",
      " [ 4.13820791  2.6905477   4.94879341  3.86980677  2.07684565  1.87538576\n",
      "   3.40685558  3.98705721  2.2877543   3.36876416]\n",
      " [-1.57511938 -3.07667422 -1.90535617 -3.25267172 -0.00599647 -1.47174799\n",
      "   0.34719908 -0.48738497 -2.8654902   0.14474924]]\n",
      "Training set BPC at step 4300: 4.19911 learning rate: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ -1.63112497e+00  -2.54475760e+00  -2.27431223e-01  -1.89015377e+00\n",
      "   -5.92362344e-01  -2.44709015e+00  -1.63757205e+00  -9.38894629e-01\n",
      "   -2.96653676e+00  -1.18582368e+00]\n",
      " [  2.69469643e+00   5.66152744e-02  -2.42251158e-03   1.90641832e+00\n",
      "    1.24308240e+00   3.86403233e-01   3.31090307e+00   2.26662374e+00\n",
      "    1.06707764e+00   2.58016729e+00]\n",
      " [  4.25011444e+00   2.79542828e+00   5.08110523e+00   3.97457767e+00\n",
      "    2.25240350e+00   1.98650026e+00   3.51860356e+00   4.16394377e+00\n",
      "    2.45667076e+00   3.44577360e+00]\n",
      " [ -1.57092500e+00  -2.89480329e+00  -1.80171919e+00  -2.96566081e+00\n",
      "    3.01070929e-01  -1.28896070e+00   4.70474988e-01  -2.06734002e-01\n",
      "   -2.61391521e+00   2.73278207e-01]]\n",
      "Training set BPC at step 4400: 2.75723 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.72000539 -2.66571808 -0.32455865 -2.02026677 -0.77544743 -2.57126951\n",
      "  -1.70779979 -1.06984401 -3.06221938 -1.37050021]\n",
      " [ 2.72486424  0.0721487   0.10732463  1.90330887  1.21785486  0.42230868\n",
      "   3.40036893  2.30700397  1.16787636  2.62316823]\n",
      " [ 4.27614594  2.75052881  5.07599592  3.96067333  2.19667864  1.97969091\n",
      "   3.51292276  4.13314199  2.44959664  3.43455982]\n",
      " [-1.60363698 -2.86188889 -1.66941035 -3.01436281  0.24830525 -1.28023291\n",
      "   0.589338   -0.16346455 -2.49030542  0.26577103]]\n",
      "Training set BPC at step 4500: 1.67407 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.75502801 -2.73829317 -0.28163493 -2.03539562 -0.81027126 -2.52798772\n",
      "  -1.67170918 -1.06372678 -3.11342382 -1.45623028]\n",
      " [ 2.82084298  0.11892581  0.27476209  2.01496243  1.30583918  0.59969246\n",
      "   3.50593042  2.42400289  1.25611532  2.67634892]\n",
      " [ 4.34343433  2.78357697  5.19193602  4.02085638  2.25689459  2.09350133\n",
      "   3.58179855  4.18346357  2.4823246   3.47875571]\n",
      " [-1.54250491 -2.85849977 -1.51383698 -2.91189122  0.30549514 -1.10753965\n",
      "   0.70259887 -0.02013128 -2.40157366  0.26205945]]\n",
      "Training set BPC at step 4600: 2.33277 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.73509669 -2.68745542 -0.42248437 -2.05542946 -0.89800298 -2.55998158\n",
      "  -1.71301532 -1.00178039 -3.20045137 -1.43232787]\n",
      " [ 3.04905343  0.33056128  0.26571348  2.09075928  1.32354927  0.66513729\n",
      "   3.54147482  2.60713148  1.33742714  2.75177002]\n",
      " [ 4.44800186  2.94676304  5.20502996  4.08125544  2.28461432  2.15358901\n",
      "   3.63456178  4.29504919  2.52594995  3.56037736]\n",
      " [-1.28796268 -2.68569684 -1.60898364 -2.86939049  0.26222906 -1.08694077\n",
      "   0.68183494  0.18267848 -2.3646915   0.30259085]]\n",
      "Training set BPC at step 4700: 1.92828 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.67793715 -2.68828034 -0.41210508 -2.20718956 -1.09099197 -2.63437438\n",
      "  -1.75111413 -0.94641632 -3.28404832 -1.37070286]\n",
      " [ 3.23990965  0.47251755  0.39813817  2.09359431  1.32708836  0.72273451\n",
      "   3.64126468  2.78917909  1.38693631  2.9375515 ]\n",
      " [ 4.6184411   3.05817842  5.36959028  4.09436464  2.33724546  2.22357893\n",
      "   3.74351215  4.44741344  2.57235003  3.71258759]\n",
      " [-1.16166568 -2.59322572 -1.61823893 -2.95350099  0.08980724 -1.11624396\n",
      "   0.68609637  0.31251866 -2.38414931  0.44132707]]\n",
      "Training set BPC at step 4800: 2.84375 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.77784848 -2.67436123 -0.20779465 -1.99739039 -1.10524666 -2.57885623\n",
      "  -1.5903964  -0.80275661 -3.08755112 -1.23479271]\n",
      " [ 3.22306919  0.56519437  0.60854441  2.30508113  1.37255728  0.86248863\n",
      "   3.85866714  2.95464444  1.55749929  3.05049634]\n",
      " [ 4.61249208  3.15842557  5.56567955  4.28763723  2.39592433  2.34974265\n",
      "   3.90237522  4.61069298  2.76758456  3.84840846]\n",
      " [-1.23153412 -2.56947351 -1.41225028 -2.74089432  0.08636931 -1.01564264\n",
      "   0.92340851  0.45681769 -2.24453497  0.52975476]]\n",
      "Training set BPC at step 4900: 1.12662 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.79231668 -2.64978147 -0.18248904 -1.91957986 -0.99702698 -2.61206365\n",
      "  -1.52683973 -0.78387868 -3.02161741 -1.29122698]\n",
      " [ 3.30624151  0.68119055  0.68156981  2.43478036  1.56843472  0.99954998\n",
      "   3.99244022  3.03661656  1.65310884  3.07754326]\n",
      " [ 4.66161251  3.21640563  5.63140726  4.35159159  2.51371145  2.4079597\n",
      "   3.99524522  4.6528554   2.84156632  3.85240483]\n",
      " [-1.16375458 -2.44170737 -1.35964036 -2.572541    0.31219655 -0.88345021\n",
      "   1.05911446  0.54660845 -2.14629102  0.54038495]]\n",
      "Training set BPC at step 5000: 5.09385 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.79225826 -2.69060159 -0.11515825 -1.86596763 -0.93061376 -2.57829571\n",
      "  -1.4734503  -0.86387074 -3.01547146 -1.23730648]\n",
      " [ 3.34897685  0.72450864  0.75775278  2.53825355  1.68095469  1.06910551\n",
      "   4.09381056  3.05204177  1.72247708  3.22835493]\n",
      " [ 4.71998453  3.26186442  5.73214483  4.4614439   2.61472392  2.49369907\n",
      "   4.08721256  4.68183994  2.94140625  3.94517922]\n",
      " [-1.16256618 -2.44499469 -1.3211329  -2.50830078  0.40653515 -0.85479659\n",
      "   1.13991129  0.49934065 -2.14694571  0.69754952]]\n",
      "Training set BPC at step 5100: 2.70180 learning rate: 0.090000\n",
      "memory=\n",
      " [[-2.00955963 -2.766258   -0.11810082 -1.82552969 -0.81272125 -2.70735693\n",
      "  -1.40280199 -0.87567484 -3.16836286 -1.29682755]\n",
      " [ 3.33784413  0.78359842  0.8550576   2.67002273  1.88314879  1.0776341\n",
      "   4.21263027  3.11328173  1.73185658  3.34138083]\n",
      " [ 4.68522596  3.25874424  5.785676    4.5742712   2.7692225   2.45606256\n",
      "   4.18315554  4.73916101  2.93091226  3.97592521]\n",
      " [-1.24669385 -2.38620567 -1.23114622 -2.40998173  0.60538292 -0.86213756\n",
      "   1.25179601  0.52472407 -2.19494581  0.81000918]]\n",
      "Training set BPC at step 5200: 1.12375 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.96390903 -2.74279737 -0.20687853 -1.80353379 -0.83748621 -2.7335031\n",
      "  -1.39703071 -0.85216397 -3.21137071 -1.25683594]\n",
      " [ 3.46329784  0.86668998  0.90057451  2.73237681  1.91788721  1.13065457\n",
      "   4.28382635  3.22772574  1.76128185  3.42419839]\n",
      " [ 4.77155399  3.36939454  5.81930542  4.62978601  2.78820419  2.50004864\n",
      "   4.25184727  4.83555508  2.97388458  4.05889988]\n",
      " [-1.1257087  -2.36935329 -1.24111438 -2.36429381  0.62667197 -0.84147584\n",
      "   1.28852248  0.60636669 -2.21816492  0.86537331]]\n",
      "Training set BPC at step 5300: 2.47278 learning rate: 0.090000\n",
      "memory=\n",
      " [[-2.09313369 -2.73192024 -0.2169707  -1.78802049 -0.90999788 -2.85726619\n",
      "  -1.50210238 -0.86263537 -3.33026314 -1.31991625]\n",
      " [ 3.48905373  0.97013015  0.96366894  2.89229679  1.93353021  1.12980437\n",
      "   4.36830425  3.37173152  1.76498199  3.45462346]\n",
      " [ 4.78712606  3.43330097  5.89605856  4.75312614  2.81799793  2.50848627\n",
      "   4.30362129  4.955194    3.01570249  4.14005613]\n",
      " [-1.16569734 -2.2737689  -1.23321438 -2.24543428  0.58291787 -0.9120999\n",
      "   1.31145585  0.69235045 -2.31677866  0.79135585]]\n",
      "Training set BPC at step 5400: 3.98643 learning rate: 0.090000\n",
      "memory=\n",
      " [[-2.12886667 -2.69592404 -0.23578627 -1.76052225 -0.89072323 -2.82639432\n",
      "  -1.56752539 -0.9159916  -3.39519644 -1.27712905]\n",
      " [ 3.56767201  1.08309102  1.10295975  3.06638288  2.05048084  1.32405007\n",
      "   4.41668701  3.53679276  1.8457911   3.59119987]\n",
      " [ 4.80517769  3.49286079  5.96080589  4.83871889  2.86805105  2.60166979\n",
      "   4.32568455  5.00779533  3.0389142   4.22042179]\n",
      " [-1.07786524 -2.14249277 -1.09593821 -2.05421877  0.7314508  -0.69600838\n",
      "   1.33235645  0.86620116 -2.24515557  0.93650162]]\n",
      "Training set BPC at step 5500: 2.01550 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.96657324 -2.40564656 -0.1484423  -1.78214431 -0.76946765 -2.76832485\n",
      "  -1.45323801 -0.7970283  -3.26274538 -1.1656903 ]\n",
      " [ 3.85278797  1.53137064  1.32523572  3.25787878  2.33465528  1.53893375\n",
      "   4.6068244   3.84052444  2.12887907  3.9045074 ]\n",
      " [ 5.02754736  3.8219111   6.09355545  4.92895699  3.06309891  2.72886848\n",
      "   4.44162226  5.22043943  3.20891142  4.41973639]\n",
      " [-0.82976693 -1.70162964 -0.86665189 -1.87892866  0.9911958  -0.48831612\n",
      "   1.54723525  1.13671184 -1.94536376  1.2482636 ]]\n",
      "Training set BPC at step 5600: 3.25491 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.93800771 -2.42164207 -0.18466727 -1.7740761  -0.82372153 -2.83884406\n",
      "  -1.45468223 -0.77298468 -3.32178187 -1.10107219]\n",
      " [ 3.95785284  1.64438343  1.43356979  3.43986654  2.4547987   1.62482238\n",
      "   4.71084595  3.96310925  2.26302862  4.09714508]\n",
      " [ 5.16335487  3.87068605  6.09622812  5.00259638  3.11203742  2.74256492\n",
      "   4.50287437  5.27856684  3.26909447  4.50596619]\n",
      " [-0.80359226 -1.58667326 -0.71757007 -1.67142177  1.09828973 -0.4028962\n",
      "   1.64118993  1.27505863 -1.83121002  1.48677456]]\n",
      "Training set BPC at step 5700: 0.60221 learning rate: 0.090000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[-1.90644884 -2.20584297 -0.16585259 -1.70266581 -0.72092545 -2.81239486\n",
      "  -1.34134507 -0.70717323 -3.17083335 -0.98057675]\n",
      " [ 4.22645283  1.99690425  1.64012575  3.70485568  2.76916718  1.89983273\n",
      "   5.00511742  4.23652458  2.55685663  4.45243931]\n",
      " [ 5.27120638  4.08603764  6.16888332  5.12668753  3.24669647  2.84653139\n",
      "   4.63087082  5.37632751  3.41306424  4.65630722]\n",
      " [-0.488821   -1.17341506 -0.46735609 -1.36222887  1.48767042 -0.07755944\n",
      "   2.01172376  1.62404037 -1.4598105   1.93153381]]\n",
      "Training set BPC at step 5800: 0.48418 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.80482829 -2.22698259 -0.10919898 -1.6741432  -0.67657179 -2.7393086\n",
      "  -1.33400273 -0.61061895 -3.15141702 -0.89735729]\n",
      " [ 4.41201687  2.07596231  1.79454136  3.8615315   2.91549397  2.06062031\n",
      "   5.09564447  4.37475109  2.73653102  4.65528727]\n",
      " [ 5.36298418  4.10290051  6.23983335  5.17469358  3.31252098  2.93904614\n",
      "   4.64529991  5.49625015  3.48513341  4.75643349]\n",
      " [-0.25468639 -1.07915199 -0.27779412 -1.1577369   1.66345501  0.10508879\n",
      "   2.14018488  1.75189877 -1.25043571  2.17629313]]\n",
      "Training set BPC at step 5900: 1.46456 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.80820346 -2.19913626 -0.03025955 -1.55242074 -0.58464694 -2.62290072\n",
      "  -1.22316253 -0.49423298 -3.17363453 -0.77836144]\n",
      " [ 4.56062365  2.19928718  1.96574831  4.02636957  3.10040689  2.23312736\n",
      "   5.27508545  4.53485155  2.83939481  4.98931837]\n",
      " [ 5.4318428   4.18820333  6.33343601  5.28691149  3.43403816  3.03172779\n",
      "   4.74095821  5.58649969  3.53216529  4.9233284 ]\n",
      " [-0.10154433 -0.96862346 -0.07694718 -0.9665581   1.86082375  0.3269977\n",
      "   2.36737847  1.95715296 -1.15253246  2.56771445]]\n",
      "Training set BPC at step 6000: 1.77032 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.70393753 -2.05705643 -0.04170779 -1.47258723 -0.45264614 -2.53205037\n",
      "  -1.17615533 -0.49540919 -3.12768173 -0.6497702 ]\n",
      " [ 4.82067013  2.50082278  2.07568359  4.2642045   3.3382659   2.48056006\n",
      "   5.42594051  4.71379232  3.01862741  5.24937773]\n",
      " [ 5.61378098  4.35599422  6.38755894  5.41332817  3.56777191  3.15377283\n",
      "   4.8334837   5.66053295  3.61862969  5.05456734]\n",
      " [ 0.1506048  -0.61781877  0.02822675 -0.69895595  2.14569807  0.61992502\n",
      "   2.52167726  2.15237141 -0.94771373  2.88813305]]\n",
      "Training set BPC at step 6100: 3.71689 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.5836699  -1.91907704  0.09898289 -1.23740149 -0.33369166 -2.30985188\n",
      "  -1.16447532 -0.27805352 -3.06044674 -0.60402513]\n",
      " [ 5.26702976  2.88068771  2.39881706  4.77605677  3.64619708  2.96561861\n",
      "   5.64015007  5.10458994  3.27155471  5.46782303]\n",
      " [ 5.78766441  4.52792978  6.56114864  5.67763662  3.69765711  3.38935256\n",
      "   4.91836834  5.8844471   3.71819186  5.10455227]\n",
      " [ 0.70176077 -0.1600419   0.39766675 -0.10655776  2.53163314  1.19627428\n",
      "   2.75955296  2.59514332 -0.64342892  3.18872285]]\n",
      "Training set BPC at step 6200: 2.83695 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -1.49117434e+00  -1.84264970e+00  -6.02077991e-02  -1.31349659e+00\n",
      "   -3.25119346e-01  -2.35163212e+00  -1.23903322e+00  -3.20134193e-01\n",
      "   -3.15001941e+00  -5.66089690e-01]\n",
      " [  5.62295246e+00   3.20992470e+00   2.48743248e+00   4.88622665e+00\n",
      "    3.89621735e+00   3.12004924e+00   5.77763319e+00   5.24795294e+00\n",
      "    3.38121676e+00   5.72389555e+00]\n",
      " [  5.96464825e+00   4.66661739e+00   6.56423378e+00   5.70157385e+00\n",
      "    3.79776883e+00   3.45705652e+00   4.97765398e+00   5.94635296e+00\n",
      "    3.75129747e+00   5.19889307e+00]\n",
      " [  1.08482182e+00   2.31728479e-01   4.51479554e-01  -2.90959142e-03\n",
      "    2.81065297e+00   1.33770335e+00   2.86865973e+00   2.72627115e+00\n",
      "   -5.56877255e-01   3.49793077e+00]]\n",
      "Training set BPC at step 6300: 0.00154 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.61161244 -1.87541258 -0.20355794 -1.18497872 -0.23912592 -2.40100265\n",
      "  -1.35738242 -0.48547089 -3.29506063 -0.55208009]\n",
      " [ 5.65827274  3.36173749  2.57382679  5.15053463  4.19268894  3.2955544\n",
      "   5.90734005  5.26403046  3.45493221  5.83029032]\n",
      " [ 5.94431782  4.71723461  6.56572819  5.83011007  3.9494884   3.48854995\n",
      "   5.00451088  5.93432665  3.75873303  5.25598955]\n",
      " [ 1.10200918  0.39420632  0.49748817  0.32966498  3.12528062  1.55924559\n",
      "   2.98581028  2.68179297 -0.52121872  3.60349512]]\n",
      "Training set BPC at step 6400: 2.61353 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.46055794 -1.83481133 -0.18795824 -1.24936914 -0.17476258 -2.52833343\n",
      "  -1.43795776 -0.39460105 -3.21548057 -0.45244458]\n",
      " [ 5.93209171  3.5447011   2.70924687  5.22811222  4.43078613  3.35159326\n",
      "   6.01488972  5.50963449  3.62214732  6.07264423]\n",
      " [ 6.12475777  4.81577253  6.64344072  5.86830997  4.08464336  3.52719998\n",
      "   5.06562328  6.11569595  3.85576987  5.42244053]\n",
      " [ 1.39925241  0.5880903   0.63140082  0.37607291  3.37495995  1.54096162\n",
      "   3.04485822  2.90474725 -0.33087561  3.83552957]]\n",
      "Training set BPC at step 6500: 1.78205 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.40892184 -1.80403829 -0.10241203 -1.32542157 -0.2434653  -2.54817104\n",
      "  -1.41727519 -0.34237853 -3.22402191 -0.48454201]\n",
      " [ 6.1474123   3.66403723  2.99597192  5.31014967  4.50819683  3.45615101\n",
      "   6.16590405  5.7719245   3.75973892  6.25118685]\n",
      " [ 6.286098    4.87557697  6.78895807  5.88494492  4.12249613  3.56420565\n",
      "   5.13507938  6.2258954   3.92217946  5.50133944]\n",
      " [ 1.55933928  0.71750492  0.93608403  0.44372046  3.41312361  1.64791393\n",
      "   3.20642138  3.20853066 -0.19851375  4.00292397]]\n",
      "Training set BPC at step 6600: 1.92568 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.43088233 -1.72614944 -0.11592472 -1.46476066 -0.16499241 -2.54621744\n",
      "  -1.47111547 -0.46607107 -3.21562028 -0.474424  ]\n",
      " [ 6.24849892  3.87291241  3.09874892  5.31448221  4.68938208  3.54304433\n",
      "   6.2497654   5.81092167  3.88897848  6.40757179]\n",
      " [ 6.31475878  4.95566034  6.80976963  5.86027765  4.21361828  3.59167123\n",
      "   5.14674568  6.2014327   3.96315885  5.60745859]\n",
      " [ 1.68566036  0.9956907   1.06566489  0.41011757  3.62028503  1.75357926\n",
      "   3.29696012  3.24383473 -0.03840003  4.113904  ]]\n",
      "Training set BPC at step 6700: 2.96564 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -1.43903339e+00  -1.72536838e+00   1.35275151e-03  -1.57583666e+00\n",
      "   -1.52353540e-01  -2.67006373e+00  -1.26429749e+00  -4.73278463e-01\n",
      "   -3.20529532e+00  -4.18686956e-01]\n",
      " [  6.40325928e+00   4.02897453e+00   3.34905744e+00   5.38898754e+00\n",
      "    4.85373354e+00   3.58349752e+00   6.57521105e+00   5.86052036e+00\n",
      "    4.03843784e+00   6.53880358e+00]\n",
      " [  6.39190817e+00   5.07847738e+00   6.96446466e+00   5.88722563e+00\n",
      "    4.25999784e+00   3.60862112e+00   5.37530661e+00   6.17940807e+00\n",
      "    4.00646639e+00   5.65102720e+00]\n",
      " [  1.83180583e+00   1.08885670e+00   1.32546461e+00   4.47378308e-01\n",
      "    3.84128332e+00   1.73856056e+00   3.63664103e+00   3.36529374e+00\n",
      "    1.51522309e-01   4.31392479e+00]]\n",
      "Training set BPC at step 6800: 1.85481 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.43376756 -1.70222652  0.12010678 -1.54802012 -0.16656631 -2.69202042\n",
      "  -1.08956099 -0.47612947 -3.27972054 -0.52995992]\n",
      " [ 6.54114485  4.14812183  3.49108171  5.49445724  5.01565409  3.6822989\n",
      "   6.81176949  6.01350403  4.08148623  6.56010962]\n",
      " [ 6.47784758  5.12432957  7.03229809  5.94867086  4.33653975  3.65400505\n",
      "   5.4980464   6.25747681  3.98231721  5.61881828]\n",
      " [ 1.93793392  1.23669922  1.53149235  0.55699182  4.00192881  1.83167922\n",
      "   3.9514873   3.51422906  0.21802036  4.32943249]]\n",
      "Training set BPC at step 6900: 1.28283 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.33440149 -1.81480408  0.14273685 -1.58476245 -0.11575805 -2.60878372\n",
      "  -1.03862345 -0.38638547 -3.16495466 -0.39291793]\n",
      " [ 6.73802233  4.19489956  3.65932417  5.57223845  5.20226955  3.89808059\n",
      "   6.96698999  6.21960831  4.32214737  6.81839943]\n",
      " [ 6.60122776  5.11262083  7.11412716  5.99559593  4.40761185  3.77368069\n",
      "   5.55304956  6.33170795  4.14832211  5.76037359]\n",
      " [ 2.13567758  1.26474392  1.70938587  0.60483515  4.23560572  2.06819272\n",
      "   4.15932131  3.79118729  0.44739652  4.6337347 ]]\n",
      "Training set BPC at step 7000: 5.42391 learning rate: 0.090000\n",
      "memory=\n",
      " [[-1.09352291 -1.78331625  0.15468965 -1.55730355 -0.07620069 -2.65044689\n",
      "  -0.77685583 -0.37079817 -2.99653721 -0.40071404]\n",
      " [ 7.04524422  4.3869586   3.76010609  5.72607231  5.37777233  3.99701452\n",
      "   7.34321451  6.34937239  4.61387444  6.9523797 ]\n",
      " [ 6.87745905  5.27497816  7.17679977  6.08618116  4.52817297  3.84038877\n",
      "   5.8480711   6.41607475  4.33635426  5.86122131]\n",
      " [ 2.39944005  1.38939738  1.79517925  0.74835175  4.38712358  2.11865211\n",
      "   4.50448465  3.90069556  0.76349318  4.71977377]]\n",
      "Training set BPC at step 7100: 4.74063 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.98846751 -1.64371192  0.24109913 -1.50032341 -0.21406697 -2.60148883\n",
      "  -0.61558193 -0.2255832  -2.94947791 -0.4315424 ]\n",
      " [ 7.25193167  4.64652967  4.0471344   5.87541151  5.40740347  4.19588947\n",
      "   7.7014637   6.61930609  4.77365112  7.09068871]\n",
      " [ 7.02255154  5.40066624  7.3435955   6.21641302  4.52697754  4.0011878\n",
      "   6.04427671  6.60839462  4.40897894  5.93755722]\n",
      " [ 2.60853958  1.7192446   2.08346629  0.8616904   4.3711729   2.27148867\n",
      "   4.91848564  4.1748271   0.95332056  4.83323669]]\n",
      "Training set BPC at step 7200: 4.28944 learning rate: 0.090000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[-0.82930756 -1.63312554  0.64615458 -1.42539728 -0.12108073 -2.42326283\n",
      "  -0.34886622 -0.1622186  -2.78540134 -0.45733273]\n",
      " [ 7.49984503  4.80615902  4.51799059  6.04155731  5.60593796  4.4831419\n",
      "   8.08967972  6.80575752  5.02350235  7.19777632]\n",
      " [ 7.19304562  5.49382973  7.64808846  6.30523682  4.65862226  4.19236755\n",
      "   6.31022501  6.74461985  4.57042789  6.01133823]\n",
      " [ 2.87104964  1.85899067  2.63521028  1.04795659  4.56823587  2.58101249\n",
      "   5.32397747  4.31989717  1.23101914  4.89541674]]\n",
      "Training set BPC at step 7300: 2.46253 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.73064899 -1.49785984  0.65072012 -1.31840491  0.09920975 -2.48180509\n",
      "  -0.40224391  0.07966985 -2.74397421 -0.38496062]\n",
      " [ 7.76548433  5.1121459   4.67237711  6.36679459  6.05739927  4.60316944\n",
      "   8.2453928   7.19456291  5.27214289  7.43516541]\n",
      " [ 7.34705257  5.65888405  7.7230978   6.49009705  4.90531445  4.25577974\n",
      "   6.39395571  6.98866224  4.7058506   6.14626217]\n",
      " [ 3.15320134  2.19644308  2.78754592  1.39405     5.08100462  2.66165495\n",
      "   5.43920183  4.76243067  1.48063934  5.12734175]]\n",
      "Training set BPC at step 7400: 1.94003 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.85798019 -1.44330704  0.70444196 -1.45658386  0.0852837  -2.51142097\n",
      "  -0.37494674 -0.06494261 -2.68884945 -0.66817629]\n",
      " [ 7.89065027  5.36089373  4.97345495  6.48810101  6.21220207  4.76400375\n",
      "   8.50337696  7.29312563  5.52962255  7.41902781]\n",
      " [ 7.36730862  5.7953434   7.84586954  6.52767277  4.96220303  4.31924009\n",
      "   6.50999689  7.03577232  4.80926514  6.10447884]\n",
      " [ 3.25917768  2.43970919  3.14143515  1.47061288  5.24704123  2.82284951\n",
      "   5.70559883  4.78817225  1.78867269  5.00670147]]\n",
      "Training set BPC at step 7500: 2.16701 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.73266554 -1.44974041  0.82897705 -1.33722806  0.22440711 -2.2482667\n",
      "  -0.15493521 -0.02032027 -2.62717581 -0.67643142]\n",
      " [ 8.0880537   5.47212839  5.27339458  6.74457836  6.41158676  5.02981758\n",
      "   8.86679935  7.44916105  5.72033882  7.52477455]\n",
      " [ 7.47381926  5.87395811  8.00025654  6.65279102  5.10276413  4.46618748\n",
      "   6.69686699  7.14449787  4.88818598  6.11100578]\n",
      " [ 3.50608754  2.52011514  3.49394035  1.78932774  5.46585608  3.1981616\n",
      "   6.16666365  4.91612768  2.02546406  5.15970087]]\n",
      "Training set BPC at step 7600: 1.42093 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.51238871 -1.39662921  0.93086207 -1.52352083  0.41282856 -2.16676521\n",
      "  -0.03644354  0.11969311 -2.77525377 -0.8132329 ]\n",
      " [ 8.38783455  5.63569832  5.53622389  6.80278492  6.71929932  5.20820856\n",
      "   9.05648327  7.69178963  5.78344393  7.59822083]\n",
      " [ 7.63201332  5.95773888  8.14469147  6.64010954  5.32567739  4.53088045\n",
      "   6.80007744  7.28978062  4.886724    6.11190176]\n",
      " [ 3.88454151  2.70169401  3.7864213   1.79865527  5.76367807  3.43830633\n",
      "   6.39964056  5.19436312  2.04826093  5.20149136]]\n",
      "Training set BPC at step 7700: 1.88565 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.41528797 -1.17247748  0.96954244 -1.4028194   0.45022655 -2.087183\n",
      "  -0.01029495  0.3063387  -2.63745427 -0.74044621]\n",
      " [ 8.64970207  6.02729654  5.67694426  7.05459404  6.8527174   5.41282892\n",
      "   9.27200222  7.93237257  6.05427647  7.74512243]\n",
      " [ 7.74413204  6.19670963  8.19931793  6.80286598  5.41662359  4.65355921\n",
      "   6.8970089   7.41792107  5.02584171  6.19353867]\n",
      " [ 4.20355797  3.11080217  3.95235682  2.04029775  5.87865782  3.6467948\n",
      "   6.61415672  5.50650072  2.36875677  5.36414957]]\n",
      "Training set BPC at step 7800: 1.62596 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -4.68936592e-01  -1.18674171e+00   1.27733457e+00  -1.33033335e+00\n",
      "    6.19621754e-01  -1.95079088e+00   8.21003132e-03   3.77499938e-01\n",
      "   -2.57844257e+00  -5.50670564e-01]\n",
      " [  8.70374966e+00   6.11462736e+00   6.01327562e+00   7.19887590e+00\n",
      "    7.14544630e+00   5.61409712e+00   9.37418079e+00   8.09974861e+00\n",
      "    6.18328953e+00   8.08265591e+00]\n",
      " [  7.73080778e+00   6.22568750e+00   8.40266037e+00   6.89790344e+00\n",
      "    5.55859184e+00   4.74907923e+00   6.92183733e+00   7.51742649e+00\n",
      "    5.05129719e+00   6.40081406e+00]\n",
      " [  4.27074146e+00   3.20146585e+00   4.37874794e+00   2.18786454e+00\n",
      "    6.25181437e+00   3.91303444e+00   6.74914694e+00   5.68458366e+00\n",
      "    2.55636954e+00   5.72845554e+00]]\n",
      "Training set BPC at step 7900: 3.57201 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.26150051 -1.12065005  1.30669546 -1.38617504  0.70712703 -1.71003973\n",
      "  -0.09273794  0.42238227 -2.45832539 -0.59532589]\n",
      " [ 8.97692966  6.24490929  6.15783405  7.26846504  7.32638884  5.99636889\n",
      "   9.40983963  8.2883749   6.34015751  8.1814909 ]\n",
      " [ 7.95715904  6.34744453  8.50983906  6.95911455  5.69565487  5.01053905\n",
      "   6.97854662  7.6279192   5.16905975  6.47193432]\n",
      " [ 4.52257681  3.29429913  4.49292183  2.19447803  6.41660643  4.3110199\n",
      "   6.68697548  5.87122297  2.72061419  5.77578878]]\n",
      "Training set BPC at step 8000: 1.60037 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.05063578 -1.13470769  1.45887685 -1.36616898  0.72131056 -1.65064824\n",
      "   0.11154307  0.52729034 -2.38193917 -0.5563882 ]\n",
      " [ 9.3307066   6.35302305  6.31918573  7.44152117  7.39925194  6.104352\n",
      "   9.65672588  8.45276642  6.47940588  8.26680756]\n",
      " [ 8.18427849  6.37502718  8.6443882   7.0157547   5.71853781  5.08153057\n",
      "   7.14437056  7.71578836  5.30255651  6.49301291]\n",
      " [ 4.89961481  3.41848135  4.66119003  2.40341091  6.50583935  4.4221344\n",
      "   6.96278191  6.0740819   2.81538916  5.89808035]]\n",
      "Training set BPC at step 8100: 1.38984 learning rate: 0.090000\n",
      "memory=\n",
      " [[  3.03999637e-03  -1.07640469e+00   1.77953184e+00  -1.43103707e+00\n",
      "    8.96773875e-01  -1.77032948e+00   5.90660125e-02   4.33552325e-01\n",
      "   -2.39773226e+00  -5.99904418e-01]\n",
      " [  9.59535885e+00   6.54088354e+00   6.69141865e+00   7.57821083e+00\n",
      "    7.73443460e+00   6.16752625e+00   9.84695721e+00   8.59165955e+00\n",
      "    6.60352612e+00   8.35608959e+00]\n",
      " [  8.30877590e+00   6.47444439e+00   8.92653847e+00   7.08190680e+00\n",
      "    5.94323444e+00   5.11456728e+00   7.22800446e+00   7.75269651e+00\n",
      "    5.37209511e+00   6.53982878e+00]\n",
      " [  5.18753052e+00   3.61615491e+00   5.04032183e+00   2.49850750e+00\n",
      "    6.82291412e+00   4.41335011e+00   7.11344719e+00   6.19438028e+00\n",
      "    2.91023779e+00   5.95384169e+00]]\n",
      "Training set BPC at step 8200: 1.57305 learning rate: 0.090000\n",
      "memory=\n",
      " [[-0.0839835  -1.07565439  1.77136004 -1.54987776  0.86555409 -1.93295586\n",
      "   0.064683    0.3883054  -2.32107115 -0.7848472 ]\n",
      " [ 9.65406036  6.59703875  6.74970913  7.5863533   7.87239742  6.15559912\n",
      "   9.98131847  8.6541605   6.83061218  8.3229475 ]\n",
      " [ 8.29880238  6.4709692   8.94275284  7.07367277  5.990767    5.09322596\n",
      "   7.28449106  7.78944683  5.49905634  6.48477507]\n",
      " [ 5.24222374  3.70196986  5.10739803  2.45651817  6.95330524  4.33349419\n",
      "   7.24383879  6.21290445  3.14834547  5.86829948]]\n",
      "Training set BPC at step 8300: 1.69620 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.11375899  -1.14027274   1.76295292  -1.60482764   0.82221776\n",
      "   -1.88767838   0.05523004   0.31352502  -2.40272641  -0.99167305]\n",
      " [  9.67183304   6.59236193   6.81626797   7.64374733   7.90632296\n",
      "    6.21904135  10.05093861   8.68149948   6.81767273   8.2347374 ]\n",
      " [  8.29432011   6.44708967   9.00882053   7.02056122   5.97659349\n",
      "    5.15383148   7.29940271   7.75223207   5.4797821    6.34817553]\n",
      " [  5.26751852   3.70279264   5.12403536   2.60696745   7.01773357\n",
      "    4.39432955   7.3378644    6.27963638   3.12953949   5.79741049]]\n",
      "Training set BPC at step 8400: 2.86658 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.29443905  -1.2147826    1.80971813  -1.62874806   0.67925352\n",
      "   -1.76315701   0.0415851    0.23977214  -2.5218966   -1.05763221]\n",
      " [  9.61500168   6.58750105   6.89941263   7.66809845   7.92306995\n",
      "    6.34507561  10.07500076   8.67928219   6.78847313   8.22600555]\n",
      " [  8.25159073   6.40842962   9.01924419   7.02215481   5.97160196\n",
      "    5.21210098   7.27345848   7.71866035   5.43080425   6.30931997]\n",
      " [  5.14189672   3.70805931   5.26721573   2.63665485   6.98920822\n",
      "    4.58889723   7.40631771   6.28065634   3.08431768   5.7981739 ]]\n",
      "Training set BPC at step 8500: 3.23333 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.27747244  -1.21203125   1.74899697  -1.60154974   0.63181841\n",
      "   -1.79877043   0.24778737   0.46812502  -2.38856339  -1.04438472]\n",
      " [  9.77616978   6.7140336    6.9517374    7.78101635   8.03024769\n",
      "    6.4840126   10.32566261   8.98545361   7.02218437   8.34878731]\n",
      " [  8.30608082   6.46830654   9.04254055   7.05481291   6.01733398\n",
      "    5.27126169   7.40325117   7.94856644   5.58201981   6.3708868 ]\n",
      " [  5.33563519   3.83506966   5.28950882   2.78673196   7.07857609\n",
      "    4.71745634   7.74634981   6.58007193   3.34057212   5.91341162]]\n",
      "Training set BPC at step 8600: 1.55846 learning rate: 0.090000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ -0.19695273  -1.31925404   1.76827443  -1.56902218   0.58621329\n",
      "   -1.76562679   0.1365654    0.29833612  -2.42587185  -1.03654504]\n",
      " [  9.94681549   6.751441     6.99892902   7.8945303    8.07913113\n",
      "    6.60175467  10.33503437   8.92747593   7.05576897   8.48073292]\n",
      " [  8.3850832    6.3662672    9.0163517    7.06058359   5.99990273\n",
      "    5.28341436   7.35044813   7.86099863   5.52921534   6.43428898]\n",
      " [  5.55430794   3.98695683   5.40788412   2.97508979   7.16089439\n",
      "    4.90641975   7.78321171   6.52419519   3.43940878   6.03893948]]\n",
      "Training set BPC at step 8700: 1.21063 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.31517255  -1.33992159   1.69209814  -1.72289538   0.44168884\n",
      "   -1.6601094    0.23630601   0.33053434  -2.48439431  -1.1378746 ]\n",
      " [ 10.00493145   6.76539278   7.02415848   7.86529636   8.04575062\n",
      "    6.71139431  10.60994244   9.01429176   7.06646585   8.48649025]\n",
      " [  8.39905643   6.30516148   8.95051289   6.9801178    5.88749743\n",
      "    5.27242851   7.48066807   7.84952831   5.5177269    6.35200071]\n",
      " [  5.56746817   4.09134245   5.49233532   2.95445871   7.19566584\n",
      "    5.17207003   8.10964203   6.69728327   3.46576643   6.11491394]]\n",
      "Training set BPC at step 8800: 1.33083 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.42078304  -1.44754469   1.62559307  -1.79949594   0.25638244\n",
      "   -1.67725778   0.0358106    0.17424415  -2.424896    -1.0210588 ]\n",
      " [ 10.09656048   6.77464056   7.13600016   7.9867444    8.09821796\n",
      "    6.77955484  10.57904339   9.0550909    7.2566185    8.62007523]\n",
      " [  8.4414196    6.28247023   8.96282291   7.03465366   5.82495594\n",
      "    5.30884647   7.45191622   7.86154985   5.65701675   6.43872118]\n",
      " [  5.60175371   4.09764004   5.63291645   3.05753589   7.28767681\n",
      "    5.24576998   8.00513744   6.67364168   3.62762856   6.28762817]]\n",
      "Training set BPC at step 8900: 1.14663 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -5.48265100e-01  -1.09833705e+00   1.81110835e+00  -1.72347391e+00\n",
      "    3.67350668e-01  -1.71824765e+00   2.57119536e-05   2.18074657e-02\n",
      "   -2.53304148e+00  -9.91697073e-01]\n",
      " [  1.01141062e+01   7.06732941e+00   7.31813478e+00   8.14182472e+00\n",
      "    8.22546101e+00   6.80291748e+00   1.05962925e+01   8.98892784e+00\n",
      "    7.24439526e+00   8.74975109e+00]\n",
      " [  8.43785286e+00   6.49383545e+00   9.12054634e+00   7.16673374e+00\n",
      "    5.88229322e+00   5.29181004e+00   7.45350838e+00   7.77058601e+00\n",
      "    5.59206867e+00   6.48535252e+00]\n",
      " [  5.57423258e+00   4.47416353e+00   5.83366108e+00   3.18257475e+00\n",
      "    7.48578930e+00   5.28388262e+00   8.02116013e+00   6.61991501e+00\n",
      "    3.63181591e+00   6.45527267e+00]]\n",
      "Training set BPC at step 9000: 0.00534 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.51457316  -0.98721135   1.91823947  -1.53674889   0.45088947\n",
      "   -1.91093397   0.01542709   0.05489375  -2.39275265  -0.96028864]\n",
      " [ 10.32198811   7.21165037   7.60637522   8.38166523   8.3748188\n",
      "    6.84368992  10.6914196    9.16679478   7.46295595   8.84933758]\n",
      " [  8.55377197   6.59918404   9.28992844   7.29193211   5.97526598\n",
      "    5.33495712   7.53550863   7.94050694   5.79187965   6.55094147]\n",
      " [  5.77612734   4.62751007   6.1296587    3.48684239   7.64568186\n",
      "    5.19637394   8.07566833   6.70039797   3.78423452   6.54667568]]\n",
      "Training set BPC at step 9100: 1.16181 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.53606147  -1.04155433   1.69276631  -1.88274622   0.49527383\n",
      "   -1.97846317  -0.07102048  -0.04175822  -2.57471967  -1.06951094]\n",
      " [ 10.35803699   7.29596233   7.54126644   8.23764324   8.51429749\n",
      "    6.85322142  10.75239563   9.13710499   7.41950846   8.88565254]\n",
      " [  8.59279442   6.62920427   9.2687254    7.12056684   6.03862047\n",
      "    5.35479593   7.55726051   7.90515041   5.75316048   6.51608992]\n",
      " [  5.78182316   4.6886673    5.94727802   3.30053997   7.82691479\n",
      "    5.16488647   8.10494709   6.66298389   3.6763947    6.5936799 ]]\n",
      "Training set BPC at step 9200: 2.98458 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.59191644  -1.10424972   1.74631786  -1.72178125   0.52297813\n",
      "   -1.9823513    0.02705882   0.20833874  -2.54662776  -1.1449759 ]\n",
      " [ 10.42053795   7.35895014   7.6406064    8.40150833   8.56304169\n",
      "    6.92550278  10.95930481   9.46563244   7.54663801   8.90809631]\n",
      " [  8.58117104   6.65604544   9.31841373   7.28435135   6.0472126\n",
      "    5.32321739   7.67193508   8.15279293   5.80397272   6.50026083]\n",
      " [  5.87514687   4.73899364   6.09080172   3.45383382   7.92353725\n",
      "    5.32757568   8.3345089    6.99964762   3.83428431   6.61227703]]\n",
      "Training set BPC at step 9300: 1.60916 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.38574049  -0.8638947    1.79349017  -1.71590638   0.51858044\n",
      "   -1.9635601    0.0289055    0.21868861  -2.53665423  -1.16297603]\n",
      " [ 10.736022     7.63640881   7.83632326   8.51199722   8.64300442\n",
      "    7.12290239  11.1740799    9.6313715    7.65697432   9.0319891 ]\n",
      " [  8.84951973   6.9314127    9.44600582   7.36713266   6.07586098\n",
      "    5.4295702    7.75734806   8.24654675   5.85953999   6.59926081]\n",
      " [  6.14367723   4.94735146   6.26563454   3.53021932   8.0065403\n",
      "    5.5181284    8.56668854   7.15638304   3.94062114   6.66553926]]\n",
      "Training set BPC at step 9400: 3.60964 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.39558062  -0.67518294   2.03616548  -1.65542328   0.88024533\n",
      "   -1.73219657   0.33521664   0.31600732  -2.57041073  -1.14208972]\n",
      " [ 10.81609249   7.85090017   8.11349392   8.70485115   9.08393478\n",
      "    7.30594921  11.46775818   9.73121834   7.72644091   9.10936165]\n",
      " [  8.96090698   7.13398552   9.64829063   7.52019119   6.43602657\n",
      "    5.58155966   8.0122776    8.30258083   5.9377923    6.65499353]\n",
      " [  6.13118696   5.12375402   6.58145714   3.66583419   8.4276762\n",
      "    5.74714184   8.86879253   7.29993439   3.9363575    6.72940397]]\n",
      "Training set BPC at step 9500: 2.61838 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.49047077  -0.66556287   2.08823609  -1.80836475   0.85450548\n",
      "   -2.03569508   0.23599491   0.12594469  -2.69851232  -1.21106434]\n",
      " [ 10.81739712   7.96853399   8.24403858   8.6814394    9.22035313\n",
      "    7.21961546  11.46740246   9.70595551   7.77958536   9.13499737]\n",
      " [  8.9148674    7.19663048   9.67786217   7.43593311   6.41440153\n",
      "    5.51335907   7.97816658   8.17819881   5.88600159   6.601861  ]\n",
      " [  6.14543152   5.23915958   6.77147484   3.65595269   8.66232681\n",
      "    5.55111885   8.86390495   7.32093525   4.04094839   6.8222332 ]]\n",
      "Training set BPC at step 9600: 2.18838 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.49843898  -0.72435695   2.25287533  -1.98947859   0.98169398\n",
      "   -1.97138381   0.10466277   0.10892035  -2.64391208  -1.08676898]\n",
      " [ 10.85798168   7.99338245   8.42532921   8.64409256   9.38888454\n",
      "    7.34183884  11.44828129   9.79931259   7.86089373   9.3013649 ]\n",
      " [  8.93606091   7.24420118   9.83710289   7.40935373   6.55476952\n",
      "    5.60402775   7.97251129   8.21039963   5.96632099   6.74321318]\n",
      " [  6.17817307   5.19304991   6.94504118   3.53636122   8.81468868\n",
      "    5.66682005   8.77390194   7.42893124   4.10387135   6.9737587 ]]\n",
      "Training set BPC at step 9700: 3.37794 learning rate: 0.090000\n",
      "memory=\n",
      " [[ -0.503766    -0.77349198   2.2816546   -1.96106279   0.99599773\n",
      "   -1.95216584   0.11776076   0.18008369  -2.66929126  -1.05596077]\n",
      " [ 10.89090919   7.94247198   8.46610641   8.71250248   9.41505718\n",
      "    7.39947367  11.46951294   9.86127853   7.86972237   9.35781288]\n",
      " [  8.96765041   7.16264725   9.87593079   7.4751339    6.59171343\n",
      "    5.64209747   8.00485039   8.30831242   5.98174667   6.75926542]\n",
      " [  6.21638966   5.21201181   7.00451422   3.5948112    8.83146\n",
      "    5.73509026   8.79309845   7.46229696   4.10019636   7.07910347]]\n",
      "Training set BPC at step 9800: 2.39491 learning rate: 0.090000\n",
      "memory=\n",
      " [[  0.06756996  -0.53158653   2.50138426  -1.60825658   1.13958693\n",
      "   -1.92037046   0.45497933   0.62261891  -2.4247148   -0.89355838]\n",
      " [ 11.33509159   8.2195549    8.73710346   9.02126884   9.61106014\n",
      "    7.48410463  11.82518196  10.2815237    8.11358738   9.53041077]\n",
      " [  9.3605814    7.42664528  10.06833172   7.72296476   6.74925709\n",
      "    5.71194267   8.28961372   8.65883541   6.15041494   6.92500448]\n",
      " [  6.72707558   5.44651556   7.31368446   3.96673822   9.02628326\n",
      "    5.81542921   9.17371082   7.92094135   4.41074419   7.24218178]]\n",
      "Training set BPC at step 9900: 2.35350 learning rate: 0.090000\n"
     ]
    }
   ],
   "source": [
    "# How often the test loss on validation batch will be computed. \n",
    "summary_frequency = 100\n",
    "\n",
    "# Create session to execute graph.\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "# Create summary writers, point them to LOG_DIR.\n",
    "train_writer = tf.summary.FileWriter(LOG_DIR + '/train', sess.graph)\n",
    "valid_writer = tf.summary.FileWriter(LOG_DIR + '/valid')\n",
    "test_writer = tf.summary.FileWriter(LOG_DIR + '/test')\n",
    "\n",
    "# Initialize global variables.\n",
    "tf.global_variables_initializer().run()\n",
    "print('Variables initialized')\n",
    "\n",
    "\n",
    "# Create initial previous read and update - full of zeros. \n",
    "prev_rw_seq_batch = list()\n",
    "prev_uw_seq_batch = list()\n",
    "for i in range(SEQ_LENGTH):\n",
    "    prev_rw_seq_batch.append(np.zeros([BATCH_SIZE, MEMORY_SLOTS]))\n",
    "    prev_uw_seq_batch.append(np.zeros([BATCH_SIZE, MEMORY_SLOTS]))\n",
    "\n",
    "num_steps = 10000 #train_size // (BATCH_SIZE*SEQ_LENGTH) #70001\n",
    "print(\"Number of iterations per epoch =\", num_steps)\n",
    "for step in range(num_steps):\n",
    "    input_seq_batch_, memory_, prev_rw_seq_batch, prev_uw_seq_batch, summaries, _, loss_, lr_ = sess.run([\n",
    "        input_seq_batch, memory, read_weights_seq_batch, update_weights_seq_batch, merged_summaries, optimizer, loss, learning_rate],\n",
    "        feed_dict=create_feed_dict(\"train\"))#batch_seq))\n",
    "    \n",
    "    # Add summary.\n",
    "    train_writer.add_summary(summaries, step*BATCH_SIZE*SEQ_LENGTH)\n",
    "    train_writer.flush()\n",
    "\n",
    "    # Every (100) steps collect statistics.\n",
    "    if step % summary_frequency == 0:\n",
    "        print(\"memory=\\n\", memory_)\n",
    "        # Print loss from last batch.\n",
    "        print('Training set BPC at step %d: %0.5f learning rate: %f' % (step, loss_, lr_))\n",
    "    \n",
    "        # Validation set BPC.\n",
    "        #v_summaries, v_loss = sess.run([merged_summaries, loss], feed_dict=create_feed_dict(\"valid\"))\n",
    "        #print(\"Validation set BPC: %.5f\" % v_loss)\n",
    "        #valid_writer.add_summary(v_summaries, step*BATCH_SIZE*SEQ_LENGTH)\n",
    "        #valid_writer.flush()\n",
    "    # End of statistics collection\n",
    "\n",
    "# Test set BPC.\n",
    "#print(\"Calculating BPC on test dataset\")\n",
    "#t_summary, t_loss = sess.run([merged_summaries, loss], feed_dict=create_feed_dict(\"test\"))\n",
    "#print(\"Final test set BPC: %.5f\" % t_loss)\n",
    "#test_writer.add_summary(t_summary, step*BATCH_SIZE*SEQ_LENGTH)\n",
    "#test_writer.flush()\n",
    "    \n",
    "# Close writers and session.\n",
    "train_writer.close()\n",
    "valid_writer.close()\n",
    "test_writer.close()\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
