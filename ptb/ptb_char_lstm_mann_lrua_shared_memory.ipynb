{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import tarfile\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import shutil \n",
    "import random\n",
    "\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "# Dirs - must be absolute paths!\n",
    "LOG_DIR = '/tmp/tf/ptb_char_lstm_mann_lrua_shared_memory/h16b1s1lru3_no_trunk/'\n",
    "# Local dir where PTB files will be stored.\n",
    "PTB_DIR = '/home/tkornuta/data/ptb/'\n",
    "\n",
    "# Filenames.\n",
    "TRAIN = \"ptb.train.txt\"\n",
    "VALID = \"ptb.valid.txt\"\n",
    "TEST = \"ptb.test.txt\"\n",
    "\n",
    "# Size of the hidden state\n",
    "HIDDEN_SIZE = 5\n",
    "\n",
    "# Size of batch\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Length of sequence (=  number of units of controller (recurrent layer))\n",
    "SEQ_LENGTH = 1\n",
    "\n",
    "#### MANN-related parameters.\n",
    "# Size of the local memory of each cell.\n",
    "MEMORY_SLOTS = 10\n",
    "\n",
    "# Number of smallest elements - used in LRUA scheme.\n",
    "N_SMALLEST = 1\n",
    "\n",
    "# \"Update weight decay\".\n",
    "GAMMA = 0.95\n",
    "\n",
    "# Eps for normalization in visualization\n",
    "EPS = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified /home/tkornuta/data/ptb/simple-examples.tgz ( 34869662 )\n"
     ]
    }
   ],
   "source": [
    "def maybe_download_ptb(path, \n",
    "                       filename='simple-examples.tgz', \n",
    "                       url='http://www.fit.vutbr.cz/~imikolov/rnnlm/', \n",
    "                       expected_bytes =34869662):\n",
    "  # Eventually create the PTB dir.\n",
    "  if not tf.gfile.Exists(path):\n",
    "    tf.gfile.MakeDirs(path)\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  _filename = path+filename\n",
    "  if not os.path.exists(_filename):\n",
    "    print('Downloading %s...' % filename)\n",
    "    _filename, _ = urlretrieve(url+filename, _filename)\n",
    "  statinfo = os.stat(_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', (_filename), '(', statinfo.st_size, ')')\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + _filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download_ptb(PTB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check/maybe download PTB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract dataset-related files from the PTB archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_ptb(path, filename='simple-examples.tgz', files=[\"ptb.train.txt\", \"ptb.valid.txt\", \"ptb.test.txt\", \n",
    "                                       \"ptb.char.train.txt\", \"ptb.char.valid.txt\", \"ptb.char.test.txt\"]):\n",
    "    \"\"\"Extracts files from PTB archive.\"\"\"\n",
    "    # Extract\n",
    "    tar = tarfile.open(path+filename)\n",
    "    tar.extractall(path)\n",
    "    tar.close()\n",
    "    # Copy files\n",
    "    for file in files:\n",
    "        shutil.copyfile(PTB_DIR+\"simple-examples/data/\"+file, PTB_DIR+file)\n",
    "    # Delete directory\n",
    "    shutil.rmtree(PTB_DIR+\"simple-examples/\")        \n",
    "\n",
    "extract_ptb(PTB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train, valid and test texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5101618  aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memote\n",
      "399782  consumers may want to move their telephones a little closer to \n",
      "449945  no it was n't black monday \n",
      " but while the new york stock excha\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename, path):\n",
    "    with open(path+filename, 'r') as myfile:\n",
    "        data=myfile.read()# .replace('\\n', '')\n",
    "        return data\n",
    "\n",
    "train_text = read_data(TRAIN, PTB_DIR)\n",
    "train_size=len(train_text)\n",
    "print(train_size, train_text[:100])\n",
    "\n",
    "valid_text = read_data(VALID, PTB_DIR)\n",
    "valid_size=len(valid_text)\n",
    "print(valid_size, valid_text[:64])\n",
    "\n",
    "test_text = read_data(TEST, PTB_DIR)\n",
    "test_size=len(test_text)\n",
    "print(test_size, test_text[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to map characters to vocabulary IDs and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size =  59\n",
      "65\n",
      "33 1 58 26 0 0\n",
      "a A\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 59 # [A-Z] + [a-z] + ' ' +few 'in between; + punctuation\n",
    "first_letter = ord(string.ascii_uppercase[0]) # ascii_uppercase before lowercase! \n",
    "print(\"vocabulary size = \", vocabulary_size)\n",
    "print(first_letter)\n",
    "\n",
    "def char2id(char):\n",
    "  \"\"\" Converts char to id (int) with one-hot encoding handling of unexpected characters\"\"\"\n",
    "  if char in string.ascii_letters:# or char in string.punctuation or char in string.digits:\n",
    "    return ord(char) - first_letter + 1\n",
    "  elif char == ' ':\n",
    "    return 0\n",
    "  else:\n",
    "    # print('Unexpected character: %s' % char)\n",
    "    return 0\n",
    "  \n",
    "def id2char(dictid):\n",
    "  \"\"\" Converts single id (int) to character\"\"\"\n",
    "  if dictid > 0:\n",
    "    return chr(dictid + first_letter - 1)\n",
    "  else:\n",
    "    return ' '\n",
    "\n",
    "def characters(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  characters back into its (most likely) character representation.\"\"\"\n",
    "  return [id2char(c) for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "  \"\"\"Convert a sequence of batches back into their (most likely) string\n",
    "  representation.\"\"\"\n",
    "  s = [''] * batches[0].shape[0]\n",
    "  for b in batches:\n",
    "    s = [''.join(x) for x in zip(s, characters(b))]\n",
    "  return s\n",
    "\n",
    "#print(len(string.punctuation))\n",
    "#for i in string.ascii_letters:\n",
    "#    print (i, char2id(i))\n",
    "\n",
    "\n",
    "print(char2id('a'), char2id('A'), char2id('z'), char2id('Z'), char2id(' '), char2id('Ã¯'))\n",
    "print(id2char(char2id('a')), id2char(char2id('A')))\n",
    "#print(id2char(65), id2char(33), id2char(90), id2char(58), id2char(0))\n",
    "#bankno\n",
    "sample = np.zeros(shape=(1, vocabulary_size), dtype=np.float)\n",
    "sample[0, char2id(' ')] = 1.0\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper class for batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, seq_length, vocab_size):\n",
    "    \"\"\"\n",
    "    Initializes the batch generator object. Stores the variables and first \"letter batch\".\n",
    "    text is text to be processed\n",
    "    batch_size is size of batch (number of samples)\n",
    "    seq_length represents the length of sequence\n",
    "    vocab_size is number of words in vocabulary (assumes one-hot encoding)\n",
    "    \"\"\"\n",
    "    # Store input parameters.\n",
    "    self._text = text\n",
    "    self._text_size = len(text)\n",
    "    self._batch_size = batch_size\n",
    "    self._seq_length = seq_length\n",
    "    self._vocab_size = vocab_size\n",
    "    # Divide text into segments depending on number of batches, each segment determines a cursor position for a batch.\n",
    "    segment = self._text_size // batch_size\n",
    "    # Set initial cursor position.\n",
    "    self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "    # Store first \"letter batch\".\n",
    "    self._last_letter_batch = self._next_letter_batch()\n",
    "  \n",
    "  def _next_letter_batch(self):\n",
    "    \"\"\"\n",
    "    Returns a batch containing of encoded single letters depending on the current batch \n",
    "    cursor positions in the data.\n",
    "    Returned \"letter batch\" is of size batch_size x vocab_size\n",
    "    \"\"\"\n",
    "    letter_batch = np.zeros(shape=(self._batch_size, self._vocab_size), dtype=np.float)\n",
    "    # Iterate through \"samples\"\n",
    "    for b in range(self._batch_size):\n",
    "      # Set 1 in position pointed out by one-hot char encoding.\n",
    "      letter_batch[b, char2id(self._text[self._cursor[b]])] = 1.0\n",
    "      self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "    return letter_batch\n",
    "  \n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "    the last batch of the previous array, followed by num_unrollings new ones.\n",
    "    \"\"\"\n",
    "    # First add last letter from previous batch (the \"additional one\").\n",
    "    batches = [self._last_letter_batch]\n",
    "    for step in range(self._seq_length):\n",
    "      batches.append(self._next_letter_batch())\n",
    "    # Store last \"letter batch\" for next batch.\n",
    "    self._last_letter_batch = batches[-1]\n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(1, 59)\n"
     ]
    }
   ],
   "source": [
    "# Trick - override first 10 chars\n",
    "#list1 = list(train_text)\n",
    "#for i in range(2):\n",
    "#    list1[i] = 'z'\n",
    "#train_text = ''.join(list1)\n",
    "#print(\"Train set =\", train_text[0:100])\n",
    "\n",
    "# Create objects for training, validation and testing batch generation.\n",
    "train_batches = BatchGenerator(train_text, BATCH_SIZE, SEQ_LENGTH, vocabulary_size)\n",
    "\n",
    "# Get first training batch.\n",
    "batch = train_batches.next()\n",
    "print(len(batch))\n",
    "print(batch[0].shape)\n",
    "#print(\"Batch = \", batch)\n",
    "#print(batches2string(batch))\n",
    "#print(\"batch len = num of enrollings\",len(batch))\n",
    "#for i in range(num_unrollings):\n",
    "#    print(\"i = \", i, \"letter=\", batches2string(batch)[0][i][0], \"bits = \", batch[i][0])\n",
    "\n",
    "\n",
    "# For validation  - process the whole text as one big batch.\n",
    "VALID_BATCH_SIZE = int(np.floor(valid_size/SEQ_LENGTH))\n",
    "valid_batches = BatchGenerator(valid_text, VALID_BATCH_SIZE, SEQ_LENGTH, vocabulary_size)\n",
    "valid_batch = valid_batches.next()\n",
    "#print (VALID_BATCH_SIZE)\n",
    "#print(len(valid_batch))\n",
    "#print(valid_batch[0].shape)\n",
    "\n",
    "# For texting  - process the whole text as one big batch.\n",
    "TEST_BATCH_SIZE = int(np.floor(test_size/SEQ_LENGTH))\n",
    "test_batches = BatchGenerator(test_text, TEST_BATCH_SIZE, SEQ_LENGTH, vocabulary_size)\n",
    "# Get single batch! \n",
    "#test_batch = test_batches.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell definition OK\n"
     ]
    }
   ],
   "source": [
    "# Definition of the cell computation.\n",
    "def controller_cell(input_, # input x\n",
    "                    memory_input_, # read vector from the memory returned by previous cell\n",
    "                    prev_output_, # output of the previous cell\n",
    "                    prev_cell_state_, # previous cell state\n",
    "                    prev_read_weights_batch_, # read weights from previous time state (t-1) \n",
    "                    prev_update_weights_batch_, # update weights from previous time state (t-1)\n",
    "                    name_):\n",
    "    \"\"\"Create a controller with local memory cell\"\"\"\n",
    "    \"\"\"First dimensions of each of the computational nodes below is \"derrived\" from BATCH_SIZE\"\"\"\n",
    "    with tf.name_scope(name_):\n",
    "\n",
    "        with tf.name_scope(\"LSTM\"):\n",
    "            # LSTM cell equations according to Christopher Olah blog.\n",
    "            # colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "            # Concatenate intyp x with h_prev (\"prev output\") TODO: and memory.\n",
    "            i_h_m = tf.concat([input_, prev_output_, memory_input_], 1)\n",
    "\n",
    "            # Calculate forget, input and output gate activations.\n",
    "            forget_gate = tf.sigmoid(tf.matmul(i_h_m, Wf) + bf, name=\"Forget_gate\")\n",
    "            input_gate = tf.sigmoid(tf.matmul(i_h_m, Wi) + bi, name=\"Input_gate\")\n",
    "            output_gate = tf.sigmoid(tf.matmul(i_h_m, Wo) + bo, name=\"Output_gate\")\n",
    "\n",
    "            # Update of the cell state C~.\n",
    "            cell_update = tf.tanh(tf.matmul(i_h_m, Wc) + bc, name=\"Cell_update\")\n",
    "            # New cell state C.\n",
    "            cell_state = tf.add(forget_gate * prev_cell_state_, input_gate * cell_update, name = \"Cell_state\")\n",
    "            # Calculate h - \"output\".\n",
    "            cell_output = output_gate * tf.tanh(cell_state)\n",
    "            \n",
    "        with tf.name_scope(\"Keys\"):\n",
    "            # Calculate keys - read and add.\n",
    "            k_t = tf.tanh(tf.matmul(cell_output, W_key) + b_key) # (batch_size, nb_reads, memory_size[1])\n",
    "            #a_t = tf.tanh(tf.matmul(cell_output, W_add) + b_add) # (batch_size, nb_reads, memory_size[1])\n",
    "            alpha = tf.sigmoid(tf.matmul(cell_output, W_alpha) + b_alpha) # (batch_size, nb_reads, 1)\n",
    "\n",
    "            # Add histograms to TensorBoard.\n",
    "            k_t_hist = tf.summary.histogram(\"k_t\", k_t)\n",
    "            #a_t_hist = tf.summary.histogram(\"a_t\", a_t)\n",
    "            \n",
    "        # Read from the memory.\n",
    "        with tf.name_scope(\"Read_head\"):\n",
    "            \n",
    "            # Normalize batch.\n",
    "            norm_batch = tf.nn.l2_normalize(k_t,1)\n",
    "            # Normalize memory.\n",
    "            norm_memory = tf.nn.l2_normalize(memory,0)\n",
    "            # Calculate cosine similarity.\n",
    "            similarity_batch = tf.matmul(norm_batch, norm_memory)\n",
    "            # Calculate read weights based on similarity.\n",
    "            read_weights_batch = tf.nn.softmax(similarity_batch)\n",
    "\n",
    "            # Add to list returned as \"previous read weights\".\n",
    "            read_weights_seq_batch.append(read_weights_batch)\n",
    "            \n",
    "            # Add histograms to TensorBoard.\n",
    "            norm_batch_hist = tf.summary.histogram(\"norm_batch\", norm_batch)\n",
    "            norm_batch_hist = tf.summary.histogram(\"norm_batch\", norm_batch)\n",
    "            norm_memory_hist = tf.summary.histogram(\"norm_memory\", norm_memory)\n",
    "            similarity_batch_hist = tf.summary.histogram(\"cosine_similarity_batch\", similarity_batch)\n",
    "            read_weights_batch_hist = tf.summary.histogram(\"read_weights_batch\", read_weights_batch)\n",
    "        \n",
    "        \n",
    "        with tf.name_scope(\"Memory_output\"):\n",
    "            # Calcualte read vector.\n",
    "            memory_output_batch = tf.tensordot(read_weights_batch, tf.transpose(memory), axes=1, name=\"Memory_output_batch_r\")   \n",
    "            # Add histograms to TensorBoard.\n",
    "            memory_output_batch_hist = tf.summary.histogram(\"memory_output_batch\", memory_output_batch)\n",
    "\n",
    "        with tf.name_scope(\"Write_head\"):\n",
    "            # \"Truncation scheme to update the least-used positions\".\n",
    "            # First, find (size-n) top elements (in each \"batch sample\"/head separatelly).\n",
    "            top = tf.nn.top_k(-prev_update_weights_batch_, N_SMALLEST)\n",
    "            # To get boolean True/False values, you can first get the k-th value and then use tf.greater_equal:\n",
    "            kth = tf.reduce_min(top.values, axis=1, keep_dims=True)\n",
    "            top2 = tf.greater_equal(-prev_update_weights_batch_, kth)\n",
    "            # And finally - cast it to n smallest elements.\n",
    "            prev_smallest_lru_weights = tf.cast(top2, tf.float32)\n",
    "\n",
    "            #write_weights_seq_batch.append(prev_smallest_lru_weights)\n",
    "            write_weights_batch = tf.add(tf.sigmoid(alpha) * prev_read_weights_batch_,\n",
    "                                   (1.0 - tf.sigmoid(alpha)) * prev_smallest_lru_weights,\n",
    "                                   name=\"Write_weights_ww\")\n",
    "\n",
    "            # Add histograms to TensorBoard.\n",
    "            smallest_lru_weight_batch_hist = tf.summary.histogram(\"smallest_lru_weight_batch\", prev_smallest_lru_weights)\n",
    "            write_weights_batch_hist = tf.summary.histogram(\"write_weights_batch\", write_weights_batch)\n",
    "\n",
    "        with tf.name_scope(\"Update_head\"):\n",
    "            # This relies on prev. weights and will be used in fact in the NEXT step.\n",
    "            update_weights_batch = tf.add(GAMMA * prev_update_weights_batch_,\n",
    "                                            read_weights_batch + write_weights_batch,\n",
    "                                            name=\"Update_weights_uw\")\n",
    "            \n",
    "            # Add to list returned as \"previous update weights\".\n",
    "            update_weights_seq_batch.append(update_weights_batch)\n",
    "            # Add histograms to TensorBoard.\n",
    "            update_weights_batch_hist = tf.summary.histogram(\"update_weights_batch\", update_weights_batch)\n",
    "\n",
    "            \n",
    "    with tf.name_scope(\"Memory_update\"):\n",
    "        # Perform single update for each sequence/batch.\n",
    "        memory_update_batch = tf.tensordot(tf.transpose(k_t), write_weights_batch, axes=1)\n",
    "        # Add dependendency control - first prediction?\n",
    "        #with tf.control_dependencies([prediction_batch]):\n",
    "        # Update the memory\n",
    "        memory_update_op = memory.assign(memory + memory_update_batch)\n",
    "        \n",
    "        # Create hot-cold visualization of memory (red=positive/blue=negative)\n",
    "        zeros = tf.zeros([HIDDEN_SIZE, MEMORY_SLOTS])\n",
    "        # Get negative values only.\n",
    "        neg = tf.less(memory, zeros)\n",
    "        blue = tf.multiply(tf.cast(neg, tf.float32), memory)\n",
    "        min_blue = tf.reduce_min(memory, axis=0) + EPS\n",
    "        norm_blue = 255.0 * blue/min_blue\n",
    "        # Get positive values only.\n",
    "        pos = tf.greater(memory, zeros)\n",
    "        red = tf.multiply(tf.cast(pos, tf.float32), memory)\n",
    "        max_red = tf.reduce_max(memory, axis=0) + EPS\n",
    "        norm_red = 255.0 * red/max_red\n",
    "        # Stack them into three channel image with hot-cold values.\n",
    "        rgb_memory = tf.stack([norm_red, zeros, norm_blue], axis=2)\n",
    "        rgb_memory_reshaped = tf.reshape(rgb_memory, [1, HIDDEN_SIZE, MEMORY_SLOTS, 3])\n",
    "        \n",
    "        # Memory \"truncation\".\n",
    "        #memory_trunk_op = memory.assign(tf.tanh(memory))\n",
    "        #memory_trunk_vis = tf.reshape(memory, [1,HIDDEN_SIZE, MEMORY_SLOTS,1])\n",
    "\n",
    "        # Add histograms to TensorBoard.\n",
    "        memory_update_batch_hist = tf.summary.histogram(\"memory_update_batch\", memory_update_batch)\n",
    "        memory_hist = tf.summary.histogram(\"memory_before_truncation\", memory_update_op)\n",
    "        #memory_trunk_hist = tf.summary.histogram(\"memory_after_truncation\", memory_trunk_op)\n",
    "        # Visualize memory as image.\n",
    "        memory_updated_img = tf.summary.image(\"memory_before_truncation\", rgb_memory_reshaped)\n",
    "        #memory_trunk_img = tf.summary.image(\"memory_after_truncation\", memory_trunk_vis)\n",
    "\n",
    "        \n",
    "    return memory_output_batch, cell_output, cell_state\n",
    "\n",
    "print(\"Cell definition OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Definition of tensor graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_buffers shape = (?, 59)\n",
      "Seq length  = 1\n",
      "Batch shape = (?, 59)\n",
      "Graph definition OK\n"
     ]
    }
   ],
   "source": [
    "# Reset graph - just in case.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Memory.\n",
    "memory = tf.Variable(tf.truncated_normal(shape=[HIDDEN_SIZE, MEMORY_SLOTS]), trainable=False, name=\"Memory_M\")\n",
    "# Latest vs LRU ratio.\n",
    "#alpha = tf.Variable(tf.truncated_normal(shape=[1]), name=\"Alpha\")\n",
    "\n",
    "# 0. Previous variables.\n",
    "with tf.name_scope(\"Previous_variables\"):\n",
    "    # Create \"read vectors\" (in fact batch).\n",
    "    read_vectors_seq_batch = list()    \n",
    "    for i_seq in range(SEQ_LENGTH):\n",
    "        read_vectors_seq_batch.append(tf.placeholder(tf.float32, shape=[None, HIDDEN_SIZE], name=\"Read_vector_r\"))    \n",
    "\n",
    "    # Placeholders for previous weights.\n",
    "    prev_read_weights_seq_batch = list()    \n",
    "    prev_update_weights_seq_batch = list()    \n",
    "    for i_seq in range(SEQ_LENGTH):\n",
    "        prev_read_weights_seq_batch.append(tf.placeholder(tf.float32, shape=[None, MEMORY_SLOTS], name=\"Prev_rw\"))\n",
    "        prev_update_weights_seq_batch.append(tf.placeholder(tf.float32, shape=[None, MEMORY_SLOTS], name=\"Prev_uw\"))\n",
    "\n",
    "# 1. Placeholders for inputs.\n",
    "with tf.name_scope(\"Input_data\"):\n",
    "    # Define input data buffers.\n",
    "    data_buffers = list()\n",
    "    for _ in range(SEQ_LENGTH + 1):\n",
    "        # Collect placeholders for inputs/labels: Batch x Vocab size.\n",
    "        data_buffers.append(tf.placeholder(tf.float32, shape=[None, vocabulary_size], name=\"data_buffers\"))\n",
    "    print (\"data_buffers shape =\", data_buffers[0].shape)\n",
    "\n",
    "    # Sequence of batches.\n",
    "    input_seq_batch = data_buffers[:SEQ_LENGTH]\n",
    "    print (\"Seq length  =\", len(input_seq_batch))\n",
    "    print (\"Batch shape =\", input_seq_batch[0].shape)\n",
    "\n",
    "    # Labels are pointing to the same placeholders!\n",
    "    # Labels are inputs shifted by one time step.\n",
    "    labels_seq_batch = data_buffers[1:]  \n",
    "    # Concatenate targets into 2D tensor.\n",
    "    target_batch = tf.concat(labels_seq_batch, 0)\n",
    "\n",
    "    # Add histograms to TensorBoard.\n",
    "    input_seq_batch_hist = tf.summary.histogram(\"input_seq_batch\", input_seq_batch)\n",
    "\n",
    "# 2. Unrolled controller ops.\n",
    "with tf.name_scope(\"Controller\"):\n",
    "    # Define parameters:\n",
    "    # Input gate: input, previous output, and bias.\n",
    "    Wf = tf.Variable(tf.truncated_normal([vocabulary_size+2*HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"Wf\")\n",
    "    bf = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"bf\")\n",
    "\n",
    "    # Forget gate: input, previous output, and bias.\n",
    "    Wi = tf.Variable(tf.truncated_normal([vocabulary_size+2*HIDDEN_SIZE,HIDDEN_SIZE], -0.1, 0.1), name=\"Wi\")\n",
    "    bi = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"bi\")\n",
    "\n",
    "    # Memory cell: input, state and bias.                             \n",
    "    Wc = tf.Variable(tf.truncated_normal([vocabulary_size+2*HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"Wc\")\n",
    "    bc = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"bc\")\n",
    "\n",
    "    # Output gate: input, previous output, and bias.\n",
    "    Wo = tf.Variable(tf.truncated_normal([vocabulary_size+2*HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"Wo\")\n",
    "    bo = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"bo\")\n",
    "\n",
    "    # Read key.\n",
    "    W_key = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"W_key\")\n",
    "    b_key = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"b_key\")\n",
    "    \n",
    "    # Add key.\n",
    "    #W_add = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, HIDDEN_SIZE], -0.1, 0.1), name=\"W_add\")\n",
    "    #b_add = tf.Variable(tf.zeros([1, HIDDEN_SIZE]), name=\"b_add\")\n",
    "    \n",
    "    # Alpha - used in Latest vs LRU ratio.\n",
    "    W_alpha = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, 1], -0.1, 0.1), name=\"W_alpha\")\n",
    "    b_alpha = tf.Variable(tf.zeros([1, 1]), name=\"b_alpha\")\n",
    "    \n",
    "    # Placeholders for \"zero\" (the oldest) state and output: Batch x Hidden size.\n",
    "    init_controller_output = tf.placeholder(tf.float32, shape=[None, HIDDEN_SIZE], name=\"init_controller_output\")\n",
    "    init_controller_state = tf.placeholder(tf.float32, shape=[None, HIDDEN_SIZE], name=\"init_controller_state\")\n",
    "    # Placeholder for \"zero\" memory read: Batch X Hidden (TODO: memory?) size.\n",
    "    init_memory_output = tf.placeholder(tf.float32, shape=[None, HIDDEN_SIZE], name=\"init_memory_read\")\n",
    "\n",
    "    # Unrolled LSTM.\n",
    "    # Build outpus of size SEQ_LENGTH.\n",
    "    controller_outputs_batch_seq = list()\n",
    "    memory_outputs_batch_seq = list()\n",
    "    # Two lists that will be \"returned\" and later passed as previous states. \n",
    "    read_weights_seq_batch = list()  \n",
    "    update_weights_seq_batch = list()  \n",
    "    \n",
    "    # \"Link\" oldest statte and output to placeholders.\n",
    "    controller_output = init_controller_output\n",
    "    controller_state = init_controller_state\n",
    "    memory_output = init_memory_output\n",
    "    # For every buffer in input sequence batch buffers...\n",
    "    for i in range(SEQ_LENGTH):\n",
    "        # ... add cell...     \n",
    "        memory_output, controller_output, controller_state = controller_cell(\n",
    "            input_seq_batch[i], \n",
    "            memory_output, \n",
    "            controller_output, \n",
    "            controller_state, \n",
    "            prev_read_weights_seq_batch[i],\n",
    "            prev_update_weights_seq_batch[i],\n",
    "            \"cell_\"+str(i))\n",
    "        # .. add controller buffer to outputs...\n",
    "        controller_outputs_batch_seq.append(controller_output)\n",
    "        memory_outputs_batch_seq.append(memory_output)\n",
    "        # .. and set memory input of (i+1) cell to i-th read vector buffer.\n",
    "        #memory_input = read_vectors_seq_batch[i]\n",
    "        \n",
    "    # Add histograms to TensorBoard.\n",
    "    controller_outputs_batch_seq_hist = tf.summary.histogram(\"controller_outputs_batch_seq\", controller_outputs_batch_seq)\n",
    "    memory_outputs_batch_seq_hist = tf.summary.histogram(\"memory_outputs_batch_seq\", memory_outputs_batch_seq)\n",
    "    memory_hist = tf.summary.histogram(\"memory\", memory)\n",
    "    read_weights_seq_batch_hist = tf.summary.histogram(\"read_weights_seq_batch\", read_weights_seq_batch)\n",
    "    update_weights_seq_batch_hist = tf.summary.histogram(\"update_weights_seq_batch\", update_weights_seq_batch)\n",
    "\n",
    "# 3. Output ops.\n",
    "with tf.name_scope(\"Output\"):\n",
    "    # Concatenate controller hidden state with the read vector.\n",
    "    coutput_rvector_seq_batch = list()    \n",
    "    for i_seq in range(SEQ_LENGTH):\n",
    "        coutput_rvector_seq_batch.append(tf.concat([controller_outputs_batch_seq[i_seq], \n",
    "                                                 memory_outputs_batch_seq[i_seq]], 1, name=\"Concat_coutput_rvector\"))    \n",
    "    # Add histograms to TensorBoard.\n",
    "    coutput_rvector_seq_batch_hist = tf.summary.histogram(\"coutput_rvector_seq_batch\", coutput_rvector_seq_batch)\n",
    "\n",
    "    output_batch = tf.concat(controller_outputs_batch_seq, 0) \n",
    "    #output_batch = tf.concat(controller_outputs_batch_seq, 0)\n",
    " \n",
    "    # Output layer weights and biases.\n",
    "    w = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, vocabulary_size], -0.1, 0.1), name=\"w\")\n",
    "    b = tf.Variable(tf.zeros([vocabulary_size]), name=\"b\")\n",
    "\n",
    "    # Logits.\n",
    "    logits_batch = tf.nn.xw_plus_b(output_batch, w, b, name = \"Final_FC\")\n",
    "    # Add fully connected softmax layer on top - predictions.\n",
    "    prediction_batch = tf.nn.softmax(logits_batch)\n",
    "    \n",
    "# 4. Loss ops.\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    # Loss function(s) - one for every output generated by every LSTM cell.\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=target_batch, logits=logits_batch))\n",
    "    # Add loss summary.\n",
    "    loss_summary = tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "# 5. Training ops.  \n",
    "with tf.name_scope(\"Optimization\"):\n",
    "    # Learning rate decay.\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, 5000, 0.9, staircase=True)\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "    # Gradient clipping.\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n",
    "\n",
    "# Merge all summaries.\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "\n",
    "print(\"Graph definition OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed_dict definition OK\n"
     ]
    }
   ],
   "source": [
    "def create_feed_dict(set_type_):\n",
    "    \"\"\"Creates a dictionaries for different sets: maps data onto Tensor placeholders.\"\"\"\n",
    "    feed_dict = dict()\n",
    "    \n",
    "    #if set_type_==\"train\":\n",
    "    # Get next batch and create a feed dict.\n",
    "    next_batch = train_batches.next()\n",
    "    # Feed batch to input buffers.\n",
    "    for i in range(SEQ_LENGTH + 1):\n",
    "        feed_dict[data_buffers[i]] = next_batch[i]\n",
    "\n",
    "    # Set previous weights of read and write heades.\n",
    "    for i in range(SEQ_LENGTH):\n",
    "        feed_dict[prev_read_weights_seq_batch[i]] = prev_rw_seq_batch[i]\n",
    "        feed_dict[prev_update_weights_seq_batch[i]] = prev_uw_seq_batch[i]\n",
    "\n",
    "    # Reset \"init\" state and output of controller.\n",
    "    feed_dict[init_controller_output] = np.zeros([BATCH_SIZE, HIDDEN_SIZE])\n",
    "    feed_dict[init_controller_state] = np.zeros([BATCH_SIZE, HIDDEN_SIZE])\n",
    "    feed_dict[init_memory_output] = np.zeros([BATCH_SIZE, HIDDEN_SIZE])\n",
    "            \n",
    "    #elif set_type_==\"valid\":\n",
    "    #    for i in range(SEQ_LENGTH + 1):\n",
    "    #        feed_dict[data_buffers[i]] = valid_batch[i]\n",
    "\n",
    "    # TODO: HOW TO VALIDATE !! when update/write depends on the previous batch??\n",
    "    \n",
    "    #else: # test\n",
    "    #    for i in range(SEQ_LENGTH + 1):\n",
    "    #        feed_dict[data_buffers[i]] = test_batch[i]\n",
    "        \n",
    "       \n",
    "    return feed_dict\n",
    "\n",
    "print(\"Feed_dict definition OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log dir CLEARED\n"
     ]
    }
   ],
   "source": [
    "# Eventually clear the log dir.\n",
    "if tf.gfile.Exists(LOG_DIR):\n",
    "  tf.gfile.DeleteRecursively(LOG_DIR)\n",
    "# Create (new) log dir.\n",
    "tf.gfile.MakeDirs(LOG_DIR)\n",
    "\n",
    "print(\"Log dir CLEARED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables initialized\n",
      "Number of iterations per epoch = 10000\n",
      "memory=\n",
      " [[-1.62183619  0.42470118  1.28924441  0.60822302 -0.61682415  1.00247824\n",
      "   1.41308975  1.18546331 -1.21948457  0.37774783]\n",
      " [-1.64181793  0.58796543 -1.28425908 -0.30923542 -0.5706014  -0.61637932\n",
      "  -1.17260826  0.05734515 -1.00058949 -0.44328439]\n",
      " [ 1.12578321 -0.75492275  0.74851525 -0.60906279  0.21810517  1.17030799\n",
      "   1.81300998 -0.15758897  0.44733503  1.12421823]\n",
      " [ 0.39198929 -0.11256467 -1.69561434 -0.94239986  0.7355327   1.72307825\n",
      "   0.78167647  0.50731486 -1.34242415  0.21491817]\n",
      " [ 0.04932863  0.47347218  1.62203944  0.48852581  1.74889898  0.12459899\n",
      "   0.18837456  1.44944644 -1.38566017  0.16286469]]\n",
      "Training set BPC at step 0: 4.07823 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.35506594  0.7182405   1.54528081  0.96097815 -0.33629978  1.31876838\n",
      "   1.65656352  1.41641772 -0.79469842  0.58067894]\n",
      " [-1.32378888  0.92816538 -0.98989129  0.13525626 -0.22159512 -0.25117764\n",
      "  -0.91565925  0.31586424 -0.48393708 -0.2228892 ]\n",
      " [ 1.33851147 -0.5247311   0.94903958 -0.31055149  0.44843575  1.41848278\n",
      "   1.988029    0.01443737  0.79322636  1.27684569]\n",
      " [ 0.57463354  0.09479874 -1.52424169 -0.66605949  0.95644677  1.9464407\n",
      "   0.92397463  0.65935576 -1.01734114  0.33077523]\n",
      " [ 0.32077309  0.76530075  1.87644243  0.83747423  2.03408837  0.43722031\n",
      "   0.43568155  1.68770623 -0.9618898   0.36479461]]\n",
      "Training set BPC at step 100: 3.12795 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.32614756  0.78704226  1.7219193   1.09231246 -0.24157016  1.53582573\n",
      "   1.79840231  1.62941575 -0.63402551  0.63336831]\n",
      " [-1.34572589  0.97654295 -0.822914    0.23100251 -0.13273633 -0.03083857\n",
      "  -0.76353669  0.51034927 -0.35197145 -0.23859471]\n",
      " [ 1.34466863 -0.47888702  1.0761224  -0.23136321  0.51471311  1.58612657\n",
      "   2.09969449  0.16508691  0.90301526  1.28813612]\n",
      " [ 0.54352713  0.11379168 -1.43288696 -0.635732    1.01129556  2.11546183\n",
      "   1.02322721  0.76007783 -0.96014923  0.292685  ]\n",
      " [ 0.32226649  0.81559104  2.03364086  0.95536196  2.11978674  0.61577559\n",
      "   0.55980861  1.87370682 -0.82827723  0.39373091]]\n",
      "Training set BPC at step 200: 3.71602 learning rate: 0.100000\n",
      "memory=\n",
      " [[-1.09175098  0.96207011  1.96851206  1.19411075 -0.02829619  1.77016723\n",
      "   1.93476653  1.70917928 -0.38217503  0.93220425]\n",
      " [-1.15838134  1.0198096  -0.67020446  0.19922327 -0.04651691  0.06667097\n",
      "  -0.75671577  0.52740127 -0.15339667 -0.06242962]\n",
      " [ 1.46472561 -0.45029336  1.19063592 -0.23689577  0.58990985  1.66601503\n",
      "   2.13395882  0.17525639  1.03717697  1.41176629]\n",
      " [ 0.65826052  0.09413909 -1.39135325 -0.73195165  0.99974144  2.11069775\n",
      "   0.9438594   0.74864835 -0.86467415  0.35524499]\n",
      " [ 0.58359259  1.0278827   2.29192758  1.06995511  2.34379506  0.86921221\n",
      "   0.68188852  1.97415948 -0.55448568  0.72621453]]\n",
      "Training set BPC at step 300: 1.01277 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.79389775  1.15454006  2.11461973  1.31915247  0.223342    1.99292672\n",
      "   2.03245234  1.93443763 -0.16324417  1.01819515]\n",
      " [-0.84079999  1.18225253 -0.55911875  0.26815221  0.18294495  0.3004472\n",
      "  -0.6092959   0.74470967  0.07817872 -0.02930505]\n",
      " [ 1.70084584 -0.30688751  1.29132533 -0.14748585  0.77699655  1.849383\n",
      "   2.24218869  0.36903581  1.21410763  1.45842254]\n",
      " [ 0.94230592  0.17610151 -1.3271662  -0.70894122  1.15747297  2.27923107\n",
      "   1.15100324  0.91952348 -0.67534089  0.39715266]\n",
      " [ 0.82591724  1.16719496  2.39812279  1.12689829  2.53944039  1.0398643\n",
      "   0.73043084  2.10512757 -0.38357216  0.77044129]]\n",
      "Training set BPC at step 400: 2.55836 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.6575532   1.33300519  2.06172919  1.52552545  0.32761332  2.09668851\n",
      "   2.09887147  1.99075615 -0.0461456   1.16863298]\n",
      " [-0.68342757  1.37266684 -0.67930818  0.48722583  0.26858804  0.40677035\n",
      "  -0.54278135  0.7636528   0.21713604  0.1553691 ]\n",
      " [ 1.82633424 -0.15723245  1.24718595  0.03634003  0.86183357  1.94197094\n",
      "   2.30102968  0.41463646  1.31555796  1.59581912]\n",
      " [ 1.07650781  0.30875495 -1.41957939 -0.54108512  1.19945717  2.36242032\n",
      "   1.20197666  0.91636437 -0.57080585  0.55246025]\n",
      " [ 0.9188996   1.30552793  2.2892189   1.26169324  2.59904957  1.10213792\n",
      "   0.76985991  2.10872769 -0.28582919  0.88697714]]\n",
      "Training set BPC at step 500: 1.89591 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.49449688  1.48933423  2.21840954  1.65443301  0.54192179  2.31320024\n",
      "   2.23660159  2.10719681  0.10233926  1.4206388 ]\n",
      " [-0.54503512  1.60409999 -0.5683338   0.53556633  0.50066978  0.6703651\n",
      "  -0.37262648  0.89439201  0.34808081  0.4424974 ]\n",
      " [ 1.95553708 -0.01927032  1.37056708  0.11964902  1.04072976  2.1271944\n",
      "   2.41688824  0.51067269  1.43175519  1.80072498]\n",
      " [ 1.14039958  0.50452727 -1.38270986 -0.54431987  1.35390711  2.5614984\n",
      "   1.32811463  1.00631845 -0.51185542  0.7327137 ]\n",
      " [ 1.02381289  1.47727144  2.37054181  1.31904447  2.77058554  1.29503286\n",
      "   0.8990677   2.20846629 -0.18092273  1.11533213]]\n",
      "Training set BPC at step 600: 2.99288 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.31977165  1.70306683  2.72746396  1.79400384  0.75989038  2.59674144\n",
      "   2.3595829   2.39411545  0.32588321  1.67389369]\n",
      " [-0.33361298  1.83794916  0.01189161  0.69584137  0.76455832  1.01266122\n",
      "  -0.21354349  1.2223084   0.54619253  0.74331844]\n",
      " [ 2.1221714   0.16965219  1.8004607   0.25353527  1.24781704  2.39095569\n",
      "   2.54661441  0.77605838  1.61812687  2.029984  ]\n",
      " [ 1.35557497  0.69944119 -0.92862403 -0.38524103  1.6125232   2.88086581\n",
      "   1.52730501  1.30417657 -0.32990265  0.99968904]\n",
      " [ 1.13516963  1.62187612  2.7934289   1.39664042  2.91509151  1.49037659\n",
      "   0.9567306   2.39490414 -0.0556503   1.3006078 ]]\n",
      "Training set BPC at step 700: 2.40606 learning rate: 0.100000\n",
      "memory=\n",
      " [[-0.01051401  1.96981835  3.06329703  2.17205358  1.27226436  2.85605669\n",
      "   2.66923833  2.56416488  0.57747781  1.88491142]\n",
      " [-0.06443604  2.08706474  0.29678199  1.0964061   1.23273742  1.22000825\n",
      "   0.10144766  1.36221385  0.79452598  0.9763456 ]\n",
      " [ 2.34392285  0.3500177   2.02639627  0.55151588  1.61471832  2.58875608\n",
      "   2.78493953  0.89793164  1.80217206  2.18974757]\n",
      " [ 1.54513359  0.84534699 -0.79117155 -0.07322639  1.85891533  2.99510527\n",
      "   1.74347401  1.37445498 -0.16818963  1.16623557]\n",
      " [ 1.38485789  1.8759712   3.09627438  1.72056055  3.36188579  1.65521181\n",
      "   1.21900237  2.52546215  0.17223687  1.50282741]]\n",
      "Training set BPC at step 800: 3.21870 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 0.17612879  2.23600388  3.15773559  2.31333542  1.57297659  3.00407958\n",
      "   2.81960964  2.76088476  0.77695352  2.12094975]\n",
      " [ 0.13502412  2.35076427  0.28627527  1.19647682  1.46725261  1.27991879\n",
      "   0.1939389   1.52293468  0.99582428  1.15080762]\n",
      " [ 2.48885703  0.55908126  2.07650447  0.64960235  1.82517672  2.68871331\n",
      "   2.89326572  1.05447912  1.95668244  2.37601519]\n",
      " [ 1.68495321  1.01473176 -0.85655099 -0.02918697  1.98922896  2.9884243\n",
      "   1.77035272  1.46441102 -0.04207194  1.25711727]\n",
      " [ 1.5496583   2.08822918  3.11204743  1.81627119  3.58269715  1.71534252\n",
      "   1.29948163  2.63982558  0.3386828   1.62790978]]\n",
      "Training set BPC at step 900: 5.05743 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 0.39451036  2.37535977  3.34871173  2.47525048  1.82869506  3.17764544\n",
      "   3.09067249  2.93857574  1.09431314  2.25239158]\n",
      " [ 0.37267163  2.49803615  0.52206951  1.38365626  1.73232996  1.5200932\n",
      "   0.5351454   1.76220083  1.38615525  1.28233492]\n",
      " [ 2.66521192  0.67438692  2.23511291  0.78102392  2.02772069  2.83315206\n",
      "   3.1176281   1.20086575  2.22220993  2.47817397]\n",
      " [ 1.85216951  1.12832665 -0.68135518  0.09998986  2.15665388  3.18263507\n",
      "   2.0252769   1.65034473  0.24617143  1.34827375]\n",
      " [ 1.73070931  2.19082022  3.29191399  1.96228945  3.79294705  1.90450299\n",
      "   1.56364703  2.83050466  0.63362026  1.73166525]]\n",
      "Training set BPC at step 1000: 3.70997 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 0.799537    2.75356102  3.63722229  3.00578213  2.07676649  3.59054565\n",
      "   3.39017367  3.39470482  1.50278544  2.48506808]\n",
      " [ 0.80729234  2.87502408  0.83600456  1.98539984  1.94874048  2.01721954\n",
      "   0.84394032  2.23694801  1.83462512  1.50736296]\n",
      " [ 2.98730731  0.97519743  2.46690536  1.20499992  2.22584534  3.18206406\n",
      "   3.36333752  1.57064784  2.53206921  2.65943623]\n",
      " [ 2.16375303  1.3716619  -0.45006251  0.55126595  2.29426813  3.58136916\n",
      "   2.25092363  2.03467941  0.57866538  1.49355578]\n",
      " [ 2.0702517   2.48218369  3.53291678  2.43880296  3.94616795  2.26172781\n",
      "   1.78405201  3.17425251  1.01518166  1.91000259]]\n",
      "Training set BPC at step 1100: 2.01023 learning rate: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ 1.09771335  3.04433751  3.8560462   3.22221375  2.40452361  3.71601915\n",
      "   3.67833829  3.58117366  1.90522218  2.66240573]\n",
      " [ 1.10164869  3.11363459  0.9977805   2.1768744   2.2973597   2.02153397\n",
      "   1.10673273  2.31036711  2.24496865  1.63594675]\n",
      " [ 3.22156882  1.17223573  2.60433745  1.38089824  2.4707408   3.22376728\n",
      "   3.58202958  1.6675272   2.83428359  2.77984142]\n",
      " [ 2.36404228  1.48790038 -0.36651006  0.70672613  2.53232431  3.50488329\n",
      "   2.39891362  2.00334835  0.83122575  1.54088271]\n",
      " [ 2.29707384  2.72104192  3.71139336  2.5600059   4.25015163  2.3493607\n",
      "   2.0031395   3.30502009  1.3724035   2.03800702]]\n",
      "Training set BPC at step 1200: 2.67206 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 1.2141124   3.25680804  4.0947485   3.44735789  2.69498539  3.82311821\n",
      "   3.92611933  3.8811183   2.24932551  2.81708026]\n",
      " [ 1.23357499  3.31921411  1.33971274  2.43048811  2.66562057  2.09563041\n",
      "   1.38388753  2.74996853  2.64566398  1.79705405]\n",
      " [ 3.31968117  1.35064733  2.82487059  1.57143962  2.72051501  3.30223322\n",
      "   3.78480506  1.9265399   3.12647367  2.89329147]\n",
      " [ 2.47286105  1.63981903 -0.04933406  0.89420825  2.81616473  3.53511524\n",
      "   2.6121459   2.37240887  1.16681778  1.64286387]\n",
      " [ 2.38621378  2.85225821  3.93139029  2.73703551  4.51601648  2.40960264\n",
      "   2.20889711  3.63835835  1.64844656  2.18327284]]\n",
      "Training set BPC at step 1300: 0.86847 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 1.50444829  3.71964502  4.48798561  3.73674607  3.10342216  4.18981028\n",
      "   4.36301613  4.12023163  2.58579493  3.28563881]\n",
      " [ 1.4592036   3.70525908  1.6670469   2.67568827  2.98802352  2.47150731\n",
      "   1.74233985  2.9583869   2.92789364  2.20866966]\n",
      " [ 3.5231421   1.68091822  3.0848763   1.75216758  2.99140978  3.55418158\n",
      "   4.06238651  2.09285998  3.35879421  3.19149709]\n",
      " [ 2.57503557  1.83104575  0.11579716  1.02879298  2.96000528  3.78753829\n",
      "   2.75834966  2.48830295  1.29591119  1.84578168]\n",
      " [ 2.59934878  3.20692158  4.27189827  3.01051354  4.8507762   2.77779675\n",
      "   2.61103463  3.83763266  1.92545712  2.63781619]]\n",
      "Training set BPC at step 1400: 3.64442 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 1.59004998  4.03312159  4.70408249  4.01563025  3.3338151   4.3390379\n",
      "   4.76464939  4.36411095  2.84853554  3.73787951]\n",
      " [ 1.45716989  3.9858582   1.85437882  2.90199828  3.25042462  2.56419611\n",
      "   2.15002942  3.18131733  3.0914681   2.59755564]\n",
      " [ 3.55932593  1.91105783  3.22663355  1.9490118   3.16900158  3.65645003\n",
      "   4.3353672   2.27318192  3.51588893  3.51728129]\n",
      " [ 2.52087736  1.97536731  0.21974091  1.11117613  3.14848852  3.81980872\n",
      "   3.02974582  2.60801315  1.34663939  2.04025578]\n",
      " [ 2.63729072  3.45920706  4.47082472  3.23075461  5.07428455  2.86739898\n",
      "   3.02469921  4.03553915  2.13383389  3.00257564]]\n",
      "Training set BPC at step 1500: 0.74687 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 1.74647439  4.34027147  4.93744421  4.19093132  3.54782557  4.78288651\n",
      "   5.00823927  4.52133179  3.09154773  3.91418505]\n",
      " [ 1.54242432  4.28846645  2.09154344  3.04858708  3.41506529  3.05710483\n",
      "   2.34874964  3.32592893  3.23521566  2.68429184]\n",
      " [ 3.67254806  2.15283847  3.4102025   2.08979011  3.31881332  4.00921488\n",
      "   4.50468493  2.39456391  3.66039491  3.64102364]\n",
      " [ 2.54114819  2.1608777   0.38017198  1.21404791  3.24571848  4.19222641\n",
      "   3.12721062  2.70333743  1.36919546  2.04307127]\n",
      " [ 2.70513225  3.69790268  4.65791559  3.3276844   5.22343397  3.26258826\n",
      "   3.21615815  4.14921808  2.31758738  3.07960463]]\n",
      "Training set BPC at step 1600: 3.44328 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 2.03961396  4.81320286  5.35915136  4.48404741  3.91355371  5.08934879\n",
      "   5.25792551  4.83789825  3.44295859  4.30916929]\n",
      " [ 1.82875872  4.82687759  2.52190852  3.36621594  3.78456974  3.40364003\n",
      "   2.56010318  3.7264607   3.57487893  3.12868381]\n",
      " [ 3.8927319   2.54121304  3.74213076  2.33784962  3.62917161  4.27704239\n",
      "   4.70497465  2.65928841  3.95587301  3.96951199]\n",
      " [ 2.71926689  2.55078578  0.65668553  1.4464767   3.50162244  4.46645641\n",
      "   3.24454093  3.03203964  1.59729552  2.35843325]\n",
      " [ 2.95267773  4.11588097  5.01202393  3.54886675  5.4699192   3.48809934\n",
      "   3.36767936  4.45181799  2.54827642  3.40948534]]\n",
      "Training set BPC at step 1700: 3.55084 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 2.35712886  5.11767149  5.71124077  5.01699591  4.39330244  5.46590567\n",
      "   5.85213947  5.19485807  3.95663881  4.63032341]\n",
      " [ 2.14711428  5.08693123  2.78627586  3.86268473  4.28689384  3.81724024\n",
      "   3.12714362  4.07391977  4.11989403  3.42397141]\n",
      " [ 4.14251852  2.75841498  4.00321007  2.73215818  4.00600958  4.57814264\n",
      "   5.17677259  2.92592144  4.36096478  4.20900059]\n",
      " [ 2.91000891  2.70116568  0.74948752  1.71322298  3.79360056  4.75311661\n",
      "   3.60612822  3.2375164   1.92390251  2.50893378]\n",
      " [ 3.20869398  4.35337973  5.24019146  3.99710441  5.88446522  3.81470394\n",
      "   3.80659437  4.75555944  2.99601841  3.66964483]]\n",
      "Training set BPC at step 1800: 3.61455 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 2.59688544  5.41746712  5.99812603  5.23245382  4.61952782  5.67618418\n",
      "   6.19208574  5.43878365  4.10436773  4.9035697 ]\n",
      " [ 2.42956591  5.39711332  3.01504135  3.99875927  4.49327421  4.01389408\n",
      "   3.43497014  4.30156469  4.21641779  3.70671463]\n",
      " [ 4.34092665  3.00753617  4.19851351  2.8660779   4.18102455  4.74486542\n",
      "   5.42757845  3.10824037  4.47964621  4.41117239]\n",
      " [ 3.16537356  2.93108463  0.87048465  1.75721312  3.92274094  4.88916063\n",
      "   3.81302714  3.36738229  1.99746323  2.72154474]\n",
      " [ 3.40467548  4.56728458  5.46227217  4.15112209  6.04433012  3.95878029\n",
      "   4.06795216  4.94967651  3.04294491  3.91150546]]\n",
      "Training set BPC at step 1900: 1.59412 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 2.82322288  5.79780436  6.28572369  5.70985031  4.891078    6.10233974\n",
      "   6.70839739  5.77865839  4.48064661  5.36152887]\n",
      " [ 2.62482667  5.76792431  3.2531395   4.51106882  4.71858978  4.43822193\n",
      "   4.0342927   4.69040823  4.53942823  4.18905687]\n",
      " [ 4.51385117  3.29707026  4.39084864  3.22959495  4.363873    5.04982281\n",
      "   5.8531909   3.35379028  4.75718498  4.76221991]\n",
      " [ 3.299016    3.18353367  1.02073407  2.09686399  4.04100943  5.16523695\n",
      "   4.29001808  3.66074419  2.18643761  3.02471972]\n",
      " [ 3.55581737  4.88066339  5.69983196  4.58830023  6.26946306  4.35151672\n",
      "   4.52230978  5.30850506  3.3182714   4.32110071]]\n",
      "Training set BPC at step 2000: 5.60129 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 3.24479413  6.17285156  6.56116438  5.92133999  5.20886087  6.33927917\n",
      "   7.22368765  6.12647057  4.82987499  5.68275213]\n",
      " [ 2.96825099  6.07711697  3.43929887  4.59930563  4.99930382  4.4930892\n",
      "   4.4923296   4.94749355  4.83428144  4.41455603]\n",
      " [ 4.79492569  3.56343246  4.56482363  3.33429837  4.55444622  5.1569519\n",
      "   6.18948936  3.5765965   4.99735451  4.96065807]\n",
      " [ 3.45809746  3.31466484  1.06059086  2.07331347  4.19527245  5.06915379\n",
      "   4.53453827  3.76743507  2.33566499  3.07935047]\n",
      " [ 3.92230844  5.17669439  5.92106056  4.75625706  6.6043067   4.51710701\n",
      "   5.02088118  5.60219288  3.6196301   4.59488583]]\n",
      "Training set BPC at step 2100: 2.85658 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 3.56497312  6.46168804  6.80927563  6.30119038  5.4010253   6.54150724\n",
      "   7.58355808  6.50792122  5.21336269  6.09524536]\n",
      " [ 3.22367406  6.30809975  3.70160913  4.95326328  5.16650629  4.68267965\n",
      "   4.8412571   5.26276445  5.23214197  4.77845907]\n",
      " [ 5.02772474  3.77382278  4.75118446  3.59822583  4.69539547  5.30537081\n",
      "   6.46680593  3.8417809   5.2873559   5.23468542]\n",
      " [ 3.57584834  3.42515826  1.22847879  2.25088882  4.28621149  5.17651939\n",
      "   4.73247576  3.9196589   2.55666065  3.28500175]\n",
      " [ 4.15859461  5.3891511   6.15589523  5.10988903  6.75480223  4.69060183\n",
      "   5.31437683  5.91709232  3.97363186  4.98052645]]\n",
      "Training set BPC at step 2200: 4.72714 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 3.70502734  6.67712545  6.99299574  6.51042414  5.52079296  6.74635744\n",
      "   7.77573252  6.66922903  5.41911936  6.28745317]\n",
      " [ 3.29957962  6.53764915  3.88303494  5.08917618  5.23070288  4.87032938\n",
      "   4.97272587  5.44049788  5.4020052   4.92720413]\n",
      " [ 5.10765934  3.94700813  4.888834    3.74113679  4.7619276   5.44416618\n",
      "   6.59712934  3.9660399   5.4354372   5.38471222]\n",
      " [ 3.60218954  3.584656    1.36519098  2.26249933  4.29603624  5.29624271\n",
      "   4.77919483  4.04063177  2.62105918  3.36735725]\n",
      " [ 4.2579155   5.56526089  6.30561304  5.24880791  6.84556818  4.87496376\n",
      "   5.44357777  6.06624889  4.13076115  5.08542776]]\n",
      "Training set BPC at step 2300: 2.77850 learning rate: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ 4.06503963  6.99123001  7.565063    6.78344345  5.86716986  7.03643942\n",
      "   8.06806564  7.30474472  5.6587348   6.66304541]\n",
      " [ 3.60838842  6.84423256  4.45565939  5.38105679  5.53064299  5.19225216\n",
      "   5.22652864  6.02880812  5.63035631  5.20755291]\n",
      " [ 5.37332344  4.17894506  5.3120923   3.95059299  5.01469278  5.67857838\n",
      "   6.81127262  4.40537262  5.60895967  5.60283375]\n",
      " [ 3.82164073  3.82731986  1.71903193  2.48457241  4.45655775  5.563025\n",
      "   4.92728233  4.42919874  2.77335763  3.49830151]\n",
      " [ 4.51210928  5.82216549  6.81509399  5.48796701  7.10969734  5.11364126\n",
      "   5.66269016  6.62783194  4.33440781  5.43327379]]\n",
      "Training set BPC at step 2400: 2.89620 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 4.17000389  7.19363165  7.78436756  7.01193666  6.15983915  7.28636503\n",
      "   8.35802174  7.47700071  5.81656885  6.85704136]\n",
      " [ 3.58885336  7.00581455  4.59868574  5.61039972  5.72515631  5.35278749\n",
      "   5.44957066  6.15830135  5.73863268  5.34725618]\n",
      " [ 5.41392517  4.29689693  5.45523024  4.11623812  5.17334557  5.84662485\n",
      "   7.00903511  4.53100395  5.71130657  5.71796513]\n",
      " [ 3.72841406  3.91739893  1.7413075   2.62221503  4.54855108  5.60437965\n",
      "   5.03342152  4.50653744  2.80981755  3.57568097]\n",
      " [ 4.55034971  6.01779938  6.97206688  5.69956541  7.37400961  5.2759428\n",
      "   5.88131428  6.73338795  4.45083857  5.59857416]]\n",
      "Training set BPC at step 2500: 2.08253 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 4.45870543  7.24652052  7.96131516  7.21551704  6.39974642  7.52466536\n",
      "   8.56986332  7.6527729   5.9833703   7.133605  ]\n",
      " [ 3.92124343  6.94885397  4.75012684  5.81521416  5.93888235  5.5439229\n",
      "   5.59658909  6.35786963  5.86338902  5.54015875]\n",
      " [ 5.6248436   4.30653524  5.57909966  4.26351118  5.32167625  5.99268389\n",
      "   7.13181067  4.66650772  5.80693436  5.89934063]\n",
      " [ 3.97022963  3.81748915  1.82765484  2.7862246   4.66631079  5.69536161\n",
      "   5.07941341  4.66576767  2.87822461  3.64584303]\n",
      " [ 4.85336161  6.00887156  7.1135788   5.87846756  7.61590338  5.49814415\n",
      "   6.06993008  6.89749002  4.60558176  5.80337429]]\n",
      "Training set BPC at step 2600: 2.60310 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 4.59336233  7.52726221  8.17546558  7.43142271  6.75799179  7.89477539\n",
      "   8.7432642   7.80047178  6.13832808  7.40298414]\n",
      " [ 3.95289063  7.08185625  4.95374775  5.92694998  6.17741156  5.78320456\n",
      "   5.71260405  6.37356138  5.94233704  5.71765184]\n",
      " [ 5.71122122  4.4759903   5.74609613  4.42940474  5.53346014  6.25639009\n",
      "   7.26725006  4.75459385  5.9209528   6.08353615]\n",
      " [ 3.95359969  3.80172396  1.97310531  2.83052087  4.73511505  5.77690172\n",
      "   5.15670776  4.59016323  2.91171956  3.71762943]\n",
      " [ 4.88839674  6.18430328  7.27199125  5.94440269  7.91776037  5.71861076\n",
      "   6.14252329  6.9374218   4.66107321  5.98269796]]\n",
      "Training set BPC at step 2700: 4.69265 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 4.79964161  7.82537317  8.48900986  7.66052961  7.22896671  8.29317951\n",
      "   8.95259953  8.10236549  6.5464077   7.65593529]\n",
      " [ 4.14965487  7.33091307  5.16750288  6.09842157  6.6151433   6.14268303\n",
      "   5.88610172  6.60691357  6.34233427  5.93028736]\n",
      " [ 5.86254168  4.70804501  5.95463324  4.59559727  5.8664279   6.54931402\n",
      "   7.42889595  4.95831776  6.23048592  6.24507189]\n",
      " [ 4.07588196  3.94833255  2.00495219  2.91124964  5.01025772  5.97708988\n",
      "   5.2749753   4.72501469  3.17775369  3.83969879]\n",
      " [ 5.0654664   6.37391663  7.50497675  6.09494734  8.33560848  6.04430914\n",
      "   6.27272129  7.16711712  5.00379086  6.21516514]]\n",
      "Training set BPC at step 2800: 1.89266 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 5.21975565  8.16777611  8.79157543  7.95406246  7.63230944  8.58957481\n",
      "   9.34946346  8.37919331  6.75097847  8.06953812]\n",
      " [ 4.48893929  7.65509224  5.46943569  6.27405882  6.97384357  6.40783739\n",
      "   6.22640753  6.77820873  6.50298882  6.25413656]\n",
      " [ 6.14959478  4.94222593  6.18491411  4.77141571  6.17508268  6.78467989\n",
      "   7.70291901  5.1233325   6.36907482  6.50196457]\n",
      " [ 4.23914623  4.15322638  2.22059226  2.96652889  5.25418043  6.17853212\n",
      "   5.49526072  4.77283478  3.26636147  4.02067566]\n",
      " [ 5.40359688  6.69493818  7.75565004  6.31302547  8.62396908  6.23121595\n",
      "   6.6036849   7.38279438  5.16417933  6.58730888]]\n",
      "Training set BPC at step 2900: 2.06380 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 5.42525864  8.39564133  8.96898365  8.09128666  7.76381445  8.77214336\n",
      "   9.46886349  8.55799866  6.93076611  8.36861229]\n",
      " [ 4.70907307  7.84988403  5.70792961  6.35385466  7.12037992  6.64298725\n",
      "   6.35568666  7.0194521   6.66955376  6.57513523]\n",
      " [ 6.31326294  5.05589294  6.32330561  4.83002138  6.26891375  6.9206748\n",
      "   7.78682852  5.26610279  6.49563599  6.6988225 ]\n",
      " [ 4.41277218  4.28210545  2.42471528  2.9968822   5.36572027  6.37067127\n",
      "   5.59638357  4.98128891  3.37143064  4.24454737]\n",
      " [ 5.57170773  6.96326637  7.95662785  6.45573521  8.75990009  6.44139576\n",
      "   6.72445154  7.57958794  5.3197937   6.91924572]]\n",
      "Training set BPC at step 3000: 1.81140 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 5.65334749  8.46415424  9.0985899   8.34243488  7.98814774  8.89229298\n",
      "   9.59097862  8.7084446   7.0861845   8.53729057]\n",
      " [ 4.92087173  7.83263016  5.82708883  6.59584951  7.38281679  6.68528175\n",
      "   6.47095251  7.19263792  6.86815262  6.80252171]\n",
      " [ 6.44221354  5.09089947  6.40046406  4.97338772  6.43705368  6.96672297\n",
      "   7.88456678  5.3952322   6.62338257  6.83700705]\n",
      " [ 4.58807707  4.25308418  2.52340031  3.19645214  5.5702405   6.38656855\n",
      "   5.72138691  5.16842508  3.57005024  4.46434975]\n",
      " [ 5.82129288  6.95756245  8.08972168  6.73786116  8.9886322   6.54241896\n",
      "   6.79637384  7.68423271  5.46461487  7.09163237]]\n",
      "Training set BPC at step 3100: 2.52604 learning rate: 0.100000\n",
      "memory=\n",
      " [[  5.9068718    8.78230858   9.29674625   8.54577255   8.31535149\n",
      "    9.12613487  10.02789116   8.86078548   7.29328823   8.69253349]\n",
      " [  5.13284159   8.10124302   5.95930099   6.81672668   7.70178699\n",
      "    6.97727537   6.91436005   7.25186014   6.95576239   6.93218422]\n",
      " [  6.59077072   5.30159521   6.53368664   5.13173866   6.66793871\n",
      "    7.15829134   8.20630455   5.49118042   6.73752451   6.94515848]\n",
      " [  4.7170186    4.37403107   2.55771828   3.36349177   5.7766037\n",
      "    6.62695026   5.9891963    5.14641857   3.53388667   4.5355711 ]\n",
      " [  6.07374477   7.23955917   8.22431278   6.9149971    9.28797245\n",
      "    6.76679325   7.19425774   7.75563765   5.60488129   7.21388245]]\n",
      "Training set BPC at step 3200: 2.89904 learning rate: 0.100000\n",
      "memory=\n",
      " [[  6.22868729   8.93349743   9.56742764   8.83225632   8.6077919\n",
      "    9.43267536  10.23173714   9.12327957   7.44241476   9.06858444]\n",
      " [  5.42806816   8.18031502   6.14011049   7.08128119   7.91858482\n",
      "    7.15638924   7.09785986   7.42906475   7.01237106   7.20514297]\n",
      " [  6.79677725   5.39057589   6.67825937   5.33657074   6.83317471\n",
      "    7.31595039   8.35020161   5.66590548   6.80862951   7.17065811]\n",
      " [  4.90024471   4.40093374   2.62296581   3.52543998   5.8742485\n",
      "    6.70673323   6.12453604   5.23718929   3.52583027   4.66085958]\n",
      " [  6.3901372    7.33892107   8.47877216   7.15652418   9.56863213\n",
      "    7.0285964    7.35940695   7.93504047   5.71579266   7.5400281 ]]\n",
      "Training set BPC at step 3300: 3.26283 learning rate: 0.100000\n",
      "memory=\n",
      " [[  6.63236666   9.17416     10.0106945    9.32448006   9.09018517\n",
      "    9.76432419  10.62351131   9.33034611   7.66989994   9.62240887]\n",
      " [  5.63675785   8.30246353   6.39414644   7.33093929   8.21092415\n",
      "    7.28123331   7.25458527   7.47931623   7.04787254   7.68225145]\n",
      " [  6.98673201   5.50712013   6.90510607   5.54391718   7.06353188\n",
      "    7.44437838   8.50274467   5.75009537   6.87852097   7.50981474]\n",
      " [  4.89942932   4.41398859   2.66900945   3.52503562   5.93764782\n",
      "    6.6544528    6.09078836   5.18256235   3.43386054   4.91790724]\n",
      " [  6.76380301   7.54957342   8.87621307   7.65353632  10.04989719\n",
      "    7.3408556    7.73220491   8.09129906   5.91336346   8.09853554]]\n",
      "Training set BPC at step 3400: 12.47141 learning rate: 0.100000\n",
      "memory=\n",
      " [[  6.8851943    9.3871994   10.54544353   9.5132103    9.3162117\n",
      "   10.03836632  10.8533659    9.60540104   7.8918047    9.8451376 ]\n",
      " [  5.82934332   8.37006569   6.90119171   7.50346518   8.32917023\n",
      "    7.45696592   7.3812542    7.70203972   7.24531603   7.87445164]\n",
      " [  7.15361929   5.61169434   7.27599382   5.66803312   7.18498182\n",
      "    7.59467125   8.61382675   5.9163661    7.01541185   7.68108511]\n",
      " [  5.00479269   4.37378597   2.97919393   3.63454485   5.95241404\n",
      "    6.71145725   6.1371665    5.29275084   3.55954075   5.0765934 ]\n",
      " [  6.9598937    7.6920352    9.37492943   7.83237267  10.22800922\n",
      "    7.58465862   7.938694     8.35367298   6.13486576   8.23759079]]\n",
      "Training set BPC at step 3500: 0.08889 learning rate: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[  7.26798391   9.77956772  10.96530247   9.91740227   9.59500408\n",
      "   10.38308716  11.15550232   9.83610821   8.19562721  10.00970554]\n",
      " [  6.13023853   8.82290554   7.15252256   7.8274622    8.51410198\n",
      "    7.72100592   7.62263203   7.83309555   7.42203283   7.91787863]\n",
      " [  7.39675617   5.90648222   7.4889493    5.91104364   7.34181929\n",
      "    7.80556297   8.80628014   6.06184483   7.18839407   7.77433634]\n",
      " [  5.15833855   4.68597651   3.01557541   3.77133679   6.00528097\n",
      "    6.80600309   6.24935865   5.31759596   3.60367465   5.05012083]\n",
      " [  7.29812384   8.09623241   9.77022648   8.22181034  10.47718811\n",
      "    7.89869022   8.20538616   8.50402546   6.37282658   8.31025028]]\n",
      "Training set BPC at step 3600: 0.68163 learning rate: 0.100000\n",
      "memory=\n",
      " [[  7.50505114  10.17921066  11.33293343  10.15253448  10.06380367\n",
      "   10.80856991  11.39659786  10.16469383   8.48966599  10.32464695]\n",
      " [  6.23485422   9.15652847   7.47066212   7.98714828   8.85101795\n",
      "    8.02707863   7.75609398   8.07607079   7.69981337   8.12593842]\n",
      " [  7.53454542   6.17577267   7.74315834   6.07626677   7.61870575\n",
      "    8.0549078    8.95452785   6.26091671   7.38745785   7.9747076 ]\n",
      " [  5.15388727   4.91239309   3.16543388   3.86728859   6.11434507\n",
      "    6.92941666   6.26263952   5.47588348   3.7958076    5.14434099]\n",
      " [  7.44184399   8.41779423  10.08243847   8.35864258  10.89770317\n",
      "    8.27893353   8.36728764   8.77784538   6.64531469   8.53646088]]\n",
      "Training set BPC at step 3700: 6.09341 learning rate: 0.100000\n",
      "memory=\n",
      " [[  7.90163231  10.43486595  11.47964096  10.35404015  10.26321125\n",
      "   10.86382294  11.56657791  10.40933132   8.64667892  10.41009998]\n",
      " [  6.56352043   9.25296497   7.5772872    8.15318489   8.96856594\n",
      "    7.95086527   7.8110795    8.24433327   7.75260735   8.11314392]\n",
      " [  7.78408909   6.26478148   7.82699251   6.19444275   7.72430229\n",
      "    8.04813671   9.00768471   6.39607334   7.4434638    7.99734592]\n",
      " [  5.34262848   4.88975906   3.22960043   3.98709822   6.15598774\n",
      "    6.81127262   6.24770164   5.55698156   3.78920007   5.08775997]\n",
      " [  7.81058693   8.67422009  10.21496105   8.5528965   11.06829166\n",
      "    8.28505898   8.53807259   9.0007925    6.79039383   8.58909607]]\n",
      "Training set BPC at step 3800: 1.85456 learning rate: 0.100000\n",
      "memory=\n",
      " [[  8.1359396   10.59127808  11.68531609  10.71015358  10.52064419\n",
      "   11.11100197  11.78533936  10.67561626   8.90765476  10.60080528]\n",
      " [  6.64068937   9.31048679   7.64204502   8.367342     9.01558685\n",
      "    8.0541172    7.93240499   8.2728014    7.91208696   8.18358612]\n",
      " [  7.87848139   6.3281498    7.8947463    6.36699915   7.80485106\n",
      "    8.15749168   9.09536171   6.46729946   7.56696987   8.07185459]\n",
      " [  5.30042315   4.86405468   3.19061732   4.01761866   6.0470438\n",
      "    6.79446125   6.27294922   5.4228797    3.82427907   5.07770586]\n",
      " [  8.0094099    8.81365681  10.41600418   8.90416622  11.29748535\n",
      "    8.49798775   8.77449703   9.24044418   7.053617     8.75976181]]\n",
      "Training set BPC at step 3900: 2.51799 learning rate: 0.100000\n",
      "memory=\n",
      " [[  8.39661598  10.85459042  12.09951973  11.25124454  10.90546703\n",
      "   11.4511776   12.20215321  11.04574394   9.17398548  10.87970066]\n",
      " [  6.73006201   9.44169617   7.87790489   8.61255646   9.28546429\n",
      "    8.33290291   8.18472099   8.48756409   8.04925251   8.29420471]\n",
      " [  7.98181677   6.44136333   8.09331894   6.58117104   8.01567078\n",
      "    8.36828423   9.30509377   6.63362741   7.68203306   8.18264389]\n",
      " [  5.24026155   4.87529945   3.20549202   3.97821331   6.12816381\n",
      "    6.93876028   6.31385183   5.45514393   3.84102392   5.04925346]\n",
      " [  8.24182796   9.06811237  10.81631947   9.44657612  11.66820717\n",
      "    8.81472206   9.17114353   9.6200285    7.31449652   9.01870155]]\n",
      "Training set BPC at step 4000: 2.74078 learning rate: 0.100000\n",
      "memory=\n",
      " [[  8.62798691  11.06278801  12.42387486  11.7186985   11.19272614\n",
      "   11.63968754  12.56654167  11.23189259   9.44048309  11.03635216]\n",
      " [  6.84631968   9.56095886   8.0941782    9.0645647    9.41011524\n",
      "    8.45632648   8.44462204   8.60945225   8.20295048   8.30568123]\n",
      " [  8.10533237   6.53822899   8.26974583   6.90826273   8.11511803\n",
      "    8.49077606   9.47849751   6.75186062   7.84526062   8.23227882]\n",
      " [  5.24135685   4.91989517   3.28596854   4.30437517   6.14318705\n",
      "    7.02759027   6.45239544   5.5382309    3.87907577   4.99165106]\n",
      " [  8.42101479   9.26662731  11.11276817   9.86750984  11.96772957\n",
      "    8.93427181   9.56394958   9.74466515   7.49788475   9.13196087]]\n",
      "Training set BPC at step 4100: 2.09515 learning rate: 0.100000\n",
      "memory=\n",
      " [[  9.02371788  11.29732895  12.72288418  12.21051025  11.5551548\n",
      "   11.86818886  12.88915157  11.53532505   9.67764378  11.40076542]\n",
      " [  7.27069807   9.78233814   8.32591152   9.52190685   9.7864933\n",
      "    8.68428612   8.73806953   8.89273071   8.43457127   8.6903162 ]\n",
      " [  8.42401886   6.73392916   8.47779655   7.25633383   8.39342499\n",
      "    8.67784786   9.70310307   6.97569132   8.03855515   8.50397015]\n",
      " [  5.53275681   5.10072374   3.39083195   4.55842257   6.36784077\n",
      "    7.20415878   6.62384653   5.71203613   4.05369043   5.25921345]\n",
      " [  8.74656487   9.40328407  11.33247662  10.3008337   12.28667831\n",
      "    9.09127045   9.84489346   9.99043846   7.65770245   9.46604156]]\n",
      "Training set BPC at step 4200: 4.07193 learning rate: 0.100000\n",
      "memory=\n",
      " [[  9.16809464  11.53780651  12.88742542  12.40736485  11.7681818\n",
      "   11.94953537  13.05531979  11.63701153   9.77708626  11.50752258]\n",
      " [  7.37548637   9.97174931   8.45048714   9.78762627  10.03804016\n",
      "    8.70020294   8.8634119    8.92017937   8.43671417   8.7915535 ]\n",
      " [  8.51192951   6.90090942   8.58360767   7.43533707   8.57032967\n",
      "    8.72402      9.82544708   7.03030825   8.09325218   8.58301258]\n",
      " [  5.5892663    5.21682262   3.49049401   4.82141256   6.61166763\n",
      "    7.18559361   6.69508743   5.69474363   3.99515224   5.33653164]\n",
      " [  8.86612415   9.57627678  11.45577526  10.4654007   12.4603672\n",
      "    9.12001133   9.94548607  10.04101753   7.68201399   9.5495863 ]]\n",
      "Training set BPC at step 4300: 3.92636 learning rate: 0.100000\n",
      "memory=\n",
      " [[  9.31366348  11.78849697  13.0724144   12.51768208  11.99873447\n",
      "   12.1191864   13.25081539  11.87903023  10.02054691  11.68935204]\n",
      " [  7.44259214  10.16892338   8.60634708   9.84948254  10.22767067\n",
      "    8.80091381   9.0133276    9.07066822   8.66333008   8.91901398]\n",
      " [  8.58706665   7.06364536   8.71769905   7.50285149   8.73711491\n",
      "    8.81556606   9.96201897   7.17650557   8.26775169   8.70550251]\n",
      " [  5.59511805   5.31851482   3.57407379   4.83226347   6.69457054\n",
      "    7.22106791   6.7575922    5.74976444   4.1055007    5.384974  ]\n",
      " [  8.97474766   9.78353119  11.59263325  10.53993034  12.63072681\n",
      "    9.26153946  10.08699512  10.22110844   7.89476919   9.67636967]]\n",
      "Training set BPC at step 4400: 1.83680 learning rate: 0.100000\n",
      "memory=\n",
      " [[  9.52181816  12.00068569  13.2276926   12.64768791  12.1714344\n",
      "   12.31075859  13.32967758  12.02795124  10.07992649  11.84488487]\n",
      " [  7.66928196  10.30690193   8.77833557   9.90091228  10.29386234\n",
      "    8.94312668   9.02579021   9.14638138   8.63352585   9.00122738]\n",
      " [  8.75238895   7.20161867   8.84525871   7.58981514   8.82636261\n",
      "    8.94474316  10.0126543    7.27835178   8.29327393   8.79692459]\n",
      " [  5.74545908   5.33393764   3.70865893   4.81150579   6.67464924\n",
      "    7.27473259   6.73343039   5.74823427   4.02774668   5.37958956]\n",
      " [  9.15527439   9.93718243  11.71724033  10.5922184   12.74771786\n",
      "    9.40507889  10.10093975  10.29388618   7.89245129   9.78694725]]\n",
      "Training set BPC at step 4500: 4.32788 learning rate: 0.100000\n",
      "memory=\n",
      " [[  9.80402851  12.36081696  13.46214962  12.94986153  12.36806202\n",
      "   12.53052521  13.57250595  12.21723175  10.30761623  12.19095707]\n",
      " [  7.95284891  10.6055851    8.98848057  10.19211292  10.47718716\n",
      "    9.07845306   9.23488712   9.26456451   8.74768639   9.33006954]\n",
      " [  8.97814083   7.44355059   9.02257538   7.83502579   8.98967934\n",
      "    9.08750725  10.20149994   7.4196825    8.4463625    9.05949402]\n",
      " [  5.93660736   5.4647398    3.82102966   4.98921251   6.80435085\n",
      "    7.29004955   6.84066916   5.78030729   3.99341846   5.53316784]\n",
      " [  9.36854458  10.24465275  11.89214993  10.80340576  12.86650085\n",
      "    9.55494118  10.26231861  10.38376141   8.01495457  10.07055283]]\n",
      "Training set BPC at step 4600: 3.39360 learning rate: 0.100000\n",
      "memory=\n",
      " [[  9.9473238   12.45497131  13.5830698   13.2821207   12.65145302\n",
      "   12.79871845  13.67789555  12.35938644  10.53091145  12.33797455]\n",
      " [  8.07673645  10.60508728   9.06409264  10.36144543  10.64018345\n",
      "    9.39236546   9.24943829   9.30948162   8.93980408   9.44140148]\n",
      " [  9.08864689   7.51052523   9.1035347    8.0100193    9.18515682\n",
      "    9.30159569  10.26189709   7.51409054   8.62928867   9.1663065 ]\n",
      " [  6.01592493   5.43460226   3.84304214   4.9732604    6.79947567\n",
      "    7.51434183   6.78931236   5.74842978   4.12169266   5.5937891 ]\n",
      " [  9.46216202  10.22802353  11.96783066  11.07364178  13.02725697\n",
      "    9.807477    10.29691792  10.42951488   8.13715744  10.16364384]]\n",
      "Training set BPC at step 4700: 2.09301 learning rate: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ 10.02234936  12.56306267  13.62746239  13.36639023  12.72086906\n",
      "   12.96455574  13.79468822  12.55919456  10.59315491  12.44140053]\n",
      " [  8.10723305  10.7226181    9.04156685  10.37512398  10.67312908\n",
      "    9.50917339   9.35860538   9.522645     8.92144489   9.4658041 ]\n",
      " [  9.14197922   7.59300041   9.12554836   8.06659889   9.23726177\n",
      "    9.42643833  10.35037041   7.67349434   8.64880753   9.23318005]\n",
      " [  6.03220081   5.52574158   3.7917459    4.9460721    6.81364441\n",
      "    7.56977129   6.87896824   5.90557766   4.07144928   5.55869961]\n",
      " [  9.48028851  10.32489014  11.95797539  11.08397293  13.04496002\n",
      "    9.89501476  10.38117504  10.59207916   8.15847874  10.19233704]]\n",
      "Training set BPC at step 4800: 1.39553 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 10.36020279  12.91185951  14.07751179  13.87800407  13.03811169\n",
      "   13.42077732  14.20510769  12.94034481  10.82588196  12.85246181]\n",
      " [  8.35806561  10.94859791   9.40243244  10.87587929  10.92146969\n",
      "    9.91424847   9.64872265   9.80268574   9.04291344   9.87099171]\n",
      " [  9.38146305   7.81080198   9.41014481   8.45762253   9.46207714\n",
      "    9.76028442  10.62641811   7.91240263   8.7963438    9.54241276]\n",
      " [  6.13121033   5.55843735   3.93639636   5.23955488   6.90075779\n",
      "    7.77428341   6.92618036   5.9878931    4.05372763   5.80581903]\n",
      " [  9.72079563  10.59716606  12.36900234  11.51203156  13.28278828\n",
      "   10.26617908  10.69202328  10.92053032   8.30786133  10.54971409]]\n",
      "Training set BPC at step 4900: 1.23086 learning rate: 0.100000\n",
      "memory=\n",
      " [[ 10.69484138  13.20399857  14.28347683  14.18078423  13.44381618\n",
      "   13.74729729  14.46946621  13.13035297  11.13699055  13.18498421]\n",
      " [  8.57208633  11.24557781   9.57637691  11.11568642  11.2569418\n",
      "   10.1538353    9.83053303   9.89758205   9.33064175  10.14494324]\n",
      " [  9.5973196    8.0489397    9.5670805    8.68590927   9.74324989\n",
      "    9.9882822   10.81605148   8.03966236   9.03691673   9.78630257]\n",
      " [  6.17832756   5.7571702    4.02974415   5.35376215   7.02102089\n",
      "    7.84431219   6.97007799   5.96725225   4.20378923   5.92341757]\n",
      " [  9.95618057  10.81275558  12.50694561  11.70354176  13.61588383\n",
      "   10.49693394  10.85520077  11.02067947   8.53987122  10.79016972]]\n",
      "Training set BPC at step 5000: 2.75105 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 11.09896755  13.76659298  14.51691246  14.43644524  13.68114853\n",
      "   13.95928478  14.71470451  13.51343536  11.52367973  13.564188  ]\n",
      " [  8.85953331  11.66078186   9.70529556  11.34375477  11.42396355\n",
      "   10.27104855   9.97104263  10.20638561   9.6177969   10.47198963]\n",
      " [  9.84665966   8.36485291   9.70536804   8.84996319   9.8708725\n",
      "   10.11519527  10.93573666   8.25441074   9.25727749  10.02344513]\n",
      " [  6.27071047   5.89743757   4.05737066   5.49930525   7.09072876\n",
      "    7.88035583   7.00954199   6.11792135   4.34566879   6.11115217]\n",
      " [ 10.29228115  11.36202431  12.66953278  11.9446907   13.8449316\n",
      "   10.63954544  11.08116722  11.41646576   8.90183449  11.15180874]]\n",
      "Training set BPC at step 5100: 4.39606 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 11.25961018  13.85466576  14.67299557  14.64297771  13.93492889\n",
      "   14.1235218   14.84191132  13.56578159  11.62268257  13.77315235]\n",
      " [  9.02381897  11.69842815   9.88733006  11.52751255  11.61728859\n",
      "   10.37644386  10.04196072  10.17712212   9.64617348  10.69286537]\n",
      " [  9.95341682   8.40431499   9.82451057   8.98805714  10.04369068\n",
      "   10.22300434  11.0162487    8.27079296   9.31966305  10.1775713 ]\n",
      " [  6.37504959   5.89732742   4.17737436   5.57836294   7.12629652\n",
      "    7.88691998   6.99564934   6.03892565   4.31535912   6.23972511]\n",
      " [ 10.46088219  11.4325695   12.82818413  12.13640022  14.04607487\n",
      "   10.75498772  11.1666851   11.42449284   8.93787289  11.35243797]]\n",
      "Training set BPC at step 5200: 2.67035 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 11.61358261  14.14449215  14.92546654  14.93041992  14.1202364\n",
      "   14.37471771  15.04724407  13.89364719  11.88673782  14.06317711]\n",
      " [  9.3396759   11.97332668  10.10766506  11.74860859  11.78130627\n",
      "   10.59555149  10.18719292  10.43577003   9.85357952  10.94877625]\n",
      " [ 10.1596384    8.58632755   9.96994495   9.14388275  10.16181087\n",
      "   10.36736012  11.13808727   8.45724201   9.47675228  10.33531475]\n",
      " [  6.56302881   6.06251431   4.32389927   5.6731534    7.23463726\n",
      "    8.01803589   7.04864788   6.14585924   4.41585207   6.4076252 ]\n",
      " [ 10.83986855  11.73513889  13.09190655  12.43407536  14.22021198\n",
      "   11.02152729  11.3448801   11.75547791   9.18635559  11.67772484]]\n",
      "Training set BPC at step 5300: 2.02526 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 11.93457127  14.55515575  15.16468906  15.33910275  14.6696043\n",
      "   14.65528965  15.38071156  14.14323044  12.31573582  14.52598286]\n",
      " [  9.4826479   12.31908417  10.2705822   12.20312786  12.27530956\n",
      "   10.75507259  10.58162785  10.63619995  10.15682316  11.27210236]\n",
      " [ 10.31283855   8.84487247  10.11748886   9.43921566  10.50674915\n",
      "   10.50492859  11.38676929   8.6262722    9.73432922  10.5923748 ]\n",
      " [  6.56003237   6.25033951   4.39646721   6.04184723   7.49667883\n",
      "    8.0557003    7.36313534   6.27949715   4.52337265   6.5325613 ]\n",
      " [ 11.10149479  12.11640644  13.27748966  12.84120083  14.77173042\n",
      "   11.2788105   11.68983555  11.94579411   9.55340767  12.10837841]]\n",
      "Training set BPC at step 5400: 5.21773 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 12.39690495  15.16379452  15.52641201  15.7572298   15.23547173\n",
      "   15.03193855  15.77302265  14.64441967  12.90667439  14.76932621]\n",
      " [  9.71780872  12.68302059  10.44582081  12.49213982  12.66812515\n",
      "   10.94278717  10.80570507  10.94553852  10.53890991  11.27050686]\n",
      " [ 10.51247215   9.14483833  10.27049351   9.694664    10.8096323\n",
      "   10.68730259  11.5781641    8.89667416  10.07759476  10.68005848]\n",
      " [  6.57122087   6.33693504   4.40440512   6.17760706   7.61546326\n",
      "    8.04549217   7.44060326   6.35582495   4.60201883   6.38877773]\n",
      " [ 11.55892086  12.70720387  13.63134861  13.17814159  15.32892704\n",
      "   11.61224365  12.05100727  12.39967346  10.06394482  12.25469875]]\n",
      "Training set BPC at step 5500: 4.01738 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 12.6722126   15.50879955  15.67749405  16.11826897  15.72669315\n",
      "   15.21636391  15.94001961  14.99028206  13.26545906  14.93086338]\n",
      " [  9.91149902  12.88776684  10.43944454  12.67947197  13.02504635\n",
      "   10.97444916  10.77411366  11.10094929  10.73205662  11.24696541]\n",
      " [ 10.67967033   9.35008526  10.3292408    9.87681103  11.10507774\n",
      "   10.76712227  11.61640835   9.05778503  10.23870468  10.7421608 ]\n",
      " [  6.62506962   6.33141327   4.30629539   6.18701982   7.70329189\n",
      "    7.95509005   7.29653215   6.34965897   4.64801693   6.24656105]\n",
      " [ 11.79454803  12.97757244  13.70747852  13.49446297  15.77123165\n",
      "   11.7339325   12.16348743  12.69266415  10.40932846  12.3237772 ]]\n",
      "Training set BPC at step 5600: 1.11212 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 12.96369457  15.87048531  16.04327965  16.30105209  15.99167347\n",
      "   15.51452541  16.20755386  15.27040195  13.66637421  15.15344524]\n",
      " [ 10.10016727  13.15043449  10.69550896  12.75871468  13.20142555\n",
      "   11.01630783  10.91969585  11.2992382   10.96221924  11.3303299 ]\n",
      " [ 10.86142731   9.57327271  10.54302406   9.97853947  11.25148201\n",
      "   10.84712505  11.78029537   9.2221365   10.45195389  10.87745762]\n",
      " [  6.6600275    6.42894983   4.38041353   6.18665409   7.78138399\n",
      "    7.85944366   7.30669451   6.4549737    4.69045973   6.23696804]\n",
      " [ 12.01624012  13.28218842  14.03237057  13.61074352  16.00510597\n",
      "   12.00039387  12.34085846  12.93117619  10.74943447  12.42758656]]\n",
      "Training set BPC at step 5700: 2.57578 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 13.05618477  16.0255127   16.29773712  16.56666374  16.34161186\n",
      "   15.69370174  16.42600441  15.49164677  13.89053249  15.45773888]\n",
      " [ 10.07967186  13.24633121  10.94093323  12.93992329  13.48809052\n",
      "   11.03857803  11.0830822   11.40401363  11.14515114  11.49377251]\n",
      " [ 10.89938831   9.66950607  10.72675705  10.13289261  11.47622681\n",
      "   10.9252491   11.92758083   9.34711361  10.62084007  11.03754711]\n",
      " [  6.56282616   6.43628073   4.50723076   6.231812     7.8855567\n",
      "    7.74870396   7.35230827   6.43853951   4.73714781   6.21761703]\n",
      " [ 12.04470539  13.39775562  14.26076317  13.84452152  16.32398605\n",
      "   12.11045647  12.50992012  13.08446121  10.90743542  12.68681145]]\n",
      "Training set BPC at step 5800: 3.57299 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 13.31818295  16.32546425  16.55807495  16.89641571  16.49722481\n",
      "   15.83489704  16.62187386  15.69259739  14.09052944  15.74236584]\n",
      " [ 10.2105875   13.40344429  11.10497189  13.17230701  13.4112072\n",
      "   11.0840292   11.07632446  11.47231197  11.26183605  11.67874718]\n",
      " [ 11.05621719   9.85062408  10.88478279  10.34096909  11.49032784\n",
      "   10.99939251  11.97278976   9.4640646   10.7355175   11.2021656 ]\n",
      " [  6.51797295   6.40027046   4.51592016   6.27065182   7.69294024\n",
      "    7.71315718   7.22476578   6.39570522   4.77129173   6.27406502]\n",
      " [ 12.22344398  13.60556316  14.46661758  14.11569977  16.42067719\n",
      "   12.19668484  12.6694231   13.18764687  11.05985546  12.92395306]]\n",
      "Training set BPC at step 5900: 1.75683 learning rate: 0.090000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ 13.43429661  16.63531685  16.79667854  17.04382706  16.57407379\n",
      "   16.00850487  16.65687943  15.82613754  14.28365707  15.9374485 ]\n",
      " [ 10.16023445  13.65401077  11.16518879  13.22885418  13.37457371\n",
      "   11.16219902  10.93703556  11.47299194  11.31969547  11.76667595]\n",
      " [ 11.07327271  10.05827332  10.98454762  10.40530014  11.51326466\n",
      "   11.1073494   11.95673656   9.50816822  10.81783867  11.29931927]\n",
      " [  6.38821888   6.50654268   4.44223213   6.26041222   7.60672665\n",
      "    7.71250963   7.04549885   6.33283091   4.71797276   6.25404787]\n",
      " [ 12.28939152  13.8702774   14.64535904  14.23839855  16.43720055\n",
      "   12.28985977  12.60051727  13.27252769  11.21221066  13.08101177]]\n",
      "Training set BPC at step 6000: 3.33460 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 13.66508293  16.79536247  17.1636219   17.11199951  16.75824547\n",
      "   16.21742439  16.95121193  15.96338654  14.35857201  16.17629242]\n",
      " [ 10.33539677  13.76104832  11.4366169   13.18825817  13.50144291\n",
      "   11.33118725  11.28138447  11.5479269   11.28814697  11.99335861]\n",
      " [ 11.23174763  10.15890312  11.21869183  10.43374729  11.64147091\n",
      "   11.25843906  12.18516922   9.5834713   10.84847069  11.4432745 ]\n",
      " [  6.43186617   6.54848576   4.51524973   6.16969013   7.64215231\n",
      "    7.79092932   7.27274418   6.33788443   4.62591791   6.39471245]\n",
      " [ 12.46766567  13.99045753  14.95915508  14.2301321   16.5590477\n",
      "   12.44091129  12.89543915  13.3824625   11.21988106  13.34284878]]\n",
      "Training set BPC at step 6100: 1.46035 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 13.80770683  17.06532478  17.35032845  17.22683525  16.8753624\n",
      "   16.49417114  17.03811455  16.1751709   14.50349331  16.29389191]\n",
      " [ 10.40528679  13.96681976  11.60711479  13.27276039  13.56298161\n",
      "   11.60934258  11.2680912   11.69406414  11.35542107  12.06990433]\n",
      " [ 11.32763386  10.36102104  11.36071587  10.51672459  11.71224976\n",
      "   11.47459602  12.22918224   9.74302483  10.94772816  11.52709579]\n",
      " [  6.41179228   6.62499857   4.59996367   6.1996603    7.6521101\n",
      "    7.96530199   7.20947886   6.38058233   4.60732365   6.41108704]\n",
      " [ 12.54095554  14.15925694  15.10083389  14.303936    16.63046265\n",
      "   12.66228867  12.90620422  13.49636173  11.285285    13.41096306]]\n",
      "Training set BPC at step 6200: 0.12721 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 14.23997784  17.36504745  17.51176453  17.51491547  17.08927536\n",
      "   16.76806068  17.34523392  16.48295403  14.79096889  16.5371685 ]\n",
      " [ 10.81800365  14.20914841  11.6906786   13.55174541  13.75543404\n",
      "   11.85069561  11.55588436  11.89673233  11.57802963  12.25745773]\n",
      " [ 11.66335487  10.57306671  11.48259926  10.74554348  11.87955761\n",
      "   11.65562439  12.4554882    9.95164871  11.15061188  11.68639469]\n",
      " [  6.6593833    6.74494076   4.64294863   6.3934412    7.78740597\n",
      "    8.1322422    7.38932943   6.43247461   4.6933527    6.52108145]\n",
      " [ 12.87081337  14.38948631  15.14966297  14.51247883  16.77270699\n",
      "   12.90450764  13.15524673  13.70642757  11.49519634  13.60325527]]\n",
      "Training set BPC at step 6300: 1.67579 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 14.37139797  17.43761826  17.6663208   17.63493347  17.38007355\n",
      "   16.84685898  17.51842117  16.6672821   14.88607121  16.64710999]\n",
      " [ 10.86978912  14.21107197  11.79944134  13.59231758  13.96467876\n",
      "   11.88124371  11.68128395  12.06419849  11.62777615  12.3135128 ]\n",
      " [ 11.72322083  10.61065388  11.56263447  10.79868984  12.06101894\n",
      "   11.69797039  12.56732273  10.06972313  11.20859337  11.7530489 ]\n",
      " [  6.67157078   6.72956896   4.72636318   6.39267063   7.87788057\n",
      "    8.1493969    7.44365263   6.54807425   4.71732044   6.53868532]\n",
      " [ 12.97110939  14.40538502  15.29370022  14.60062218  17.01441193\n",
      "   12.94742393  13.28955269  13.88225937  11.55142689  13.66944885]]\n",
      "Training set BPC at step 6400: 2.29154 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 14.74665737  17.83646584  18.00246048  17.99566269  17.670187\n",
      "   17.13420677  17.76398277  16.98975754  15.30655098  17.07086563]\n",
      " [ 11.29711246  14.57793617  12.09638405  13.9279995   14.20368385\n",
      "   12.09429836  11.92461586  12.33646011  11.95602322  12.71312714]\n",
      " [ 12.02663708  10.89346504  11.81469631  11.08386421  12.27483654\n",
      "   11.87507629  12.75799751  10.28434181  11.46005821  12.07232761]\n",
      " [  7.01465273   6.93568516   4.89312601   6.61591101   8.00794029\n",
      "    8.2500248    7.63048649   6.69025707   4.86574793   6.79111719]\n",
      " [ 13.29345512  14.74863625  15.54122543  14.84850597  17.21531677\n",
      "   13.19048691  13.47532654  14.16072369  11.94373608  14.00734615]]\n",
      "Training set BPC at step 6500: 1.99283 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 14.95456886  18.05224037  18.3970108   18.25806618  17.87930679\n",
      "   17.41273689  18.08708572  17.27978897  15.61675644  17.3369503 ]\n",
      " [ 11.51179981  14.81478882  12.48383713  14.13009834  14.43048573\n",
      "   12.29950714  12.11136436  12.59881592  12.2098484   12.95092583]\n",
      " [ 12.16679478  11.04386806  12.07593441  11.22915173  12.41779327\n",
      "   12.03385544  12.90978813  10.46489906  11.66034508  12.24510193]\n",
      " [  7.14847326   7.09499264   5.1049614    6.69357872   8.15515041\n",
      "    8.32748413   7.64691305   6.82043219   4.95362139   6.91105604]\n",
      " [ 13.51141739  14.97889709  15.94799042  15.11641026  17.44208527\n",
      "   13.45456123  13.79565334  14.45895004  12.22464657  14.26300716]]\n",
      "Training set BPC at step 6600: 1.26917 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 15.27173424  18.30710602  18.66890526  18.456007    18.18694878\n",
      "   17.54122734  18.34376907  17.58962059  15.85153198  17.60988045]\n",
      " [ 11.77995491  14.97432518  12.63253593  14.20772743  14.71553516\n",
      "   12.32934093  12.30832005  12.77709103  12.38402557  13.14369678]\n",
      " [ 12.36503696  11.20478821  12.24177074  11.32192326  12.62763214\n",
      "   12.09687614  13.08033943  10.64214516  11.80240345  12.4121685 ]\n",
      " [  7.28171778   7.14577627   5.08077002   6.68231153   8.30214405\n",
      "    8.27970219   7.71981096   6.83469009   5.02315474   6.97983742]\n",
      " [ 13.81299019  15.15698051  16.13959694  15.26933765  17.72854614\n",
      "   13.53037548  14.00107861  14.70278263  12.43174648  14.49057102]]\n",
      "Training set BPC at step 6700: 2.93192 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 15.51681614  18.40619659  19.01810646  18.86728477  18.48693275\n",
      "   17.81010437  18.65071869  17.8844986   16.11222458  17.77033997]\n",
      " [ 11.85977268  14.8005085   12.78150177  14.43085003  14.85281181\n",
      "   12.39917278  12.45311356  12.91960049  12.49893093  13.06228256]\n",
      " [ 12.47993279  11.19938087  12.42648029  11.52092934  12.78285503\n",
      "   12.22076702  13.24916458  10.81203175  11.94810677  12.45340633]\n",
      " [  7.22951365   6.85133505   5.04361534   6.68800163   8.26173973\n",
      "    8.19223213   7.68935204   6.80768633   5.01387787   6.77464056]\n",
      " [ 13.98913574  15.1223135   16.38671303  15.64945507  17.96282196\n",
      "   13.71172619  14.22346687  14.90633106  12.60143852  14.53634167]]\n",
      "Training set BPC at step 6800: 3.71042 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 15.75645161  18.61381149  19.3868866   19.19512939  18.69766998\n",
      "   18.12665558  18.84617043  18.20004082  16.42973709  18.06404495]\n",
      " [ 11.96103477  14.90086079  13.14041519  14.66171741  14.98062801\n",
      "   12.65017414  12.61215496  13.1943388   12.91913986  13.31164742]\n",
      " [ 12.622715    11.35272503  12.69412327  11.72674561  12.91291428\n",
      "   12.44222355  13.39301014  11.03956985  12.22211552  12.6413002 ]\n",
      " [  7.23559237   6.89272118   5.27116823   6.79620171   8.32211304\n",
      "    8.29043961   7.79622507   6.98965073   5.39389277   6.91639709]\n",
      " [ 14.11864662  15.18326092  16.70905685  15.9040451   18.10572624\n",
      "   13.9517355   14.35164642  15.14464188  12.89644623  14.80355358]]\n",
      "Training set BPC at step 6900: 0.72488 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 15.89695358  18.80754662  19.54081535  19.51310539  18.96274757\n",
      "   18.63091087  19.06148911  18.46399498  16.7366066   18.51478767]\n",
      " [ 11.95783615  15.02022839  13.17990303  15.01072788  15.24119663\n",
      "   13.13319683  12.73877621  13.36644936  13.23648262  13.67666245]\n",
      " [ 12.7054491   11.49986839  12.78177547  11.98964787  13.11892509\n",
      "   12.83538914  13.5379343   11.23313427  12.46834946  12.9673233 ]\n",
      " [  7.12160873   6.92484093   5.21794844   7.03796148   8.46251011\n",
      "    8.55032349   7.80120659   7.02031994   5.58856106   7.07062006]\n",
      " [ 14.14368916  15.27077579  16.78272247  16.16235542  18.32199097\n",
      "   14.35143661  14.48523045  15.29244804  13.14411545  15.14118004]]\n",
      "Training set BPC at step 7000: 0.00157 learning rate: 0.090000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ 16.12380028  19.1020813   19.77911377  19.75449181  19.2549324\n",
      "   18.85455704  19.19846153  18.75199509  17.03657341  18.73190308]\n",
      " [ 12.10137177  15.27678299  13.2986002   15.21354389  15.4420166\n",
      "   13.33500671  12.79788685  13.59050465  13.512043    13.82618332]\n",
      " [ 12.85977459  11.73500443  12.94261456  12.1600666   13.33222866\n",
      "   13.01893234  13.63807392  11.44608212  12.70606709  13.11136436]\n",
      " [  7.16664219   7.100667     5.24259663   7.18993044   8.56725216\n",
      "    8.7065506    7.82397985   7.15398407   5.77563381   7.13872147]\n",
      " [ 14.28773403  15.4599638   16.90650177  16.34461975  18.49421501\n",
      "   14.48390865  14.52462387  15.48493195  13.34963512  15.29634571]]\n",
      "Training set BPC at step 7100: 1.07547 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 16.16317749  19.26581955  19.86623573  19.88246727  19.36651039\n",
      "   19.05417633  19.36450195  18.85756111  17.17725372  18.9296875 ]\n",
      " [ 12.03099632  15.46335125  13.31039906  15.34756851  15.54849529\n",
      "   13.5063982   12.92863083  13.71126652  13.63805294  14.0114336 ]\n",
      " [ 12.8605566   11.87393475  13.00691605  12.25920868  13.42183304\n",
      "   13.17948341  13.7350502   11.54219913  12.80830479  13.27126598]\n",
      " [  7.0767312    7.29034853   5.24322271   7.30038595   8.65674877\n",
      "    8.82130432   7.91084719   7.29368544   5.88459778   7.27216721]\n",
      " [ 14.25901031  15.5755024   16.89486885  16.44603348  18.56558037\n",
      "   14.59738064  14.6779604   15.54118919  13.45188332  15.4229641 ]]\n",
      "Training set BPC at step 7200: 1.92233 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 16.36004257  19.44600868  20.18303108  20.17097855  19.56859779\n",
      "   19.32974434  19.56073189  19.11227036  17.59183121  19.11649704]\n",
      " [ 12.1426897   15.62252331  13.57207108  15.58924961  15.67629623\n",
      "   13.69633293  13.06999969  13.86162758  14.0121212   14.12302876]\n",
      " [ 12.96971512  11.99602985  13.21591282  12.44416046  13.56044674\n",
      "   13.34561348  13.8522234   11.67701817  13.0699234   13.36688232]\n",
      " [  7.13458681   7.40153742   5.40465832   7.44956541   8.72450447\n",
      "    8.88096523   7.99658918   7.33302689   6.13087511   7.31701279]\n",
      " [ 14.40891266  15.73068905  17.16836548  16.70282364  18.68183517\n",
      "   14.82937813  14.84393692  15.76370907  13.86384296  15.59080887]]\n",
      "Training set BPC at step 7300: 3.36253 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 16.55290413  19.68853569  20.35916901  20.46298218  19.77162361\n",
      "   19.60615921  19.80665016  19.36634064  17.74805069  19.28142548]\n",
      " [ 12.26608562  15.73760223  13.6026144   15.86429787  15.89718628\n",
      "   13.86144161  13.2863369   14.06834221  14.13681602  14.24616528]\n",
      " [ 13.0875864   12.12172508  13.30363178  12.67339516  13.73035431\n",
      "   13.52133083  14.04868889  11.88057137  13.18055725  13.49662209]\n",
      " [  7.20970488   7.41097975   5.36217642   7.63217545   8.92216206\n",
      "    8.94686317   8.15620232   7.47483015   6.21262503   7.41646004]\n",
      " [ 14.5496521   15.91909409  17.25410843  16.92134857  18.83183861\n",
      "   15.01756573  14.99427986  15.9077301   13.97657108  15.66921425]]\n",
      "Training set BPC at step 7400: 4.56088 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 16.63047409  20.00584984  20.65906525  20.59470177  19.86566353\n",
      "   19.61872482  20.08520508  19.59654999  17.86324501  19.36727142]\n",
      " [ 12.21140003  15.9539156   13.82228279  15.87300301  15.82944393\n",
      "   13.67900276  13.44740391  14.20364666  14.04297066  14.21660614]\n",
      " [ 13.11638737  12.3290472   13.51975441  12.73378277  13.76374626\n",
      "   13.486413    14.22906971  12.04493713  13.19428635  13.540802  ]\n",
      " [  7.1015377    7.49161386   5.4545083    7.57409191   8.8155489\n",
      "    8.7229147    8.21362877   7.52867126   6.05570745   7.35062933]\n",
      " [ 14.53952408  16.14961624  17.45653152  16.98405075  18.81397629\n",
      "   14.91551113  15.17228508  16.02810287  13.99969578  15.66149807]]\n",
      "Training set BPC at step 7500: 3.43957 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 16.85795593  20.27827644  20.79550552  20.78549004  20.01865387\n",
      "   19.76713371  20.219944    19.89347839  18.06723595  19.64870644]\n",
      " [ 12.30616474  16.17320251  13.76512241  16.06511879  15.94010258\n",
      "   13.68587399  13.52175426  14.37965775  14.13755417  14.41440678]\n",
      " [ 13.22487926  12.52093792  13.54984093  12.87606049  13.86696625\n",
      "   13.54014683  14.31343842  12.22102165  13.30485535  13.73258686]\n",
      " [  7.07682371   7.60192537   5.31018686   7.71832657   8.8797493\n",
      "    8.66085911   8.23937798   7.53665352   6.06871223   7.41567469]\n",
      " [ 14.72268105  16.36082649  17.51486015  17.1460762   18.92024994\n",
      "   15.00687504  15.25534058  16.2582283   14.1415863   15.85767078]]\n",
      "Training set BPC at step 7600: 2.53303 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 17.02271652  20.55188179  20.89614677  21.08301735  20.19478035\n",
      "   19.90240479  20.40330315  20.19717407  18.12479591  19.79897881]\n",
      " [ 12.37978554  16.38176346  13.7843647   16.33530807  16.12049484\n",
      "   13.75464916  13.58187294  14.57431507  14.06833553  14.5290184 ]\n",
      " [ 13.32961845  12.70062256  13.6151371   13.1027565   14.00622463\n",
      "   13.63557625  14.39317608  12.40915298  13.31914139  13.83866978]\n",
      " [  7.05246258   7.67400455   5.2920022    7.86025906   9.01880932\n",
      "    8.68008232   8.22766399   7.58170223   5.95101976   7.47777605]\n",
      " [ 14.81027699  16.58325386  17.53214455  17.36803055  19.05580139\n",
      "   15.06096363  15.39339066  16.48645973  14.11599827  15.95748711]]\n",
      "Training set BPC at step 7700: 2.73786 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 17.15282631  20.61039162  20.97549438  21.2095356   20.3309269\n",
      "   20.13920403  20.51826286  20.26471519  18.21436691  19.90033531]\n",
      " [ 12.33303547  16.33006477  13.79260063  16.38651085  16.20102692\n",
      "   13.96588802  13.65202427  14.58647728  14.09724522  14.45444584]\n",
      " [ 13.40402603  12.73735428  13.66808128  13.17374992  14.10596466\n",
      "   13.81578827  14.4776659   12.46660519  13.38847542  13.87333775]\n",
      " [  6.89621973   7.60632324   5.26264668   7.85303497   9.03233814\n",
      "    8.77583694   8.25179291   7.59622431   5.95666885   7.30891132]\n",
      " [ 14.78745174  16.5241394   17.53594398  17.44020271  19.11877441\n",
      "   15.23548222  15.44267273  16.45919037  14.11817455  15.94595909]]\n",
      "Training set BPC at step 7800: 2.77116 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 17.44472122  20.85466576  21.08747673  21.40659523  20.54495049\n",
      "   20.26319313  20.72035217  20.4544754   18.55206299  20.00556183]\n",
      " [ 12.63964558  16.57981491  13.79742336  16.53993607  16.36959267\n",
      "   14.07504272  13.78168201  14.73867798  14.39363098  14.48565769]\n",
      " [ 13.62825966  12.92016792  13.72770786  13.31574154  14.24633121\n",
      "   13.90970802  14.61899567  12.59589672  13.59742546  13.93972301]\n",
      " [  7.1070466    7.77763271   5.20065212   7.98512077   9.13517475\n",
      "    8.88601494   8.29638481   7.70669174   6.12512732   7.31248045]\n",
      " [ 15.03966331  16.73733521  17.56846619  17.55977058  19.28787041\n",
      "   15.31191063  15.55890465  16.59915543  14.44857121  15.97696209]]\n",
      "Training set BPC at step 7900: 2.54598 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 17.51314926  20.9375      21.34321785  21.47535515  20.73748016\n",
      "   20.31412697  20.9641571   20.51445007  18.58799171  20.10088539]\n",
      " [ 12.5688591   16.53942299  13.93761349  16.47404671  16.44560814\n",
      "   13.96901417  13.93828964  14.67873669  14.25528049  14.4481554 ]\n",
      " [ 13.63296032  12.93521118  13.89478111  13.32173061  14.34826851\n",
      "   13.90421486  14.78430653  12.60811901  13.56735325  13.96530724]\n",
      " [  6.98380566   7.68054342   5.20212841   7.86773491   9.09030247\n",
      "    8.74104214   8.3305521    7.58961296   5.93453169   7.21568727]\n",
      " [ 15.04742527  16.77515411  17.72970581  17.56999397  19.42334366\n",
      "   15.27689266  15.72251987  16.5946331   14.41261101  16.01208305]]\n",
      "Training set BPC at step 8000: 0.83901 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 17.67791176  21.06890297  21.53248024  21.75137138  20.91623688\n",
      "   20.46246338  21.20884514  20.74798584  18.76707649  20.40946579]\n",
      " [ 12.67491245  16.59531212  14.01914406  16.7023468   16.48263741\n",
      "   14.02728748  14.0693922   14.75550461  14.30959606  14.57165909]\n",
      " [ 13.73755741  13.00283241  14.00267887  13.51286983  14.41873932\n",
      "   13.96726418  14.90207672  12.72306442  13.66215992  14.10993099]\n",
      " [  7.0332222    7.67546892   5.18442774   8.00096893   9.05941963\n",
      "    8.73727322   8.36529446   7.52371597   5.87747335   7.20704699]\n",
      " [ 15.16332912  16.87162971  17.85037231  17.79247093  19.55035782\n",
      "   15.40368748  15.94184589  16.75848961  14.52100086  16.26085854]]\n",
      "Training set BPC at step 8100: 2.72717 learning rate: 0.090000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ 17.76004028  21.337883    21.83579063  21.92007446  21.04336548\n",
      "   20.6552906   21.45885658  20.98411942  19.01706696  20.63298225]\n",
      " [ 12.57814217  16.728899    14.17374134  16.69368362  16.44054222\n",
      "   14.09382629  14.19851303  14.78962612  14.33572578  14.5413456 ]\n",
      " [ 13.74223423  13.1401701   14.18477058  13.56896687  14.45994186\n",
      "   14.04910374  15.0405407   12.82604313  13.74411774  14.16063499]\n",
      " [  6.85835314   7.66890049   5.17513895   7.88003206   8.91070271\n",
      "    8.7063036    8.34101963   7.39369726   5.74084473   7.02222681]\n",
      " [ 15.16257954  17.09135818  18.05630875  17.89224434  19.59581947\n",
      "   15.56139565  16.13433456  16.90564537  14.71663189  16.42279625]]\n",
      "Training set BPC at step 8200: 1.81756 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 17.87589073  21.46368027  21.98634911  22.02259445  21.32466888\n",
      "   20.75629997  21.73462296  21.20092201  19.22961807  20.74131966]\n",
      " [ 12.62778282  16.83875084  14.29209995  16.72482109  16.62910843\n",
      "   14.15124607  14.47942066  14.97465515  14.52064896  14.5112505 ]\n",
      " [ 13.81085396  13.23727226  14.28733253  13.61751556  14.64114571\n",
      "   14.1143465   15.26523685  12.97464085  13.88466263  14.19540501]\n",
      " [  6.90050888   7.76765251   5.24203396   7.8806982    8.99135113\n",
      "    8.73544216   8.56219673   7.51506233   5.85059929   6.9425559 ]\n",
      " [ 15.21658516  17.16883659  18.17167282  17.95750618  19.80560112\n",
      "   15.62123489  16.34319878  17.08242035  14.90713692  16.46095657]]\n",
      "Training set BPC at step 8300: 2.48348 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 18.18050385  21.66819954  22.15779877  22.26863861  21.62504196\n",
      "   20.86653328  21.89517403  21.31985855  19.40120888  20.9807682 ]\n",
      " [ 12.83150005  17.00651932  14.37906742  16.87528229  16.85111046\n",
      "   14.1391449   14.47599506  14.89663506  14.58455372  14.63404655]\n",
      " [ 14.01016331  13.38935184  14.39045048  13.7857914   14.85198784\n",
      "   14.17350292  15.34125805  13.03141499  13.96537495  14.33878803]\n",
      " [  6.97515392   7.88385105   5.28033924   7.98082638   9.08976746\n",
      "    8.68788052   8.49186516   7.36611986   5.84856606   6.96049929]\n",
      " [ 15.42927647  17.30070305  18.27313995  18.08649635  20.00909805\n",
      "   15.62740993  16.39153099  17.03984833  15.03209972  16.61490822]]\n",
      "Training set BPC at step 8400: 3.43394 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 18.39709091  21.91865921  22.36700439  22.63592339  21.8980732\n",
      "   21.03970337  22.04655266  21.49555779  19.75787926  21.16449738]\n",
      " [ 12.93217659  17.20540619  14.53067303  17.10837173  17.02897835\n",
      "   14.29106426  14.49649143  15.03944874  14.87378502  14.72608566]\n",
      " [ 14.11713409  13.56190872  14.54584312  14.02907848  15.03379917\n",
      "   14.29800224  15.42227173  13.16204929  14.23150444  14.44401741]\n",
      " [  6.98763275   7.99600029   5.35611439   8.03913307   9.11210918\n",
      "    8.77556705   8.41222477   7.45327044   5.97914886   6.96021843]\n",
      " [ 15.60285664  17.48833656  18.39456558  18.33964539  20.20039368\n",
      "   15.76570511  16.45585823  17.15692711  15.28568554  16.74393082]]\n",
      "Training set BPC at step 8500: 1.33463 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 18.67938995  22.07747459  22.63358307  22.95191574  21.99824715\n",
      "   21.21355057  22.28374863  21.69774818  19.87081146  21.31061172]\n",
      " [ 13.11707497  17.25855255  14.72323227  17.3650341   16.98594284\n",
      "   14.40653706  14.70387936  15.12297058  14.9006319   14.76249504]\n",
      " [ 14.28846741  13.64123917  14.72259617  14.20802212  15.07620239\n",
      "   14.40537262  15.57145119  13.27867603  14.28736687  14.51826763]\n",
      " [  7.03213024   7.95346975   5.4388504    8.15849972   8.99471855\n",
      "    8.79895592   8.52226639   7.41502237   5.94237709   6.90632725]\n",
      " [ 15.82919121  17.59839058  18.60265732  18.66787529  20.2049942\n",
      "   15.90397453  16.68735313  17.28279495  15.35243034  16.82960892]]\n",
      "Training set BPC at step 8600: 1.47639 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 18.78735542  22.24506378  22.88917923  23.03867912  22.24125862\n",
      "   21.3472023   22.48810768  21.79337502  19.99960899  21.41083908]\n",
      " [ 13.11476135  17.36953163  14.94332409  17.32684898  17.17987823\n",
      "   14.44224644  14.84142971  15.11038113  14.97619629  14.77562714]\n",
      " [ 14.35316849  13.75783157  14.92435551  14.25788307  15.27293491\n",
      "   14.49470329  15.72480869  13.33513832  14.37215042  14.57132721]\n",
      " [  6.96413088   7.97910547   5.54905653   8.0568924    9.10137272\n",
      "    8.75379276   8.56694794   7.35337925   5.96635437   6.8659544 ]\n",
      " [ 15.84219646  17.70670891  18.77956581  18.6447506   20.34218025\n",
      "   15.94139385  16.79726028  17.28085136  15.43161964  16.87095261]]\n",
      "Training set BPC at step 8700: 2.42817 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 18.95059204  22.55706978  23.23622704  23.36715698  22.60593605\n",
      "   21.62230682  22.70516396  22.09990883  20.18573761  21.58605957]\n",
      " [ 13.19355297  17.55155945  15.29995632  17.593256    17.46389389\n",
      "   14.68625259  15.06390285  15.39318275  15.13480854  14.85089588]\n",
      " [ 14.45480824  13.92319393  15.20299435  14.49685669  15.50277424\n",
      "   14.69909859  15.89615917  13.54131699  14.50907421  14.68132591]\n",
      " [  6.99414396   8.03606033   5.81068659   8.19066429   9.25447083\n",
      "    8.92926788   8.74828911   7.52370405   6.08143282   6.8635478 ]\n",
      " [ 15.9297123   17.97387695  19.05605888  18.8772831   20.65459442\n",
      "   16.14032745  16.96431923  17.56684113  15.55867195  16.9557209 ]]\n",
      "Training set BPC at step 8800: 2.12383 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 18.97447205  22.65119934  23.43482208  23.48888588  22.61789131\n",
      "   21.71254158  22.77920151  22.09363174  20.23266029  21.63488197]\n",
      " [ 13.12758827  17.56394958  15.44303799  17.55701256  17.39186096\n",
      "   14.71672916  15.06079102  15.24906349  15.02056026  14.70429993]\n",
      " [ 14.45991421  13.99163342  15.36731529  14.57027149  15.49791908\n",
      "   14.74763107  15.95017719  13.51933384  14.49968529  14.66742802]\n",
      " [  6.92207241   8.04360294   5.90470886   8.07470989   9.18828201\n",
      "    8.93245792   8.73171616   7.37896395   5.92843294   6.65779543]\n",
      " [ 15.87508583  17.96279526  19.14187241  18.85415649  20.59265327\n",
      "   16.1895504   16.94351196  17.44582367  15.51689339  16.89468956]]\n",
      "Training set BPC at step 8900: 4.83170 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 19.12486649  22.74650002  23.73816681  23.65770721  22.70927429\n",
      "   22.04520226  23.01441574  22.24228477  20.47660828  21.7278347 ]\n",
      " [ 13.2510004   17.54315758  15.72557545  17.65261459  17.3333149\n",
      "   15.05217171  15.22594929  15.32466221  15.1680088   14.72438622]\n",
      " [ 14.58661652  14.04911518  15.61530495  14.68487644  15.52861214\n",
      "   15.02792358  16.13299751  13.62216663  14.67894936  14.73472977]\n",
      " [  7.01617241   7.96146393   6.0852232    8.09090996   9.07480431\n",
      "    9.1740675    8.80133438   7.39957285   5.98747873   6.64630079]\n",
      " [ 15.94641209  17.95768356  19.34454346  18.95275497  20.59357643\n",
      "   16.42495537  17.07488632  17.5166378   15.64557076  16.90431404]]\n",
      "Training set BPC at step 9000: 4.55799 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 19.19475365  23.13231277  24.01537132  23.8855114   22.90533066\n",
      "   22.16279984  23.10305214  22.4212513   20.67551041  21.93283653]\n",
      " [ 13.2247715   17.91982651  15.88552094  17.87700844  17.42367172\n",
      "   15.11373043  15.23168373  15.46052647  15.34892654  14.84075451]\n",
      " [ 14.61826706  14.35060406  15.8013525   14.86028671  15.66105175\n",
      "   15.11077976  16.18486214  13.73001862  14.83059597  14.85084248]\n",
      " [  6.94933605   8.1859951    6.11052227   8.23839855   9.06106567\n",
      "    9.21011734   8.76255798   7.48548269   6.1001792    6.67445803]\n",
      " [ 15.94823074  18.27388     19.5200386   19.13691711  20.68789864\n",
      "   16.4711647   17.09549141  17.67171097  15.79329205  17.06329536]]\n",
      "Training set BPC at step 9100: 4.26373 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 19.55649185  23.36951828  24.33089828  24.28446579  23.28932571\n",
      "   22.44796562  23.34177399  22.68606377  20.9701767   22.35611153]\n",
      " [ 13.66295052  18.18346596  16.13680077  18.24671364  17.86021805\n",
      "   15.46845341  15.43642521  15.71158504  15.67852879  15.32215595]\n",
      " [ 14.88889313  14.53053188  16.01068115  15.09614849  15.93878269\n",
      "   15.33247375  16.35694313  13.89748573  15.04734421  15.18461609]\n",
      " [  7.27908754   8.39959812   6.24350119   8.48643684   9.37917519\n",
      "    9.50176811   8.89047813   7.6543889    6.3617878    7.02499723]\n",
      " [ 16.34378433  18.49791718  19.79136276  19.57146263  21.09646797\n",
      "   16.77070236  17.27864265  17.94639397  16.0871067   17.46813011]]\n",
      "Training set BPC at step 9200: 3.63137 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 19.83128738  23.61390305  24.67889977  24.71619034  23.59737968\n",
      "   22.89769173  23.81072426  22.92576408  21.22266769  22.75459099]\n",
      " [ 13.97640705  18.41394615  16.52394485  18.73010254  18.13656616\n",
      "   16.00927925  15.97090435  15.89048767  15.92567348  15.73934555]\n",
      " [ 15.11183929  14.71551418  16.27978516  15.4400425   16.14226913\n",
      "   15.70231533  16.74522018  14.05715847  15.22363186  15.51480675]\n",
      " [  7.53857231   8.55467415   6.51621819   8.84769058   9.54581642\n",
      "    9.9109869    9.29973221   7.7347517    6.5326643    7.33377695]\n",
      " [ 16.58352661  18.69230652  20.1194725   19.96741295  21.38628387\n",
      "   17.19895172  17.68497467  18.1338253   16.32630539  17.774683  ]]\n",
      "Training set BPC at step 9300: 3.23057 learning rate: 0.090000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=\n",
      " [[ 19.98944092  23.90219879  24.93404388  24.90758514  23.80462074\n",
      "   23.05251312  23.98224449  23.15200233  21.33725357  23.06303406]\n",
      " [ 14.11722469  18.68014908  16.75949669  18.86453056  18.34955788\n",
      "   16.06866264  16.10206413  16.0410347   15.97167587  15.99679661]\n",
      " [ 15.24664116  14.94696045  16.47942162  15.58908463  16.31477928\n",
      "   15.8000946   16.88092232  14.22905827  15.30720329  15.76546288]\n",
      " [  7.65221262   8.73490047   6.65351105   8.93478775   9.69991112\n",
      "    9.91291809   9.38517666   7.78411722   6.55573225   7.48165989]\n",
      " [ 16.6615448   18.8841114   20.30265427  20.05385971  21.53364372\n",
      "   17.2613678   17.77129555  18.24555206  16.34903526  17.95440292]]\n",
      "Training set BPC at step 9400: 2.51365 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 20.35612869  24.05298042  25.26974678  25.17163849  23.95405197\n",
      "   23.16744804  24.04198647  23.27064323  21.4329071   23.30231476]\n",
      " [ 14.4578476   18.82097054  17.0442791   19.14455032  18.43238831\n",
      "   16.10301018  16.0748024   16.13743591  15.98202133  16.28152657]\n",
      " [ 15.52759933  15.05986404  16.73685455  15.80494499  16.40820312\n",
      "   15.87339115  16.92409706  14.32277584  15.35765457  15.94421387]\n",
      " [  7.93388557   8.83595848   6.82219219   9.14089489   9.72762489\n",
      "    9.89416695   9.3709116    7.8733263    6.52963209   7.71654701]\n",
      " [ 16.93307686  19.00292397  20.53533363  20.27174377  21.62838364\n",
      "   17.30366898  17.72271919  18.30651665  16.38438225  18.20568848]]\n",
      "Training set BPC at step 9500: 0.46592 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 20.55168152  24.21608543  25.43756104  25.25840759  24.18298721\n",
      "   23.36558533  24.11838722  23.53931808  21.59815407  23.52756119]\n",
      " [ 14.5849371   18.96543312  17.10395622  19.15225601  18.65374947\n",
      "   16.2662468   16.05381966  16.38274765  16.05949402  16.43605804]\n",
      " [ 15.65964031  15.19972324  16.83029175  15.86489773  16.59566689\n",
      "   16.01278305  16.97626305  14.52327728  15.47146225  16.1013546 ]\n",
      " [  8.00494099   8.97062206   6.80267143   9.13546181   9.91718769\n",
      "    9.98619938   9.33838367   8.06974316   6.55190802   7.76150846]\n",
      " [ 17.04948997  19.07402229  20.62807655  20.26282692  21.76946449\n",
      "   17.44892693  17.68650055  18.49988556  16.44744873  18.34973526]]\n",
      "Training set BPC at step 9600: 2.97200 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 20.77110481  24.39432526  25.50253677  25.44720459  24.31134415\n",
      "   23.49744987  24.26838493  23.65712166  21.72221756  23.65096474]\n",
      " [ 14.76852036  19.18473816  17.1104126   19.27447891  18.74889565\n",
      "   16.40968895  16.22563934  16.53011703  16.18288803  16.56524658]\n",
      " [ 15.82113361  15.33490467  16.86145973  15.9805975   16.68133736\n",
      "   16.11883545  17.09064293  14.61410046  15.55189514  16.18696213]\n",
      " [  8.0924654    9.13886738   6.78750038   9.16578293   9.96868706\n",
      "   10.10134888   9.4624033    8.19047165   6.64022207   7.88113832]\n",
      " [ 17.20753098  19.2645092   20.65311432  20.41698647  21.86309814\n",
      "   17.55509186  17.8300705   18.62272453  16.57335472  18.46339417]]\n",
      "Training set BPC at step 9700: 2.20756 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 21.0779953   24.68940735  25.76313591  25.61373901  24.77089691\n",
      "   23.64125824  24.5512352   23.8204155   22.03718567  23.92544365]\n",
      " [ 15.015728    19.33753586  17.28507423  19.26074982  19.19361115\n",
      "   16.42459869  16.43102837  16.579319    16.45863914  16.67429543]\n",
      " [ 15.992486    15.47939777  16.99464417  16.03000832  16.985466\n",
      "   16.17501831  17.22382545  14.68327713  15.71634007  16.29707336]\n",
      " [  8.19100952   9.11541462   6.82663441   9.02245903  10.19155502\n",
      "   10.02173615   9.54458427   8.13270664   6.79261827   7.83566046]\n",
      " [ 17.53080177  19.53086281  20.91588211  20.52921104  22.3358078   17.65028\n",
      "   18.14908218  18.75529099  16.94472313  18.72291374]]\n",
      "Training set BPC at step 9800: 3.24091 learning rate: 0.090000\n",
      "memory=\n",
      " [[ 21.28998947  24.88458443  26.11018372  25.80060005  25.09171677\n",
      "   23.93040657  24.74324417  23.97875214  22.19727898  24.12635231]\n",
      " [ 15.16585445  19.50903511  17.56279182  19.34545708  19.50902176\n",
      "   16.6342411   16.51461411  16.65721893  16.49134445  16.82157707]\n",
      " [ 16.13311577  15.60765362  17.21876335  16.14139366  17.21075249\n",
      "   16.35737801  17.3209362   14.78241634  15.78995609  16.43261147]\n",
      " [  8.22346783   9.20696545   6.93262196   8.98064709  10.35356998\n",
      "   10.07069588   9.51395321   8.11872482   6.71894026   7.87981606]\n",
      " [ 17.69029808  19.71000671  21.21963501  20.64893341  22.6433506\n",
      "   17.89244843  18.29844284  18.84971237  17.04608917  18.87322044]]\n",
      "Training set BPC at step 9900: 5.70229 learning rate: 0.090000\n"
     ]
    }
   ],
   "source": [
    "# How often the test loss on validation batch will be computed. \n",
    "summary_frequency = 100\n",
    "\n",
    "# Create session to execute graph.\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "# Create summary writers, point them to LOG_DIR.\n",
    "train_writer = tf.summary.FileWriter(LOG_DIR + '/train', sess.graph)\n",
    "valid_writer = tf.summary.FileWriter(LOG_DIR + '/valid')\n",
    "test_writer = tf.summary.FileWriter(LOG_DIR + '/test')\n",
    "\n",
    "# Initialize global variables.\n",
    "tf.global_variables_initializer().run()\n",
    "print('Variables initialized')\n",
    "\n",
    "\n",
    "# Create initial previous read and update - full of zeros. \n",
    "prev_rw_seq_batch = list()\n",
    "prev_uw_seq_batch = list()\n",
    "for i in range(SEQ_LENGTH):\n",
    "    prev_rw_seq_batch.append(np.zeros([BATCH_SIZE, MEMORY_SLOTS]))\n",
    "    prev_uw_seq_batch.append(np.zeros([BATCH_SIZE, MEMORY_SLOTS]))\n",
    "\n",
    "num_steps = 10000 #train_size // (BATCH_SIZE*SEQ_LENGTH) #70001\n",
    "print(\"Number of iterations per epoch =\", num_steps)\n",
    "for step in range(num_steps):\n",
    "    input_seq_batch_, memory_, prev_rw_seq_batch, prev_uw_seq_batch, summaries, _, loss_, lr_ = sess.run([\n",
    "        input_seq_batch, memory, read_weights_seq_batch, update_weights_seq_batch, merged_summaries, optimizer, loss, learning_rate],\n",
    "        feed_dict=create_feed_dict(\"train\"))#batch_seq))\n",
    "    \n",
    "    # Add summary.\n",
    "    train_writer.add_summary(summaries, step*BATCH_SIZE*SEQ_LENGTH)\n",
    "    train_writer.flush()\n",
    "\n",
    "    # Every (100) steps collect statistics.\n",
    "    if step % summary_frequency == 0:\n",
    "        print(\"memory=\\n\", memory_)\n",
    "        # Print loss from last batch.\n",
    "        print('Training set BPC at step %d: %0.5f learning rate: %f' % (step, loss_, lr_))\n",
    "    \n",
    "        # Validation set BPC.\n",
    "        #v_summaries, v_loss = sess.run([merged_summaries, loss], feed_dict=create_feed_dict(\"valid\"))\n",
    "        #print(\"Validation set BPC: %.5f\" % v_loss)\n",
    "        #valid_writer.add_summary(v_summaries, step*BATCH_SIZE*SEQ_LENGTH)\n",
    "        #valid_writer.flush()\n",
    "    # End of statistics collection\n",
    "\n",
    "# Test set BPC.\n",
    "#print(\"Calculating BPC on test dataset\")\n",
    "#t_summary, t_loss = sess.run([merged_summaries, loss], feed_dict=create_feed_dict(\"test\"))\n",
    "#print(\"Final test set BPC: %.5f\" % t_loss)\n",
    "#test_writer.add_summary(t_summary, step*BATCH_SIZE*SEQ_LENGTH)\n",
    "#test_writer.flush()\n",
    "    \n",
    "# Close writers and session.\n",
    "train_writer.close()\n",
    "valid_writer.close()\n",
    "test_writer.close()\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
