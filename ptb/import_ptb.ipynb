{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#from os import path\n",
    "import random\n",
    "#import tempfile\n",
    "#import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import random_seed\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "# Datasets = collections.namedtuple('Datasets', ['train', 'validation', 'test'])\n",
    "\n",
    "# Local dir where PRB files will be stored.\n",
    "PTB_DIR = '/home/tkornuta/data/ptb/'\n",
    "# Filenames.\n",
    "TRAIN = \"ptb.char.train.txt\"\n",
    "VALID = \"ptb.char.valid.txt\"\n",
    "TEST = \"ptb.char.test.txt\"\n",
    "\n",
    "# Number of characters in a single phrase.\n",
    "PHRASE_LENGTH=100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse_document(filename):\n",
    "    \"\"\"Parses document using space as delimiter.\"\"\"\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        return f.read().replace(\"\\n\", \"<eos>\").split()\n",
    "\n",
    "def _build_vocab(filename):\n",
    "    \"\"\"Builds and returns a vocabulary for a given document.\"\"\"\n",
    "    # Parse document.\n",
    "    data = _parse_document(filename)\n",
    "    # Transform data to dictionary (key - value)\n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    # Returns dictionary that can be used for decoding of the document.\n",
    "    return word_to_id\n",
    "\n",
    "def encode_doc_to_one_hot(dense_data_vector, num_classes):\n",
    "    \"\"\"Convert data from dense vector of scalars to vector of one-hot vectors.\"\"\"\n",
    "    num_labels = len(dense_data_vector)\n",
    "    result = np.zeros(shape=(num_labels, num_classes))\n",
    "    result[np.arange(num_labels), dense_data_vector] = 1\n",
    "    return result.astype(int)\n",
    "\n",
    "def _extract_document(filename, word_to_id_dict, one_hot=False):\n",
    "    \"\"\"Reades a document and encodeds it using a dictionary.\"\"\"\n",
    "    data = _parse_document(filename)\n",
    "    encoded_doc = [word_to_id[word] for word in data if word in word_to_id]\n",
    "    if one_hot == True:\n",
    "        return encode_doc_to_one_hot(encoded_doc, len(word_to_id))\n",
    "    # else: \n",
    "    return encoded_doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary = {'x': 29, '2': 41, '9': 38, '<eos>': 24, 'd': 12, 'm': 14, '6': 46, 'N': 26, 't': 2, 'k': 17, 's': 7, 'w': 21, '&': 35, 'q': 33, 'u': 11, 'y': 19, '$': 31, '>': 23, '3': 39, '0': 36, '1': 37, '/': 48, 'c': 13, 'a': 3, '*': 49, 'n': 4, 'b': 20, '\\\\': 44, '7': 45, 'i': 6, '_': 0, '#': 40, 'h': 9, 'o': 5, '8': 42, 'j': 30, '.': 27, 'g': 18, '-': 32, '<': 22, 'l': 10, 'z': 34, 'f': 15, '5': 43, 'p': 16, 'v': 25, '4': 47, 'e': 1, \"'\": 28, 'r': 8}\n",
      "Encoded Document = [[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Number of elements in document =  5017482\n"
     ]
    }
   ],
   "source": [
    "datafile = os.path.join(PTB_DIR, TRAIN)\n",
    "\n",
    "# Build dictionary\n",
    "word_to_id = _build_vocab(datafile)\n",
    "print (\"Vocabulary =\", word_to_id)\n",
    "\n",
    "#num_classes = len(word_to_id)\n",
    "#print (\"Vocabulary size =\", num_classes)\n",
    "\n",
    "#parsed_doc = _parse_document(datafile)\n",
    "#print (\"Document =\", parsed_doc[0:10])\n",
    "\n",
    "#encoded_doc = encode_doc_to_one_hot(datafile, word_to_id)\n",
    "#print (\"Encoded Document =\",encoded_doc[0:10])\n",
    "\n",
    "#one_hot_doc = dense_to_one_hot (encoded_doc, num_classes)\n",
    "#print (\"One-hot encoded document =\", one_hot_doc[0:10])\n",
    "\n",
    "encoded_doc = _extract_document(datafile, word_to_id, False)\n",
    "print(\"Encoded Document =\", encoded_doc[0:10])\n",
    "\n",
    "doc_size = len(encoded_doc)\n",
    "print(\"Number of elements in document = \", doc_size)\n",
    "\n",
    "#mydict = {'george':16,'amber':19}\n",
    "#print(list(mydict.keys())[list(mydict.values()).index(16)]) # Prints george"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc = [[0 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "Number of elements in document =  5017482\n",
      "Number of phrases =  10\n",
      "Phrase[0] = [[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Labels[1] = [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Indices = [0 1 2 3 4 5 6 7 8 9]\n",
      "Shuffling\n",
      "Indices = [2 0 9 3 4 1 7 6 5 8]\n",
      "Phrase[0] = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "TMP_PHRASE_LENGTH = 2\n",
    "# Divide document into phrases of a given size.\n",
    "print (\"Doc =\", encoded_doc[0:500])\n",
    "print(\"Number of elements in document = \", doc_size)\n",
    "num_phrases = 10 #int(doc_size/PHRASE_LENGTH)\n",
    "print (\"Number of phrases = \", num_phrases)\n",
    "# Process data into phrases.\n",
    "phrases = np.array([encoded_doc[i*TMP_PHRASE_LENGTH:(i+1)*TMP_PHRASE_LENGTH] for i in range(num_phrases)])\n",
    "print(\"Phrase[0] =\", phrases[0])\n",
    "labels = np.array([encoded_doc[i*TMP_PHRASE_LENGTH+1:(i+1)*TMP_PHRASE_LENGTH+1] for i in range(num_phrases)])\n",
    "print(\"Labels[1] =\", labels[0])\n",
    "perm = np.arange(num_phrases)\n",
    "print(\"Indices =\",perm)\n",
    "\n",
    "print(\"Shuffling\")\n",
    "np.random.shuffle(perm)\n",
    "print(\"Indices =\",perm)\n",
    "phrases = phrases[perm]\n",
    "print(\"Phrase[0] =\", phrases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataSet(object):\n",
    "\n",
    "  def __init__(self,\n",
    "               text,\n",
    "               phrase_length=100,\n",
    "               seed=None):\n",
    "    \"\"\"Construct a DataSet. Divides (already parsed and encoded) text data into phrases.\n",
    "    Seed arg provides for convenient deterministic testing.\n",
    "    \"\"\"\n",
    "    # Set seed.\n",
    "    seed1, seed2 = random_seed.get_seed(seed)\n",
    "    # If op level seed is not set, use whatever graph level seed is returned\n",
    "    np.random.seed(seed1 if seed is None else seed2)\n",
    "\n",
    "    self._text = text\n",
    "    self._phrase_length = phrase_length\n",
    "    self._epochs_completed = 0\n",
    "    self._index_in_epoch = 0\n",
    "    \n",
    "    # Divide document into phrases of a given size.\n",
    "    doc_size = len(text)\n",
    "    self._num_examples = int(doc_size/phrase_length)\n",
    "    # DATA: Process text into phrases.\n",
    "    self._data = np.array([text[i*phrase_length:(i+1)*phrase_length] for i in range(self._num_examples)])\n",
    "    # LABELS: Process text into phrases - label is next char, so shifted by one.\n",
    "    self._labels = np.array([text[i*phrase_length+1:(i+1)*phrase_length+1] for i in range(self._num_examples)])\n",
    "        \n",
    "  @property\n",
    "  def data(self):\n",
    "    return self._data\n",
    "\n",
    "  @property\n",
    "  def labels(self):\n",
    "    return self._labels\n",
    "\n",
    "  @property\n",
    "  def batch_length(self):\n",
    "    return self._batch_length\n",
    "\n",
    "  @property\n",
    "  def num_examples(self):\n",
    "    return self._num_examples\n",
    "\n",
    "  @property\n",
    "  def epochs_completed(self):\n",
    "    return self._epochs_completed\n",
    "\n",
    "  def next_batch(self, batch_size, shuffle=True):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = self._index_in_epoch\n",
    "    # Shuffle for the first epoch\n",
    "    if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "      perm0 = np.arange(self._num_examples)\n",
    "      np.random.shuffle(perm0)\n",
    "      self._data = self.data[perm0]\n",
    "      self._labels = self.labels[perm0]\n",
    "    # Go to the next epoch\n",
    "    if start + batch_size > self._num_examples:\n",
    "      # Finished epoch\n",
    "      self._epochs_completed += 1\n",
    "      # Get the rest examples in this epoch\n",
    "      rest_num_examples = self._num_examples - start\n",
    "      data_rest_part = self._data[start:self._num_examples]\n",
    "      labels_rest_part = self._labels[start:self._num_examples]\n",
    "      # Shuffle the data\n",
    "      if shuffle:\n",
    "        perm = np.arange(self._num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        self._data = self.data[perm]\n",
    "        self._labels = self.labels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      self._index_in_epoch = batch_size - rest_num_examples\n",
    "      end = self._index_in_epoch\n",
    "      data_new_part = self._data[start:end]\n",
    "      labels_new_part = self._labels[start:end]\n",
    "      return numpy.concatenate((data_rest_part, data_new_part), axis=0) , numpy.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "    else:\n",
    "      self._index_in_epoch += batch_size\n",
    "      end = self._index_in_epoch\n",
    "      return self._data[start:end], self._labels[start:end]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ptb(dir,\n",
    "        phrase_length=100,\n",
    "        one_hot=False,\n",
    "        seed=None):\n",
    "\n",
    "    train_file = os.path.join(PTB_DIR, TRAIN)\n",
    "    valid_file = os.path.join(PTB_DIR, VALID)\n",
    "    test_file = os.path.join(PTB_DIR, TEST)\n",
    "\n",
    "    # Build dictionary on the basis of train data.\n",
    "    word_to_id = _build_vocab(train_file)\n",
    "    #print (word_to_id)   \n",
    "    \n",
    "    # Load data.\n",
    "    train_data = _extract_document(train_file, word_to_id, one_hot)\n",
    "    validaton_data = _extract_document(valid_file, word_to_id, one_hot)\n",
    "    test_data = _extract_document(test_file, word_to_id, one_hot)\n",
    "\n",
    "    options = dict(phrase_length=100,seed=seed)\n",
    "\n",
    "    # Create datasets.\n",
    "    train = TextDataSet(train_data, **options)\n",
    "    validation = TextDataSet(validaton_data, **options)\n",
    "    test = TextDataSet(test_data, **options)\n",
    "\n",
    "    return base.Datasets(train=train, validation=validation, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb = read_ptb(PTB_DIR, PHRASE_LENGTH, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0, 26,  0, 14,  6, 10, 10,  6,  5,  4,  0,  7,  9,  3,  8,  1,  7,\n",
      "         0, 21,  3,  7,  0, 15,  3,  8,  0, 20,  1, 10,  5, 21,  0, 10,  3,\n",
      "         7,  2,  0, 21,  1,  1, 17,  0, 28,  7,  0, 22, 11,  4, 17, 23,  0,\n",
      "         3, 25,  1,  8,  3, 18,  1,  0,  5, 15,  0,  4,  1,  3,  8, 10, 19,\n",
      "         0, 26,  0, 14,  6, 10, 10,  6,  5,  4, 24, 15,  5,  8,  0,  5, 13,\n",
      "         2,  5, 20,  1,  8,  0,  7,  5,  0, 15,  3,  8,  0, 12,  3],\n",
      "       [ 0,  7,  1, 13, 11,  8,  6,  2,  6,  1,  7,  0, 13, 10,  1,  3,  8,\n",
      "         6,  4, 18,  0, 15,  6,  8, 14,  7,  0,  2,  5,  0,  2,  9,  1,  0,\n",
      "         4,  3,  2,  6,  5,  4,  3, 10,  0,  3,  7,  7,  5, 13,  6,  3,  2,\n",
      "         6,  5,  4,  0,  5, 15,  0,  7,  1, 13, 11,  8,  6,  2,  6,  1,  7,\n",
      "         0, 12,  1,  3, 10,  1,  8,  7,  0,  6,  4, 13, 10, 11, 12,  1,  0,\n",
      "         5,  4, 10, 19,  0,  2,  9,  5,  7,  1,  0,  2,  8,  3, 12],\n",
      "       [10,  6,  1, 25,  1,  0,  2,  9,  3,  2,  0,  2,  9,  1,  8,  1,  0,\n",
      "         9,  3, 25,  1,  0, 13,  5,  4,  2,  6,  4, 11,  1, 12,  0,  2,  5,\n",
      "         0, 20,  1,  0,  6,  4, 12,  6, 13,  3,  2,  6,  5,  4,  7,  0,  5,\n",
      "        15,  0,  1, 29, 13,  9,  3,  4, 18,  1, 32,  8,  3,  2,  1,  0, 14,\n",
      "         3,  4,  6, 16, 11, 10,  3,  2,  6,  5,  4,  0, 12, 11,  8,  6,  4,\n",
      "        18,  0,  2,  9,  1,  0, 16,  3,  7,  2,  0,  7,  6, 29,  0],\n",
      "       [ 3,  4, 12,  0, 14,  3,  4, 19,  0,  9,  3, 25,  1,  0, 20,  1,  1,\n",
      "         4,  0,  7, 11, 13, 13,  1,  7,  7, 15, 11, 10,  0,  3,  7,  0,  6,\n",
      "         4,  0,  2,  9,  1,  0, 13,  3,  7,  1,  0,  5, 15,  0,  2,  9,  1,\n",
      "         0,  6,  4, 12,  1, 29,  0, 15, 11,  4, 12,  0,  5, 16,  1,  8,  3,\n",
      "         2,  1, 12,  0, 20, 19,  0, 22, 11,  4, 17, 23,  0, 21,  1,  7,  2,\n",
      "         8,  6, 12, 18,  1,  0, 13,  3, 16,  6,  2,  3, 10, 24, 21],\n",
      "       [ 0,  2,  8,  3, 12,  6,  2,  6,  5,  4,  3, 10,  0, 22, 11,  4, 17,\n",
      "        23,  0,  7,  2,  8,  3,  2,  1, 18,  6,  1,  7,  0,  3, 10, 10,  0,\n",
      "         5, 15,  0,  2,  9,  1,  0,  3, 20,  5, 25,  1,  0,  8,  1, 33, 11,\n",
      "         6,  8,  1,  0,  2,  9,  3,  2,  0, 14,  3,  8, 17,  1,  2,  0, 14,\n",
      "         3, 17,  1,  8,  7,  0, 20,  1,  0,  5,  4,  0,  9,  3,  4, 12,  0,\n",
      "         2,  5,  0, 16,  8,  5, 25,  6, 12,  1,  0, 10,  6, 33, 11],\n",
      "       [12,  3,  2,  1, 12,  0,  4,  1,  2,  0, 16,  8,  5, 15,  6,  2,  0,\n",
      "         3, 15,  2,  1,  8,  0, 16,  3, 19, 14,  1,  4,  2,  7,  0,  2,  5,\n",
      "         0, 14,  6,  4,  5,  8,  6,  2, 19,  0,  6,  4,  2,  1,  8,  1,  7,\n",
      "         2,  7,  0,  8,  5,  7,  1,  0,  2,  5,  0, 26,  0, 14,  6, 10, 10,\n",
      "         6,  5,  4,  0, 15,  8,  3,  4, 13,  7,  0, 11,  7, 31,  0, 26,  0,\n",
      "        14,  6, 10, 10,  6,  5,  4,  0, 15,  8,  5, 14,  0, 26,  0],\n",
      "       [ 7,  0,  9,  6,  7,  0,  2,  1,  3, 14,  0,  6,  4,  2,  8,  5, 12,\n",
      "        11, 13,  1, 12,  0,  3, 16, 16,  3,  8,  1,  4,  2, 10, 19,  0, 22,\n",
      "        11,  4, 17, 23,  0,  2,  9,  1,  0, 14,  3, 18,  4,  1,  2,  6, 13,\n",
      "         0, 15,  6,  1, 10, 12,  7,  0,  6,  4,  0, 16, 10,  3, 13,  1,  0,\n",
      "        16,  8,  1, 25,  1,  4,  2,  6,  4, 18,  0,  2,  9,  1, 14,  0, 15,\n",
      "         8,  5, 14,  0, 10,  5, 21,  1,  8,  6,  4, 18,  0, 13, 11],\n",
      "       [10, 10,  0, 20,  1,  0,  3,  8,  5, 11,  4, 12,  0,  2,  5,  0, 15,\n",
      "         6, 29,  0, 20, 11, 18,  7,  0,  3,  4, 12,  0, 11, 16, 18,  8,  3,\n",
      "        12,  1,  0, 13,  5, 14, 16, 11,  2,  1,  8,  7,  0, 15,  5,  8,  0,\n",
      "        19,  1,  3,  8,  7,  0,  2,  5,  0, 13,  5, 14,  1, 24, 15,  5,  8,\n",
      "         0, 20, 11, 19,  1,  8,  7,  0,  2,  9,  1,  7,  1,  0,  3,  8,  1,\n",
      "         0, 22, 11,  4, 17, 23,  0, 12,  1, 13,  6,  7,  6,  5,  4],\n",
      "       [ 7,  6, 10,  6,  1,  4, 13,  1,  0,  6,  4,  0,  2,  9,  1,  0, 15,\n",
      "         3, 13,  1,  0,  5, 15,  0,  3,  0, 22, 11,  4, 17, 23,  0,  5, 15,\n",
      "         0,  9,  1,  3, 12, 10,  6,  4,  1,  0, 22, 11,  4, 17, 23,  0,  6,\n",
      "         4,  0,  8,  1, 13,  1,  4,  2,  0, 21,  1,  1, 17,  7,  0,  6,  4,\n",
      "        13, 10, 11, 12,  6,  4, 18,  0,  8,  3,  2,  1,  0,  6,  4, 13,  8,\n",
      "         1,  3,  7,  1,  7,  0,  6,  4,  0,  1, 11,  8,  5, 16,  1],\n",
      "       [ 2,  0,  6,  2,  0, 16,  3,  7,  7, 24,  6,  2,  0, 28,  7,  0, 30,\n",
      "        11,  7,  2,  0, 13,  5, 14,  6, 13,  0, 21,  9,  1,  4,  0,  2,  9,\n",
      "         1, 19,  0,  2,  8, 19,  0,  2,  5,  0, 22, 11,  4, 17, 23,  0,  2,\n",
      "         9,  1, 19,  0, 28,  8,  1,  0,  7,  2,  6, 10, 10,  0,  2,  9,  1,\n",
      "         0, 14,  3,  7,  2,  1,  8,  0,  8,  3, 13,  1, 24, 14,  8, 27,  0,\n",
      "        10,  1,  1,  0,  3, 12, 12,  1, 12,  0,  2,  9,  3,  2,  0]]), array([[26,  0, 14,  6, 10, 10,  6,  5,  4,  0,  7,  9,  3,  8,  1,  7,  0,\n",
      "        21,  3,  7,  0, 15,  3,  8,  0, 20,  1, 10,  5, 21,  0, 10,  3,  7,\n",
      "         2,  0, 21,  1,  1, 17,  0, 28,  7,  0, 22, 11,  4, 17, 23,  0,  3,\n",
      "        25,  1,  8,  3, 18,  1,  0,  5, 15,  0,  4,  1,  3,  8, 10, 19,  0,\n",
      "        26,  0, 14,  6, 10, 10,  6,  5,  4, 24, 15,  5,  8,  0,  5, 13,  2,\n",
      "         5, 20,  1,  8,  0,  7,  5,  0, 15,  3,  8,  0, 12,  3,  6],\n",
      "       [ 7,  1, 13, 11,  8,  6,  2,  6,  1,  7,  0, 13, 10,  1,  3,  8,  6,\n",
      "         4, 18,  0, 15,  6,  8, 14,  7,  0,  2,  5,  0,  2,  9,  1,  0,  4,\n",
      "         3,  2,  6,  5,  4,  3, 10,  0,  3,  7,  7,  5, 13,  6,  3,  2,  6,\n",
      "         5,  4,  0,  5, 15,  0,  7,  1, 13, 11,  8,  6,  2,  6,  1,  7,  0,\n",
      "        12,  1,  3, 10,  1,  8,  7,  0,  6,  4, 13, 10, 11, 12,  1,  0,  5,\n",
      "         4, 10, 19,  0,  2,  9,  5,  7,  1,  0,  2,  8,  3, 12,  1],\n",
      "       [ 6,  1, 25,  1,  0,  2,  9,  3,  2,  0,  2,  9,  1,  8,  1,  0,  9,\n",
      "         3, 25,  1,  0, 13,  5,  4,  2,  6,  4, 11,  1, 12,  0,  2,  5,  0,\n",
      "        20,  1,  0,  6,  4, 12,  6, 13,  3,  2,  6,  5,  4,  7,  0,  5, 15,\n",
      "         0,  1, 29, 13,  9,  3,  4, 18,  1, 32,  8,  3,  2,  1,  0, 14,  3,\n",
      "         4,  6, 16, 11, 10,  3,  2,  6,  5,  4,  0, 12, 11,  8,  6,  4, 18,\n",
      "         0,  2,  9,  1,  0, 16,  3,  7,  2,  0,  7,  6, 29,  0, 14],\n",
      "       [ 4, 12,  0, 14,  3,  4, 19,  0,  9,  3, 25,  1,  0, 20,  1,  1,  4,\n",
      "         0,  7, 11, 13, 13,  1,  7,  7, 15, 11, 10,  0,  3,  7,  0,  6,  4,\n",
      "         0,  2,  9,  1,  0, 13,  3,  7,  1,  0,  5, 15,  0,  2,  9,  1,  0,\n",
      "         6,  4, 12,  1, 29,  0, 15, 11,  4, 12,  0,  5, 16,  1,  8,  3,  2,\n",
      "         1, 12,  0, 20, 19,  0, 22, 11,  4, 17, 23,  0, 21,  1,  7,  2,  8,\n",
      "         6, 12, 18,  1,  0, 13,  3, 16,  6,  2,  3, 10, 24, 21,  1],\n",
      "       [ 2,  8,  3, 12,  6,  2,  6,  5,  4,  3, 10,  0, 22, 11,  4, 17, 23,\n",
      "         0,  7,  2,  8,  3,  2,  1, 18,  6,  1,  7,  0,  3, 10, 10,  0,  5,\n",
      "        15,  0,  2,  9,  1,  0,  3, 20,  5, 25,  1,  0,  8,  1, 33, 11,  6,\n",
      "         8,  1,  0,  2,  9,  3,  2,  0, 14,  3,  8, 17,  1,  2,  0, 14,  3,\n",
      "        17,  1,  8,  7,  0, 20,  1,  0,  5,  4,  0,  9,  3,  4, 12,  0,  2,\n",
      "         5,  0, 16,  8,  5, 25,  6, 12,  1,  0, 10,  6, 33, 11,  6],\n",
      "       [ 3,  2,  1, 12,  0,  4,  1,  2,  0, 16,  8,  5, 15,  6,  2,  0,  3,\n",
      "        15,  2,  1,  8,  0, 16,  3, 19, 14,  1,  4,  2,  7,  0,  2,  5,  0,\n",
      "        14,  6,  4,  5,  8,  6,  2, 19,  0,  6,  4,  2,  1,  8,  1,  7,  2,\n",
      "         7,  0,  8,  5,  7,  1,  0,  2,  5,  0, 26,  0, 14,  6, 10, 10,  6,\n",
      "         5,  4,  0, 15,  8,  3,  4, 13,  7,  0, 11,  7, 31,  0, 26,  0, 14,\n",
      "         6, 10, 10,  6,  5,  4,  0, 15,  8,  5, 14,  0, 26,  0, 14],\n",
      "       [ 0,  9,  6,  7,  0,  2,  1,  3, 14,  0,  6,  4,  2,  8,  5, 12, 11,\n",
      "        13,  1, 12,  0,  3, 16, 16,  3,  8,  1,  4,  2, 10, 19,  0, 22, 11,\n",
      "         4, 17, 23,  0,  2,  9,  1,  0, 14,  3, 18,  4,  1,  2,  6, 13,  0,\n",
      "        15,  6,  1, 10, 12,  7,  0,  6,  4,  0, 16, 10,  3, 13,  1,  0, 16,\n",
      "         8,  1, 25,  1,  4,  2,  6,  4, 18,  0,  2,  9,  1, 14,  0, 15,  8,\n",
      "         5, 14,  0, 10,  5, 21,  1,  8,  6,  4, 18,  0, 13, 11,  8],\n",
      "       [10,  0, 20,  1,  0,  3,  8,  5, 11,  4, 12,  0,  2,  5,  0, 15,  6,\n",
      "        29,  0, 20, 11, 18,  7,  0,  3,  4, 12,  0, 11, 16, 18,  8,  3, 12,\n",
      "         1,  0, 13,  5, 14, 16, 11,  2,  1,  8,  7,  0, 15,  5,  8,  0, 19,\n",
      "         1,  3,  8,  7,  0,  2,  5,  0, 13,  5, 14,  1, 24, 15,  5,  8,  0,\n",
      "        20, 11, 19,  1,  8,  7,  0,  2,  9,  1,  7,  1,  0,  3,  8,  1,  0,\n",
      "        22, 11,  4, 17, 23,  0, 12,  1, 13,  6,  7,  6,  5,  4,  7],\n",
      "       [ 6, 10,  6,  1,  4, 13,  1,  0,  6,  4,  0,  2,  9,  1,  0, 15,  3,\n",
      "        13,  1,  0,  5, 15,  0,  3,  0, 22, 11,  4, 17, 23,  0,  5, 15,  0,\n",
      "         9,  1,  3, 12, 10,  6,  4,  1,  0, 22, 11,  4, 17, 23,  0,  6,  4,\n",
      "         0,  8,  1, 13,  1,  4,  2,  0, 21,  1,  1, 17,  7,  0,  6,  4, 13,\n",
      "        10, 11, 12,  6,  4, 18,  0,  8,  3,  2,  1,  0,  6,  4, 13,  8,  1,\n",
      "         3,  7,  1,  7,  0,  6,  4,  0,  1, 11,  8,  5, 16,  1,  0],\n",
      "       [ 0,  6,  2,  0, 16,  3,  7,  7, 24,  6,  2,  0, 28,  7,  0, 30, 11,\n",
      "         7,  2,  0, 13,  5, 14,  6, 13,  0, 21,  9,  1,  4,  0,  2,  9,  1,\n",
      "        19,  0,  2,  8, 19,  0,  2,  5,  0, 22, 11,  4, 17, 23,  0,  2,  9,\n",
      "         1, 19,  0, 28,  8,  1,  0,  7,  2,  6, 10, 10,  0,  2,  9,  1,  0,\n",
      "        14,  3,  7,  2,  1,  8,  0,  8,  3, 13,  1, 24, 14,  8, 27,  0, 10,\n",
      "         1,  1,  0,  3, 12, 12,  1, 12,  0,  2,  9,  3,  2,  0,  2]]))\n"
     ]
    }
   ],
   "source": [
    "print(ptb.train.next_batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
