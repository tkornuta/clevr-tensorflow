{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flame on!\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A toy dataset of points around 3 * x + 2\n",
    "NUM_EXAMPLES = 1000\n",
    "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(inputs):\n",
    "    W = tfe.Variable(5., name='weight')\n",
    "    B = tfe.Variable(10., name='bias')\n",
    "    return inputs * W + B\n",
    "\n",
    "# The loss function to be optimized\n",
    "def loss_fn(model_fn, inputs, targets):\n",
    "  error = model_fn(inputs) - targets\n",
    "  return tf.reduce_mean(tf.square(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 68.86498260498047\n",
      "Loss at step 0: 68.86498260498047\n",
      "Loss at step 20: 68.86498260498047\n",
      "Loss at step 40: 68.86498260498047\n",
      "Loss at step 60: 68.86498260498047\n",
      "Loss at step 80: 68.86498260498047\n",
      "Loss at step 100: 68.86498260498047\n",
      "Loss at step 120: 68.86498260498047\n",
      "Loss at step 140: 68.86498260498047\n",
      "Loss at step 160: 68.86498260498047\n",
      "Loss at step 180: 68.86498260498047\n",
      "Loss at step 200: 68.86498260498047\n",
      "Final loss: 68.86498260498047\n"
     ]
    }
   ],
   "source": [
    "# Define:\n",
    "# 1. A model\n",
    "# 2. Derivatives of a loss function with respect to model parameters\n",
    "# 3. A strategy for updating the variables based on the derivatives\n",
    "model = model_fn\n",
    "grad = tfe.implicit_gradients(loss_fn)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "# The training loop\n",
    "print(\"Initial loss: {}\".format(loss_fn(model, training_inputs, training_outputs).numpy()))\n",
    "for i in range(201):\n",
    "  optimizer.apply_gradients(grad(model, training_inputs, training_outputs))\n",
    "  if i % 20 == 0:\n",
    "    print(\"Loss at step {}: {}\".format(i, loss_fn(model, training_inputs, training_outputs).numpy()))\n",
    "print(\"Final loss: {}\".format(loss_fn(model, training_inputs, training_outputs).numpy()))\n",
    "\n",
    "#print(\"W, B = {}, {}\".format(model.W.numpy(), model.B.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "class Model(object):\n",
    "  def __init__(self):\n",
    "    self.W = tfe.Variable(5., name='weight')\n",
    "    self.B = tfe.Variable(10., name='bias')\n",
    "\n",
    "  def predict(self, inputs):\n",
    "    return inputs * self.W + self.B\n",
    "\n",
    "\n",
    "# The loss function to be optimized\n",
    "def loss(model, inputs, targets):\n",
    "  error = model.predict(inputs) - targets\n",
    "  return tf.reduce_mean(tf.square(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 68.86498260498047\n",
      "Loss at step 0: 66.20679473876953\n",
      "Loss at step 20: 30.33294105529785\n",
      "Loss at step 40: 14.206299781799316\n",
      "Loss at step 60: 6.955915927886963\n",
      "Loss at step 80: 3.69584321975708\n",
      "Loss at step 100: 2.229825496673584\n",
      "Loss at step 120: 1.5705090761184692\n",
      "Loss at step 140: 1.2739661931991577\n",
      "Loss at step 160: 1.1405764818191528\n",
      "Loss at step 180: 1.080570936203003\n",
      "Loss at step 200: 1.0535749197006226\n",
      "Final loss: 1.0535749197006226\n",
      "W, B = 2.99599552154541, 2.119579315185547\n"
     ]
    }
   ],
   "source": [
    "# Define:\n",
    "# 1. A model\n",
    "# 2. Derivatives of a loss function with respect to model parameters\n",
    "# 3. A strategy for updating the variables based on the derivatives\n",
    "model = Model()\n",
    "grad = tfe.implicit_gradients(loss)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "# The training loop\n",
    "print(\"Initial loss: {}\".format(loss(model, training_inputs, training_outputs).numpy()))\n",
    "for i in range(201):\n",
    "  optimizer.apply_gradients(grad(model, training_inputs, training_outputs))\n",
    "  if i % 20 == 0:\n",
    "    print(\"Loss at step {}: {}\".format(i, loss(model, training_inputs, training_outputs).numpy()))\n",
    "print(\"Final loss: {}\".format(loss(model, training_inputs, training_outputs).numpy()))\n",
    "\n",
    "print(\"W, B = {}, {}\".format(model.W.numpy(), model.B.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
